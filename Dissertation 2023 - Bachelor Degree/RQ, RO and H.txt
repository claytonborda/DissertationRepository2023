RQ1: How do different sentiment analysis models perform using Malafosse's football-related tweet data set? 
RQ2: How do different stopword strategies (e.g., NLTK stopwords, customized stopwords, and no stopwords) impact the performance of machine learning and deep learning models in sentiment analysis football-related tasks?
RQ3: Is there a significant relationship between the sentiment of tweets related to football matches and (a) Points Per Game (PPG) on a monthly basis, and (b) match results (win, loss, or draw) on a weekly basis, and if so, are there any significant differences between these relationships?

Research Objectives:

To evaluate the performance of different sentiment analysis models on Malafosse's dataset and identify the best model based on accuracy, precision, recall, F1-score, and other evaluation metrics.
To investigate the impact of various stopword strategies (NLTK stopwords, customized stopwords, and no stopwords) on the performance of machine learning and deep learning models in football-related sentiment analysis tasks.
To investigate the relationships between the sentiment of football-related tweets and Points Per Game (PPG) on a monthly basis, and match results (win, loss, or draw) on a weekly basis, and to determine whether there are any significant differences between these relationships.

Hypotheses:
H1: The performance of sentiment analysis models will significantly differ when applied to Malafosse's football-related tweet dataset.
H2: Different stopword strategies will have a significant impact on the performance of machine learning and deep learning models in football-related sentiment analysis tasks.
H3: There are significant relationships between the sentiment of football-related tweets and (a) Points Per Game (PPG) on a monthly basis, and (b) match results (win, loss, or draw) on a weekly basis, and there are significant differences between these relationships.

RQ8: How does the volume of football-related tweets change in relation to the teams