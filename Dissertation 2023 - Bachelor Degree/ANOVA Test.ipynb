{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point-biserial correlation coefficient: 0.7427790573315299\n",
      "p-value: 0.09073471513358924\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Create a dataset with hypothetical proportions\n",
    "data = {\n",
    "    \"Sentiment\": [\"Positive\", \"Positive\", \"Positive\", \"Negative\", \"Negative\", \"Negative\"],\n",
    "    \"PPG_Category\": [\"High\", \"Medium\", \"Low\", \"High\", \"Medium\", \"Low\"],\n",
    "    \"Proportion\": [0.6517, 0.5733, 0.492, 0.3483, 0.4267, 0.508],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert Sentiment to a binary variable (1 for Positive, 0 for Negative)\n",
    "df[\"Sentiment_Binary\"] = df[\"Sentiment\"].apply(lambda x: 1 if x == \"Positive\" else 0)\n",
    "\n",
    "# Calculate point-biserial correlation coefficient\n",
    "r_pb, p_value = stats.pointbiserialr(df[\"Sentiment_Binary\"], df[\"Proportion\"])\n",
    "\n",
    "print(\"Point-biserial correlation coefficient:\", r_pb)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eta-squared: 0.39387061499832676\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "\n",
    "data = {'PPG_Category': ['High', 'High', 'High', 'High', 'High', 'High', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Low', 'Low', 'Low', 'Low', 'Low'],\n",
    "        'Sentiment': [0.81, 0.64, 0.49, 0.71, 0.6, 0.66, 0.455, 0.513, 0.55, 0.68, 0.53, 0.59, 0.68, 0.55, 0.62, 0.46, 0.5, 0.49, 0.47, 0.54]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "result = pg.anova(data=df, dv='Sentiment', between='PPG_Category', detailed=True)\n",
    "eta_squared = result.at[0, 'np2']\n",
    "\n",
    "print(f\"Eta-squared: {eta_squared}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_positive = {'PPG_Category': ['High', 'High', 'High', 'High', 'High', 'High', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Low', 'Low', 'Low', 'Low', 'Low'],\n",
    "                 'Sentiment': [0.81, 0.64, 0.49, 0.71, 0.6, 0.66, 0.455, 0.513, 0.55, 0.68, 0.53, 0.59, 0.68, 0.55, 0.62, 0.46, 0.5, 0.49, 0.47, 0.54]}\n",
    "\n",
    "data_negative = {'PPG_Category': ['High', 'High', 'High', 'High', 'High', 'High', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Low', 'Low', 'Low', 'Low', 'Low'],\n",
    "                 'Sentiment': [0.19, 0.36, 0.51, 0.29, 0.4, 0.34, 0.545, 0.487, 0.45, 0.32, 0.47, 0.41, 0.32, 0.45, 0.38, 0.54, 0.5, 0.51, 0.53, 0.46]}\n",
    "\n",
    "df_positive = pd.DataFrame(data_positive)\n",
    "df_negative = pd.DataFrame(data_negative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eta-squared (positive sentiment): 0.39387061499832676\n",
      "Eta-squared (negative sentiment): 0.39387061499832654\n"
     ]
    }
   ],
   "source": [
    "import pingouin as pg\n",
    "\n",
    "result_positive = pg.anova(data=df_positive, dv='Sentiment', between='PPG_Category', detailed=True)\n",
    "eta_squared_positive = result_positive.at[0, 'np2']\n",
    "\n",
    "result_negative = pg.anova(data=df_negative, dv='Sentiment', between='PPG_Category', detailed=True)\n",
    "eta_squared_negative = result_negative.at[0, 'np2']\n",
    "\n",
    "print(f\"Eta-squared (positive sentiment): {eta_squared_positive}\")\n",
    "print(f\"Eta-squared (negative sentiment): {eta_squared_negative}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of Season PPG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eta-squared (positive sentiment): 0.39387061499832676\n",
      "P-value (positive sentiment): 0.014184217483114452\n",
      "Eta-squared (negative sentiment): 0.39387061499832654\n",
      "P-value (negative sentiment): 0.014184217483114478\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "\n",
    "data_positive = {'PPG_Category': ['High', 'High', 'High', 'High', 'High', 'High', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Low', 'Low', 'Low', 'Low', 'Low'],\n",
    "                 'Sentiment': [0.81, 0.64, 0.49, 0.71, 0.6, 0.66, 0.455, 0.513, 0.55, 0.68, 0.53, 0.59, 0.68, 0.55, 0.62, 0.46, 0.5, 0.49, 0.47, 0.54]}\n",
    "\n",
    "data_negative = {'PPG_Category': ['High', 'High', 'High', 'High', 'High', 'High', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Low', 'Low', 'Low', 'Low', 'Low'],\n",
    "                 'Sentiment': [0.19, 0.36, 0.51, 0.29, 0.4, 0.34, 0.545, 0.487, 0.45, 0.32, 0.47, 0.41, 0.32, 0.45, 0.38, 0.54, 0.5, 0.51, 0.53, 0.46]}\n",
    "\n",
    "df_positive = pd.DataFrame(data_positive)\n",
    "df_negative = pd.DataFrame(data_negative)\n",
    "\n",
    "result_positive = pg.anova(data=df_positive, dv='Sentiment', between='PPG_Category', detailed=True)\n",
    "eta_squared_positive = result_positive.at[0, 'np2']\n",
    "p_value_positive = result_positive.at[0, 'p-unc']\n",
    "\n",
    "result_negative = pg.anova(data=df_negative, dv='Sentiment', between='PPG_Category', detailed=True)\n",
    "eta_squared_negative = result_negative.at[0, 'np2']\n",
    "p_value_negative = result_negative.at[0, 'p-unc']\n",
    "\n",
    "print(f\"Eta-squared (positive sentiment): {eta_squared_positive}\")\n",
    "print(f\"P-value (positive sentiment): {p_value_positive}\")\n",
    "print(f\"Eta-squared (negative sentiment): {eta_squared_negative}\")\n",
    "print(f\"P-value (negative sentiment): {p_value_negative}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Middle of Season PPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eta-squared (positive sentiment): 0.1776114621858528\n",
      "P-value (positive sentiment): 0.1897382599399187\n",
      "Eta-squared (negative sentiment): 0.17721739130434794\n",
      "P-value (negative sentiment): 0.19051245721243282\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "\n",
    "data_positive = {'PPG_Category': ['High', 'High', 'High', 'High', 'High', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Low', 'Low', 'Low', 'Low', 'Low'],\n",
    "                 'Sentiment': [0.51, 0.59, 0.57, 0.54, 0.52, 0.6, 0.42, 0.53, 0.46, 0.6, 0.44, 0.55, 0.63, 0.23, 0.52, 0.48, 0.45, 0.49, 0.37, 0.39]}\n",
    "\n",
    "data_negative = {'PPG_Category': ['High', 'High', 'High', 'High', 'High', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Low', 'Low', 'Low', 'Low', 'Low'],\n",
    "                 'Sentiment': [0.49, 0.41, 0.43, 0.46, 0.48, 0.4, 0.58, 0.46, 0.54, 0.4, 0.56, 0.45, 0.37, 0.77, 0.48, 0.52, 0.55, 0.51, 0.63, 0.61]}\n",
    "\n",
    "df_positive = pd.DataFrame(data_positive)\n",
    "df_negative = pd.DataFrame(data_negative)\n",
    "\n",
    "result_positive = pg.anova(data=df_positive, dv='Sentiment', between='PPG_Category', detailed=True)\n",
    "eta_squared_positive = result_positive.at[0, 'np2']\n",
    "p_value_positive = result_positive.at[0, 'p-unc']\n",
    "\n",
    "result_negative = pg.anova(data=df_negative, dv='Sentiment', between='PPG_Category', detailed=True)\n",
    "eta_squared_negative = result_negative.at[0, 'np2']\n",
    "p_value_negative = result_negative.at[0, 'p-unc']\n",
    "\n",
    "print(f\"Eta-squared (positive sentiment): {eta_squared_positive}\")\n",
    "print(f\"P-value (positive sentiment): {p_value_positive}\")\n",
    "print(f\"Eta-squared (negative sentiment): {eta_squared_negative}\")\n",
    "print(f\"P-value (negative sentiment): {p_value_negative}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive group η²: 0.0024\n",
      "Negative group η²: 0.0045\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Organize the data\n",
    "won_positive = [0.53, 0.32, 0.51, 0.69, 0.8, 0.66, 0.59, 0.64, 0.5, 0.62, 0.69, 0.67, 0.52, 0.38, 0.44, 0.42, 0.63, 0.63, 0.72, 0.56, 0.5, 0.55, 0.58, 0.51, 0.58, 0.69, 0.33, 0.62, 0.57, 0.55, 0.63, 0.51, 0.23, 0.18, 0.13]\n",
    "won_negative = [0.47, 0.68, 0.49, 0.31, 0.2, 0.34, 0.41, 0.36, 0.5, 0.38, 0.31, 0.36, 0.48, 0.62, 0.56, 0.58, 0.37, 0.37, 0.28, 0.44, 0.5, 0.45, 0.42, 0.49, 0.42, 0.31, 0.66, 0.38, 0.43, 0.45, 0.37, 0.49, 0.77, 0.82, 0.87]\n",
    "\n",
    "draw_positive = [0.49, 0.53, 0.65, 0.48, 0.54, 0.58, 0.37, 0.3, 0.62, 0.67, 0.67, 0.62, 0.76, 0.36, 0.65, 0.51, 0.62, 0.19, 0.11]\n",
    "draw_negative = [0.51, 0.47, 0.35, 0.52, 0.46, 0.42, 0.63, 0.7, 0.38, 0.33, 0.33, 0.38, 0.24, 0.64, 0.35, 0.49, 0.38, 0.81, 0.89]\n",
    "\n",
    "lost_positive = [0.6, 0.76, 0.6, 0.55, 0.51, 0.54, 0.5, 0.42, 0.5, 0.6, 0.63, 0.53, 0.49, 0.5, 0.49, 0.62, 0.59, 0.59, 0.46, 0.59,0.51, 0.54, 0.5, 0.43, 0.53, 0.31, 0.66, 0.55, 0.47, 0.54, 0.16, 0.17]\n",
    "lost_negative = [0.4, 0.24, 0.4, 0.45, 0.49, 0.46, 0.5, 0.58, 0.5, 0.4, 0.37, 0.47, 0.51, 0.5, 0.51, 0.38, 0.41, 0.41, 0.54, 0.41, 0.49, 0.46, 0.5, 0.57, 0.47, 0.69, 0.33, 0.45, 0.53, 0.46, 0.84, 0.83, 0.69, 0.69]\n",
    "\n",
    "# Create separate DataFrames for Positive and Negative groups\n",
    "positive_data = pd.DataFrame({'Match': ['Won']*len(won_positive) + ['Draw']*len(draw_positive) + ['Lost']*len(lost_positive),\n",
    "                              'Score': won_positive + draw_positive + lost_positive})\n",
    "negative_data = pd.DataFrame({'Match': ['Won']*len(won_negative) + ['Draw']*len(draw_negative) + ['Lost']*len(lost_negative),\n",
    "                              'Score': won_negative + draw_negative + lost_negative})\n",
    "\n",
    "# Perform the one-way ANOVA test and compute eta-squared for Positive group\n",
    "f_stat_positive, p_value_positive = f_oneway(positive_data[positive_data['Match'] == 'Won']['Score'],\n",
    "                                             positive_data[positive_data['Match'] == 'Draw']['Score'],\n",
    "                                             positive_data[positive_data['Match'] == 'Lost']['Score'])\n",
    "eta_squared_positive = f_stat_positive / (f_stat_positive + len(positive_data) - 1)\n",
    "\n",
    "# Perform the one-way ANOVA test and compute eta-squared for Negative group\n",
    "f_stat_negative, p_value_negative = f_oneway(negative_data[negative_data['Match'] == 'Won']['Score'],\n",
    "                                             negative_data[negative_data['Match'] == 'Draw']['Score'],\n",
    "                                             negative_data[negative_data['Match'] == 'Lost']['Score'])\n",
    "eta_squared_negative = f_stat_negative / (f_stat_negative + len(negative_data) - 1)\n",
    "\n",
    "print(f\"Positive group η²: {eta_squared_positive:.4f}\")\n",
    "print(f\"Negative group η²: {eta_squared_negative:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H-statistic: 12.421565223152228\n",
      "P-value: 0.029446368935351682\n",
      "Rank-biserial correlation: 0.2588260834422722\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import kruskal, rankdata\n",
    "\n",
    "# Organize the data\n",
    "won_positive = [0.53, 0.32, 0.51, 0.69, 0.8, 0.66, 0.59, 0.64, 0.5, 0.62, 0.69, 0.67, 0.52, 0.38, 0.44, 0.42, 0.63, 0.63, 0.72, 0.56, 0.5, 0.55, 0.58, 0.51, 0.58, 0.69, 0.33, 0.62, 0.57, 0.55, 0.63, 0.51, 0.23, 0.18, 0.13]\n",
    "won_negative = [0.47, 0.68, 0.49, 0.31, 0.2, 0.34, 0.41, 0.36, 0.5, 0.38, 0.31, 0.36, 0.48, 0.62, 0.56, 0.58, 0.37, 0.37, 0.28, 0.44, 0.5, 0.45, 0.42, 0.49, 0.42, 0.31, 0.66, 0.38, 0.43, 0.45, 0.37, 0.49, 0.77, 0.82, 0.87]\n",
    "\n",
    "draw_positive = [0.49, 0.53, 0.65, 0.48, 0.54, 0.58, 0.37, 0.3, 0.62, 0.67, 0.67, 0.62, 0.76, 0.36, 0.65, 0.51, 0.62, 0.19, 0.11]\n",
    "draw_negative = [0.51, 0.47, 0.35, 0.52, 0.46, 0.42, 0.63, 0.7, 0.38, 0.33, 0.33, 0.38, 0.24, 0.64, 0.35, 0.49, 0.38, 0.81, 0.89]\n",
    "\n",
    "lost_positive = [0.6, 0.76, 0.6, 0.55, 0.51, 0.54, 0.5, 0.42, 0.5, 0.6, 0.63, 0.53, 0.49, 0.5, 0.49, 0.62, 0.59, 0.59, 0.46, 0.59,0.51, 0.54, 0.5, 0.43, 0.53, 0.31, 0.66, 0.55, 0.47, 0.54, 0.16, 0.17]\n",
    "lost_negative = [0.4, 0.24, 0.4, 0.45, 0.49, 0.46, 0.5, 0.58, 0.5, 0.4, 0.37, 0.47, 0.51, 0.5, 0.51, 0.38, 0.41, 0.41, 0.54, 0.41, 0.49, 0.46, 0.5, 0.57, 0.47, 0.69, 0.33, 0.45, 0.53, 0.46, 0.84, 0.83, 0.69, 0.69]\n",
    "\n",
    "# Combine the data into a single list\n",
    "combined_data = won_positive + won_negative + draw_positive + draw_negative + lost_positive + lost_negative\n",
    "\n",
    "# Create group labels for the data\n",
    "group_labels = (['won_positive'] * len(won_positive) +\n",
    "                ['won_negative'] * len(won_negative) +\n",
    "                ['draw_positive'] * len(draw_positive) +\n",
    "                ['draw_negative'] * len(draw_negative) +\n",
    "                ['lost_positive'] * len(lost_positive) +\n",
    "                ['lost_negative'] * len(lost_negative))\n",
    "\n",
    "# Perform Kruskal-Wallis H-test\n",
    "h_stat, p_value = kruskal(won_positive, won_negative,\n",
    "                          draw_positive, draw_negative,\n",
    "                          lost_positive, lost_negative)\n",
    "\n",
    "# Perform Kruskal-Wallis H-test\n",
    "h_stat, p_value = kruskal(won_positive, won_negative,\n",
    "                          draw_positive, draw_negative,\n",
    "                          lost_positive, lost_negative)\n",
    "\n",
    "# Calculate rank-biserial correlation\n",
    "n_total = len(combined_data)\n",
    "ranked_data = rankdata(combined_data)\n",
    "group_rank_sums = {label: 0 for label in set(group_labels)}\n",
    "\n",
    "for label, rank in zip(group_labels, ranked_data):\n",
    "    group_rank_sums[label] += rank\n",
    "\n",
    "n_groups = len(group_rank_sums)\n",
    "mean_ranks = {label: rank_sum / group_labels.count(label) for label, rank_sum in group_rank_sums.items()}\n",
    "mean_rank_total = np.mean(ranked_data)\n",
    "\n",
    "ss_between = sum(group_labels.count(label) * (mean_rank - mean_rank_total)**2\n",
    "                 for label, mean_rank in mean_ranks.items())\n",
    "\n",
    "rank_biserial = np.sqrt(h_stat / (h_stat + n_total - 1))\n",
    "\n",
    "print(f\"H-statistic: {h_stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "print(f\"Rank-biserial correlation: {rank_biserial}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Middle of Season PPG - Kruskal-Wallis H-TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H-statistic: 11.382229920451623\n",
      "P-value: 0.044306617804667874\n",
      "Rank-biserial correlation: 0.43416929193712983\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import kruskal, rankdata\n",
    "\n",
    "# Replace these lists with your data\n",
    "high_ppg_positive = [0.51, 0.59, 0.57, 0.54, 0.52]\n",
    "high_ppg_negative = [0.49, 0.41, 0.43, 0.46, 0.48]\n",
    "medium_ppg_positive = [0.6, 0.42, 0.53, 0.46, 0.6, 0.44, 0.55, 0.63, 0.23, 0.52, 0.69, 0.67, 0.52, 0.57]\n",
    "medium_ppg_negative = [0.4, 0.58, 0.46, 0.54, 0.4, 0.56, 0.45, 0.37, 0.77, 0.48, 0.31, 0.33, 0.48, 0.42]\n",
    "low_ppg_positive = [0.48, 0.45, 0.49, 0.37, 0.39, 0.55]\n",
    "low_ppg_negative = [0.52, 0.55, 0.51, 0.63, 0.61, 0.45]\n",
    "\n",
    "# Combine the data into a single list\n",
    "combined_data = (high_ppg_positive + high_ppg_negative +\n",
    "                 medium_ppg_positive + medium_ppg_negative +\n",
    "                 low_ppg_positive + low_ppg_negative)\n",
    "\n",
    "# Create group labels for the data\n",
    "group_labels = (['high_ppg_positive'] * len(high_ppg_positive) +\n",
    "                ['high_ppg_negative'] * len(high_ppg_negative) +\n",
    "                ['medium_ppg_positive'] * len(medium_ppg_positive) +\n",
    "                ['medium_ppg_negative'] * len(medium_ppg_negative) +\n",
    "                ['low_ppg_positive'] * len(low_ppg_positive) +\n",
    "                ['low_ppg_negative'] * len(low_ppg_negative))\n",
    "\n",
    "# Perform Kruskal-Wallis H-test\n",
    "h_stat, p_value = kruskal(high_ppg_positive, high_ppg_negative,\n",
    "                          medium_ppg_positive, medium_ppg_negative,\n",
    "                          low_ppg_positive, low_ppg_negative)\n",
    "\n",
    "# Calculate rank-biserial correlation\n",
    "n_total = len(combined_data)\n",
    "ranked_data = rankdata(combined_data)\n",
    "group_rank_sums = {label: 0 for label in set(group_labels)}\n",
    "\n",
    "for label, rank in zip(group_labels, ranked_data):\n",
    "    group_rank_sums[label] += rank\n",
    "\n",
    "n_groups = len(group_rank_sums)\n",
    "mean_ranks = {label: rank_sum / group_labels.count(label) for label, rank_sum in group_rank_sums.items()}\n",
    "mean_rank_total = np.mean(ranked_data)\n",
    "\n",
    "ss_between = sum(group_labels.count(label) * (mean_rank - mean_rank_total)**2\n",
    "                 for label, mean_rank in mean_ranks.items())\n",
    "\n",
    "rank_biserial = np.sqrt(h_stat / (h_stat + n_total - 1))\n",
    "\n",
    "print(f\"H-statistic: {h_stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "print(f\"Rank-biserial correlation: {rank_biserial}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H-statistic: 25.41339129072683\n",
      "P-value: 0.0001159210562108758\n",
      "Rank-biserial correlation: 0.6281208782395873\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import kruskal, rankdata\n",
    "\n",
    "# Replace these lists with your data\n",
    "high_ppg_positive = [0.81, 0.64, 0.49, 0.71, 0.6, 0.66]\n",
    "high_ppg_negative = [0.19, 0.36, 0.51, 0.29, 0.4, 0.34]\n",
    "medium_ppg_positive = [0.46, 0.51, 0.55, 0.68, 0.53, 0.59, 0.68, 0.55, 0.62]\n",
    "medium_ppg_negative = [0.54, 0.487, 0.45, 0.32, 0.47, 0.41, 0.32, 0.45, 0.38]\n",
    "low_ppg_positive = [0.46, 0.5, 0.49, 0.47, 0.54]\n",
    "low_ppg_negative = [0.54, 0.5, 0.51, 0.53, 0.46]\n",
    "\n",
    "# Combine the data into a single list\n",
    "combined_data = (high_ppg_positive + high_ppg_negative +\n",
    "                 medium_ppg_positive + medium_ppg_negative +\n",
    "                 low_ppg_positive + low_ppg_negative)\n",
    "\n",
    "# Create group labels for the data\n",
    "group_labels = (['high_ppg_positive'] * len(high_ppg_positive) +\n",
    "                ['high_ppg_negative'] * len(high_ppg_negative) +\n",
    "                ['medium_ppg_positive'] * len(medium_ppg_positive) +\n",
    "                ['medium_ppg_negative'] * len(medium_ppg_negative) +\n",
    "                ['low_ppg_positive'] * len(low_ppg_positive) +\n",
    "                ['low_ppg_negative'] * len(low_ppg_negative))\n",
    "\n",
    "# Perform Kruskal-Wallis H-test\n",
    "h_stat, p_value = kruskal(high_ppg_positive, high_ppg_negative,\n",
    "                          medium_ppg_positive, medium_ppg_negative,\n",
    "                          low_ppg_positive, low_ppg_negative)\n",
    "\n",
    "# Calculate rank-biserial correlation\n",
    "n_total = len(combined_data)\n",
    "ranked_data = rankdata(combined_data)\n",
    "group_rank_sums = {label: 0 for label in set(group_labels)}\n",
    "\n",
    "for label, rank in zip(group_labels, ranked_data):\n",
    "    group_rank_sums[label] += rank\n",
    "\n",
    "n_groups = len(group_rank_sums)\n",
    "mean_ranks = {label: rank_sum / group_labels.count(label) for label, rank_sum in group_rank_sums.items()}\n",
    "mean_rank_total = np.mean(ranked_data)\n",
    "\n",
    "ss_between = sum(group_labels.count(label) * (mean_rank - mean_rank_total)**2\n",
    "                 for label, mean_rank in mean_ranks.items())\n",
    "\n",
    "rank_biserial = np.sqrt(h_stat / (h_stat + n_total - 1))\n",
    "\n",
    "print(f\"H-statistic: {h_stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "print(f\"Rank-biserial correlation: {rank_biserial}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rank-biserial correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation for Match Won: SignificanceResult(statistic=-0.9993988289536501, pvalue=9.077124466742134e-50)\n",
      "Correlation for Match Draw: SignificanceResult(statistic=-0.9999999999999999, pvalue=0.0)\n",
      "Correlation for Match Lost: SignificanceResult(statistic=-0.9999145299479045, pvalue=7.433855327356925e-62)\n",
      "Correlation for High PPG: SignificanceResult(statistic=-0.9999999999999999, pvalue=0.0)\n",
      "Correlation for Medium PPG: SignificanceResult(statistic=-0.9995343370404636, pvalue=1.470580358806051e-19)\n",
      "Correlation for Low PPG: SignificanceResult(statistic=-1.0, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Match Won\n",
    "match_won_positive = [0.53, 0.32, 0.51, 0.69, 0.8, 0.66, 0.59, 0.64, 0.5, 0.62, 0.69, 0.67, 0.52, 0.38, 0.44, 0.42, 0.63, 0.63, 0.72, 0.56, 0.5, 0.55, 0.58, 0.51, 0.58, 0.69, 0.33, 0.62, 0.57, 0.55, 0.63, 0.51, 0.23, 0.18, 0.13]\n",
    "match_won_negative = [0.47, 0.68, 0.49, 0.31, 0.2, 0.34, 0.41, 0.36, 0.5, 0.38, 0.31, 0.36, 0.48, 0.62, 0.56, 0.58, 0.37, 0.37, 0.28, 0.44, 0.5, 0.45, 0.42, 0.49, 0.42, 0.31, 0.66, 0.38, 0.43, 0.45, 0.37, 0.49, 0.77, 0.82, 0.87]\n",
    "\n",
    "# Match Draw\n",
    "match_draw_positive = [0.49, 0.53, 0.65, 0.48, 0.54, 0.58, 0.37, 0.3, 0.62, 0.67, 0.67, 0.62, 0.76, 0.36, 0.65, 0.51, 0.62, 0.19, 0.11]\n",
    "match_draw_negative = [0.51, 0.47, 0.35, 0.52, 0.46, 0.42, 0.63, 0.7, 0.38, 0.33, 0.33, 0.38, 0.24, 0.64, 0.35, 0.49, 0.38, 0.81, 0.89]\n",
    "\n",
    "match_lost_positive = [0.6, 0.76, 0.6, 0.55, 0.51, 0.54, 0.5, 0.42, 0.5, 0.6, 0.63, 0.53, 0.49, 0.5, 0.49, 0.62, 0.59, 0.59, 0.46, 0.59, 0.51, 0.54, 0.5, 0.43, 0.53, 0.31, 0.66, 0.55, 0.47, 0.54, 0.16, 0.17, 0.31, 0.31]\n",
    "match_lost_negative = [0.4, 0.24, 0.4, 0.45, 0.49, 0.46, 0.5, 0.58, 0.5, 0.4, 0.37, 0.47, 0.51, 0.5, 0.51, 0.38, 0.41, 0.41, 0.54, 0.41, 0.49, 0.46, 0.5, 0.57, 0.47, 0.69, 0.33, 0.45, 0.53, 0.46, 0.84, 0.83, 0.69, 0.69]\n",
    "\n",
    "high_ppg_positive = [0.51, 0.59, 0.57, 0.54, 0.52]\n",
    "high_ppg_negative = [0.49, 0.41, 0.43, 0.46, 0.48]\n",
    "\n",
    "medium_ppg_positive = [0.6, 0.42, 0.53, 0.46, 0.6, 0.44, 0.55, 0.63, 0.23, 0.52, 0.69, 0.67, 0.52, 0.57]\n",
    "medium_ppg_negative = [0.4, 0.58, 0.46, 0.54, 0.4, 0.56, 0.45, 0.37, 0.77, 0.48, 0.31, 0.33, 0.48, 0.42]\n",
    "\n",
    "low_ppg_positive = [0.48, 0.45, 0.49, 0.37, 0.39, 0.55]\n",
    "low_ppg_negative = [0.52, 0.55, 0.51, 0.63, 0.61, 0.45]\n",
    "\n",
    "correlation_match_won = stats.pointbiserialr(match_won_positive, match_won_negative)\n",
    "correlation_match_draw = stats.pointbiserialr(match_draw_positive, match_draw_negative)\n",
    "correlation_match_lost = stats.pointbiserialr(match_lost_positive, match_lost_negative)\n",
    "correlation_high_ppg = stats.pointbiserialr(high_ppg_positive, high_ppg_negative)\n",
    "correlation_medium_ppg = stats.pointbiserialr(medium_ppg_positive, medium_ppg_negative)\n",
    "correlation_low_ppg = stats.pointbiserialr(low_ppg_positive, low_ppg_negative)\n",
    "\n",
    "print(\"Correlation for Match Won:\", correlation_match_won)\n",
    "print(\"Correlation for Match Draw:\", correlation_match_draw)\n",
    "print(\"Correlation for Match Lost:\", correlation_match_lost)\n",
    "print(\"Correlation for High PPG:\", correlation_high_ppg)\n",
    "print(\"Correlation for Medium PPG:\", correlation_medium_ppg)\n",
    "print(\"Correlation for Low PPG:\", correlation_low_ppg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapiro-Wilk p-value for High Positive: 0.68\n",
      "Shapiro-Wilk p-value for High Negative: 0.68\n",
      "Shapiro-Wilk p-value for Medium Positive: 0.25\n",
      "Shapiro-Wilk p-value for Medium Negative: 0.23\n",
      "Shapiro-Wilk p-value for Low Positive: 0.82\n",
      "Shapiro-Wilk p-value for Low Negative: 0.82\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "# Positive and negative sentiment decimals for each PPG category\n",
    "high_positive = [0.51, 0.59, 0.57, 0.54, 0.52]\n",
    "high_negative = [0.49, 0.41, 0.43, 0.46, 0.48]\n",
    "medium_positive = [0.6, 0.42, 0.53, 0.46, 0.6, 0.44, 0.55, 0.63, 0.23, 0.52, 0.69, 0.67, 0.52, 0.57]\n",
    "medium_negative = [0.4, 0.58, 0.46, 0.54, 0.4, 0.56, 0.45, 0.37, 0.77, 0.48, 0.31, 0.33, 0.48, 0.42]\n",
    "low_positive = [0.48, 0.45, 0.49, 0.37, 0.39, 0.55]\n",
    "low_negative = [0.52, 0.55, 0.51, 0.63, 0.61, 0.45]\n",
    "\n",
    "# Perform the Shapiro-Wilk test for each list\n",
    "_, high_positive_p = shapiro(high_positive)\n",
    "_, high_negative_p = shapiro(high_negative)\n",
    "_, medium_positive_p = shapiro(medium_positive)\n",
    "_, medium_negative_p = shapiro(medium_negative)\n",
    "_, low_positive_p = shapiro(low_positive)\n",
    "_, low_negative_p = shapiro(low_negative)\n",
    "\n",
    "# Print the p-values\n",
    "print(f\"Shapiro-Wilk p-value for High Positive: {high_positive_p:.2f}\")\n",
    "print(f\"Shapiro-Wilk p-value for High Negative: {high_negative_p:.2f}\")\n",
    "print(f\"Shapiro-Wilk p-value for Medium Positive: {medium_positive_p:.2f}\")\n",
    "print(f\"Shapiro-Wilk p-value for Medium Negative: {medium_negative_p:.2f}\")\n",
    "print(f\"Shapiro-Wilk p-value for Low Positive: {low_positive_p:.2f}\")\n",
    "print(f\"Shapiro-Wilk p-value for Low Negative: {low_negative_p:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson's correlation coefficient for positive sentiment: 0.32\n",
      "Pearson's correlation coefficient for negative sentiment: -0.32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Independent variable (sentiment category decimal)\n",
    "positive_sentiment = [\n",
    "    0.51, 0.59, 0.57, 0.54, 0.52,\n",
    "    0.6, 0.42, 0.53, 0.46, 0.6, 0.44, 0.55, 0.63, 0.23, 0.52, 0.69, 0.67, 0.52, 0.57,\n",
    "    0.48, 0.45, 0.49, 0.37, 0.39, 0.55\n",
    "]\n",
    "\n",
    "negative_sentiment = [\n",
    "    0.49, 0.41, 0.43, 0.46, 0.48,\n",
    "    0.4, 0.58, 0.46, 0.54, 0.4, 0.56, 0.45, 0.37, 0.77, 0.48, 0.31, 0.33, 0.48, 0.42,\n",
    "    0.52, 0.55, 0.51, 0.63, 0.61, 0.45\n",
    "]\n",
    "\n",
    "# Dependent variable (PPG category)\n",
    "positive_ppg = [3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1]\n",
    "negative_ppg = [3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "# Calculate the Pearson's correlation coefficient for positive and negative sentiments separately\n",
    "positive_corr, _ = pearsonr(positive_sentiment, positive_ppg)\n",
    "negative_corr, _ = pearsonr(negative_sentiment, negative_ppg)\n",
    "\n",
    "print(f\"Pearson's correlation coefficient for positive sentiment: {positive_corr:.2f}\")\n",
    "print(f\"Pearson's correlation coefficient for negative sentiment: {negative_corr:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA results: F-value = 0.0003, p-value = 0.9997\n",
      "Correlation coefficient: 0.1370\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Data\n",
    "high_ppg_positive = [0.51, 0.59, 0.57, 0.54, 0.52]\n",
    "high_ppg_negative = [0.49, 0.41, 0.43, 0.46, 0.48]\n",
    "\n",
    "medium_ppg_positive = [0.6, 0.42, 0.53, 0.46, 0.6, 0.44, 0.55, 0.63, 0.23, 0.52, 0.69, 0.67, 0.52, 0.57]\n",
    "medium_ppg_negative = [0.4, 0.58, 0.46, 0.54, 0.4, 0.56, 0.45, 0.37, 0.77, 0.48, 0.31, 0.33, 0.48, 0.42]\n",
    "\n",
    "low_ppg_positive = [0.48, 0.45, 0.49, 0.37, 0.39, 0.55]\n",
    "low_ppg_negative = [0.52, 0.55, 0.51, 0.63, 0.61, 0.45]\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    \"Sentiment\": np.repeat([\"Positive\", \"Negative\"], [len(high_ppg_positive) + len(medium_ppg_positive) + len(low_ppg_positive),\n",
    "                                                      len(high_ppg_negative) + len(medium_ppg_negative) + len(low_ppg_negative)]),\n",
    "    \"PPG\": np.concatenate([np.repeat(\"High\", len(high_ppg_positive)), np.repeat(\"High\", len(high_ppg_negative)),\n",
    "                           np.repeat(\"Medium\", len(medium_ppg_positive)), np.repeat(\"Medium\", len(medium_ppg_negative)),\n",
    "                           np.repeat(\"Low\", len(low_ppg_positive)), np.repeat(\"Low\", len(low_ppg_negative))]),\n",
    "    \"SentimentValue\": np.concatenate([high_ppg_positive, high_ppg_negative, medium_ppg_positive, medium_ppg_negative, low_ppg_positive, low_ppg_negative])\n",
    "})\n",
    "\n",
    "# ANOVA test\n",
    "anova_results = stats.f_oneway(data[data[\"PPG\"] == \"High\"][\"SentimentValue\"],\n",
    "                               data[data[\"PPG\"] == \"Medium\"][\"SentimentValue\"],\n",
    "                               data[data[\"PPG\"] == \"Low\"][\"SentimentValue\"])\n",
    "\n",
    "print(f\"ANOVA results: F-value = {anova_results.statistic:.4f}, p-value = {anova_results.pvalue:.4f}\")\n",
    "\n",
    "# Correlation coefficient\n",
    "correlation_coefficient, _ = stats.pearsonr(data[\"Sentiment\"].apply(lambda x: 1 if x == \"Positive\" else -1), data[\"SentimentValue\"])\n",
    "\n",
    "print(f\"Correlation coefficient: {correlation_coefficient:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eta-squared (positive sentiment): 0.35311423047827195\n",
      "P-value (positive sentiment): 0.02466235689675315\n",
      "Eta-squared (negative sentiment): 0.35311423047827195\n",
      "P-value (negative sentiment): 0.024662356896753196\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "\n",
    "data_positive = {'PPG_Category': ['High', 'High', 'High', 'High', 'High', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Low', 'Low', 'Low', 'Low', 'Low'],\n",
    "                 'Sentiment': [0.81, 0.64, 0.49, 0.71, 0.6, 0.66, 0.45, 0.51, 0.55, 0.68, 0.53, 0.59, 0.68, 0.55, 0.62, 0.46, 0.5, 0.49, 0.47, 0.54]}\n",
    "\n",
    "data_negative = {'PPG_Category': ['High', 'High', 'High', 'High', 'High', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Low', 'Low', 'Low', 'Low', 'Low'],\n",
    "                 'Sentiment': [0.19, 0.36, 0.51, 0.29, 0.4, 0.34, 0.55, 0.49, 0.45, 0.32, 0.47, 0.41, 0.32, 0.45, 0.38, 0.54, 0.5, 0.51, 0.53, 0.46]}\n",
    "\n",
    "df_positive = pd.DataFrame(data_positive)\n",
    "df_negative = pd.DataFrame(data_negative)\n",
    "\n",
    "result_positive = pg.anova(data=df_positive, dv='Sentiment', between='PPG_Category', detailed=True)\n",
    "eta_squared_positive = result_positive.at[0, 'np2']\n",
    "p_value_positive = result_positive.at[0, 'p-unc']\n",
    "\n",
    "result_negative = pg.anova(data=df_negative, dv='Sentiment', between='PPG_Category', detailed=True)\n",
    "eta_squared_negative = result_negative.at[0, 'np2']\n",
    "p_value_negative = result_negative.at[0, 'p-unc']\n",
    "\n",
    "print(f\"Eta-squared (positive sentiment): {eta_squared_positive}\")\n",
    "print(f\"P-value (positive sentiment): {p_value_positive}\")\n",
    "print(f\"Eta-squared (negative sentiment): {eta_squared_negative}\")\n",
    "print(f\"P-value (negative sentiment): {p_value_negative}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eta-squared (positive sentiment): 0.18018252933507165\n",
      "P-value (positive sentiment): 0.18475488799718828\n",
      "Eta-squared (negative sentiment): 0.1733841842188902\n",
      "P-value (negative sentiment): 0.1981899092805913\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "\n",
    "data_positive = {'PPG_Category': ['High', 'High', 'High', 'High', 'High', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Low', 'Low', 'Low', 'Low', 'Low'],\n",
    "                 'Sentiment': [0.51, 0.59, 0.57, 0.54, 0.52, 0.6, 0.58, 0.54, 0.46, 0.6, 0.44, 0.45, 0.63, 0.23, 0.51, 0.48, 0.45, 0.49, 0.37, 0.39]}\n",
    "\n",
    "data_negative = {'PPG_Category': ['High', 'High', 'High', 'High', 'High', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Medium', 'Low', 'Low', 'Low', 'Low', 'Low'],\n",
    "                 'Sentiment': [0.49, 0.41, 0.43, 0.47, 0.48, 0.4, 0.42, 0.46, 0.54, 0.4, 0.57, 0.55, 0.37, 0.77, 0.49, 0.52, 0.55, 0.51, 0.63, 0.61]}\n",
    "\n",
    "df_positive = pd.DataFrame(data_positive)\n",
    "df_negative = pd.DataFrame(data_negative)\n",
    "\n",
    "result_positive = pg.anova(data=df_positive, dv='Sentiment', between='PPG_Category', detailed=True)\n",
    "eta_squared_positive = result_positive.at[0, 'np2']\n",
    "p_value_positive = result_positive.at[0, 'p-unc']\n",
    "\n",
    "result_negative = pg.anova(data=df_negative, dv='Sentiment', between='PPG_Category', detailed=True)\n",
    "eta_squared_negative = result_negative.at[0, 'np2']\n",
    "p_value_negative = result_negative.at[0, 'p-unc']\n",
    "\n",
    "print(f\"Eta-squared (positive sentiment): {eta_squared_positive}\")\n",
    "print(f\"P-value (positive sentiment): {p_value_positive}\")\n",
    "print(f\"Eta-squared (negative sentiment): {eta_squared_negative}\")\n",
    "print(f\"P-value (negative sentiment): {p_value_negative}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames:\n",
      "\n",
      "Match Win:\n",
      "    match_win_positive  match_win_negative\n",
      "0                 0.67                0.33\n",
      "1                 0.50                0.50\n",
      "2                 0.73                0.27\n",
      "3                 0.72                0.28\n",
      "4                 0.89                0.11\n",
      "5                 0.71                0.29\n",
      "6                 0.75                0.25\n",
      "7                 0.76                0.24\n",
      "8                 0.88                0.12\n",
      "9                 0.74                0.26\n",
      "10                0.71                0.29\n",
      "11                0.75                0.25\n",
      "\n",
      "Match Draw:\n",
      "   match_draw_positive  match_draw_negative\n",
      "0                 0.59                 0.41\n",
      "1                 0.80                 0.20\n",
      "2                 0.66                 0.34\n",
      "3                 0.29                 0.71\n",
      "\n",
      "Match Loss:\n",
      "   match_loss_positive  match_loss_negative\n",
      "0                 0.70                 0.30\n",
      "1                 0.50                 0.50\n",
      "2                 0.60                 0.40\n",
      "3                 0.69                 0.31\n",
      "4                 0.74                 0.26\n",
      "5                 0.83                 0.17\n",
      "6                 0.62                 0.38\n",
      "Correlation between positive sentiment and match win: -1.0\n",
      "Correlation between negative sentiment and match loss: -1.0\n",
      "Correlation between positive sentiment and match draw: -1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_win = {\n",
    "    \"match_win_positive\": [0.67, 0.5, 0.73, 0.72, 0.89, 0.71, 0.75, 0.76, 0.88, 0.74, 0.71, 0.75],\n",
    "    \"match_win_negative\": [0.33, 0.5, 0.27, 0.28, 0.11, 0.29, 0.25, 0.24, 0.12, 0.26, 0.29, 0.25]\n",
    "}\n",
    "\n",
    "data_draw = {\n",
    "    \"match_draw_positive\": [0.59, 0.8, 0.66, 0.29],\n",
    "    \"match_draw_negative\": [0.41, 0.2, 0.34, 0.71]\n",
    "}\n",
    "\n",
    "data_loss = {\n",
    "    \"match_loss_positive\": [0.7, 0.5, 0.6, 0.69, 0.74, 0.83, 0.62],\n",
    "    \"match_loss_negative\": [0.3, 0.5, 0.4, 0.31, 0.26, 0.17, 0.38]\n",
    "}\n",
    "\n",
    "df_win = pd.DataFrame(data_win)\n",
    "df_draw = pd.DataFrame(data_draw)\n",
    "df_loss = pd.DataFrame(data_loss)\n",
    "\n",
    "corr_win = df_win[\"match_win_positive\"].corr(df_win[\"match_win_negative\"])\n",
    "corr_loss = df_loss[\"match_loss_positive\"].corr(df_loss[\"match_loss_negative\"])\n",
    "corr_draw = df_draw[\"match_draw_positive\"].corr(df_draw[\"match_draw_negative\"])\n",
    "\n",
    "print(\"DataFrames:\")\n",
    "print(\"\\nMatch Win:\")\n",
    "print(df_win)\n",
    "print(\"\\nMatch Draw:\")\n",
    "print(df_draw)\n",
    "print(\"\\nMatch Loss:\")\n",
    "print(df_loss)\n",
    "\n",
    "print(f\"Correlation between positive sentiment and match win: {corr_win}\")\n",
    "print(f\"Correlation between negative sentiment and match loss: {corr_loss}\")\n",
    "print(f\"Correlation between positive sentiment and match draw: {corr_draw}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between positive sentiment and match win: 0.0020703933747412626\n",
      "Correlation between negative sentiment and match loss: 0.020399354302657505\n",
      "Correlation between positive sentiment and match draw: 0.021449648402926222\n",
      "Correlation between negative sentiment and match draw: -0.021449648402926222\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pointbiserialr\n",
    "\n",
    "data = [\n",
    "    {\"sentiment\":0.67, \"outcome\":\"win\", \"type\":\"positive\"},\n",
    "    {\"sentiment\":0.5, \"outcome\":\"win\", \"type\":\"positive\"},\n",
    "    {\"sentiment\":0.73, \"outcome\":\"win\", \"type\":\"positive\"},\n",
    "    {\"sentiment\":0.89, \"outcome\":\"win\", \"type\":\"positive\"},\n",
    "    {\"sentiment\":0.71, \"outcome\":\"win\", \"type\":\"positive\"},\n",
    "    {\"sentiment\":0.75, \"outcome\":\"win\", \"type\":\"positive\"},\n",
    "    {\"sentiment\":0.76, \"outcome\":\"win\", \"type\":\"positive\"},\n",
    "    {\"sentiment\":0.88, \"outcome\":\"win\", \"type\":\"positive\"},\n",
    "    {\"sentiment\":0.74, \"outcome\":\"win\", \"type\":\"positive\"},\n",
    "    {\"sentiment\":0.71, \"outcome\":\"win\", \"type\":\"positive\"},\n",
    "    {\"sentiment\":0.75, \"outcome\":\"win\", \"type\":\"positive\"},\n",
    "    {\"sentiment\":0.33, \"outcome\":\"win\", \"type\":\"negative\"},\n",
    "    {\"sentiment\":0.5, \"outcome\":\"win\", \"type\":\"negative\"},\n",
    "    {\"sentiment\":0.27, \"outcome\":\"win\", \"type\":\"negative\"},\n",
    "    {\"sentiment\":0.28, \"outcome\":\"win\", \"type\":\"negative\"},\n",
    "    {\"sentiment\":0.11, \"outcome\":\"win\", \"type\":\"negative\"},\n",
    "    {\"sentiment\":0.29, \"outcome\":\"win\", \"type\":\"negative\"},\n",
    "    {\"sentiment\":0.25, \"outcome\":\"win\", \"type\":\"negative\"},\n",
    "    {\"sentiment\":0.24, \"outcome\":\"win\", \"type\":\"negative\"},\n",
    "    {\"sentiment\":0.12, \"outcome\":\"win\", \"type\":\"negative\"},\n",
    "    {\"sentiment\":0.26, \"outcome\":\"win\", \"type\":\"negative\"},\n",
    "    {\"sentiment\":0.29, \"outcome\":\"win\", \"type\":\"negative\"},\n",
    "    {\"sentiment\":0.25, \"outcome\":\"win\", \"type\":\"negative\"},\n",
    "    {\"sentiment\":0.59, \"outcome\":\"draw\", \"type\":\"positive\"},\n",
    "    {\"sentiment\":0.8, \"outcome\":\"draw\", \"type\":\"positive\"},\n",
    "    {\"sentiment\":0.66, \"outcome\":\"draw\", \"type\":\"positive\"},\n",
    "    {\"sentiment\":0.29, \"outcome\":\"draw\", \"type\":\"positive\"},\n",
    "    {\"sentiment\":0.41, \"outcome\":\"draw\", \"type\":\"negative\"},\n",
    "    {\"sentiment\":0.2, \"outcome\":\"draw\", \"type\":\"negative\"},\n",
    "    {\"sentiment\":0.34, \"outcome\":\"draw\", \"type\":\"negative\"},\n",
    "    {\"sentiment\":0.71, \"outcome\":\"draw\", \"type\":\"negative\"},\n",
    "    {\"sentiment\":0.7, \"outcome\":\"loss\", \"type\":\"positive\"},\n",
    "    {\"sentiment\":0.5, \"outcome\":\"loss\", \"type\":\"positive\"},\n",
    "    {\"sentiment\":0.6, \"outcome\":\"loss\", \"type\":\"positive\"},\n",
    "    {\"sentiment\":0.74, \"outcome\":\"loss\", \"type\":\"positive\"},\n",
    "    {\"sentiment\":0.83, \"outcome\":\"loss\", \"type\":\"positive\"},\n",
    "    {\"sentiment\":0.62, \"outcome\":\"loss\", \"type\":\"positive\"},\n",
    "    {\"sentiment\":0.3, \"outcome\":\"loss\", \"type\":\"negative\"},\n",
    "    {\"sentiment\":0.5, \"outcome\":\"loss\", \"type\":\"negative\"},\n",
    "    {\"sentiment\":0.4, \"outcome\":\"loss\", \"type\":\"negative\"},\n",
    "    {\"sentiment\":0.31, \"outcome\":\"loss\", \"type\":\"negative\"},\n",
    "    {\"sentiment\":0.26, \"outcome\":\"loss\", \"type\":\"negative\"},\n",
    "    {\"sentiment\":0.17, \"outcome\":\"loss\", \"type\":\"negative\"},\n",
    "    {\"sentiment\":0.38, \"outcome\":\"loss\", \"type\":\"negative\"},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df[\"win\"] = np.where(df[\"outcome\"] == \"win\", 1, 0)\n",
    "df[\"loss\"] = np.where(df[\"outcome\"] == \"loss\", 1, 0)\n",
    "df[\"draw\"] = np.where(df[\"outcome\"] == \"draw\", 1, 0)\n",
    "\n",
    "df[\"positive\"] = np.where(df[\"type\"] == \"positive\", 1, 0)\n",
    "df[\"negative\"] = np.where(df[\"type\"] == \"negative\", 1, 0)\n",
    "\n",
    "corr_positive_win = pointbiserialr(df[\"positive\"], df[\"win\"])[0]\n",
    "corr_negative_loss = pointbiserialr(df[\"negative\"], df[\"loss\"])[0]\n",
    "corr_positive_draw = pointbiserialr(df[\"positive\"], df[\"draw\"])[0]\n",
    "corr_negative_draw = pointbiserialr(df[\"negative\"], df[\"draw\"])[0]\n",
    "\n",
    "print(f\"Correlation between positive sentiment and match win: {corr_positive_win}\")\n",
    "print(f\"Correlation between negative sentiment and match loss: {corr_negative_loss}\")\n",
    "print(f\"Correlation between positive sentiment and match draw: {corr_positive_draw}\")\n",
    "print(f\"Correlation between negative sentiment and match draw: {corr_negative_draw}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spearman's Rho "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between positive sentiment and match win: 0.40717205074500235\n",
      "Correlation between negative sentiment and match loss: 0.21388753670858077\n",
      "Correlation between positive sentiment and match draw: -0.2769595963858701\n",
      "Correlation between negative sentiment and match draw: 0.2769595963858701\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Your data\n",
    "positive_win = np.array([0.67, 0.5, 0.73, 0.72, 0.89, 0.71, 0.75, 0.76, 0.88, 0.74, 0.71, 0.75])\n",
    "negative_win = np.array([0.33, 0.5, 0.27, 0.28, 0.11, 0.29, 0.25, 0.24, 0.12, 0.26, 0.29, 0.25])\n",
    "\n",
    "positive_draw = np.array([0.59, 0.8, 0.66, 0.29])\n",
    "negative_draw = np.array([0.41, 0.2, 0.34, 0.71])\n",
    "\n",
    "positive_loss = np.array([0.7, 0.5, 0.6, 0.69, 0.74, 0.83, 0.62])\n",
    "negative_loss = np.array([0.3, 0.5, 0.4, 0.31, 0.26, 0.17, 0.38])\n",
    "\n",
    "# Combine data into single arrays\n",
    "positive_sentiment = np.concatenate([positive_win, positive_draw, positive_loss])\n",
    "negative_sentiment = np.concatenate([negative_win, negative_draw, negative_loss])\n",
    "match_outcomes = np.array(['win'] * len(positive_win) + ['draw'] * len(positive_draw) + ['loss'] * len(positive_loss))\n",
    "\n",
    "# Create binary outcome variables\n",
    "is_win = (match_outcomes == 'win').astype(int)\n",
    "is_loss = (match_outcomes == 'loss').astype(int)\n",
    "is_draw = (match_outcomes == 'draw').astype(int)\n",
    "\n",
    "# Calculate Spearman's rho correlations\n",
    "corr_positive_win, _ = spearmanr(positive_sentiment, is_win)\n",
    "corr_negative_loss, _ = spearmanr(negative_sentiment, is_loss)\n",
    "corr_positive_draw, _ = spearmanr(positive_sentiment, is_draw)\n",
    "corr_negative_draw, _ = spearmanr(negative_sentiment, is_draw)\n",
    "\n",
    "# Print correlations\n",
    "print(f\"Correlation between positive sentiment and match win: {corr_positive_win}\")\n",
    "print(f\"Correlation between negative sentiment and match loss: {corr_negative_loss}\")\n",
    "print(f\"Correlation between positive sentiment and match draw: {corr_positive_draw}\")\n",
    "print(f\"Correlation between negative sentiment and match draw: {corr_negative_draw}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between positive sentiment and match win: 0.1960571971773029\n",
      "Correlation between negative sentiment and match loss: 0.18031537842584064\n",
      "Correlation between positive sentiment and match draw: -0.019873072027399255\n",
      "Correlation between negative sentiment and match draw: 0.019873072027399255\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Your data\n",
    "positive_win = np.array([0.67, 0.5, 0.73, 0.72, 0.89, 0.71, 0.75, 0.76, 0.88, 0.74, 0.71, 0.75, 0.54, 0.46, 0.75, 0.82, 0.44, 0.46, 0.71, 0.75, 0.72, 0.85, 0.56, 0.68, 0.68, 0.44, 0.7, 0.72, 0.77, 0.78, 0.75, 0.53, 0.74, 0.76, 0.75])\n",
    "negative_win = np.array([0.33, 0.5, 0.27, 0.28, 0.11, 0.29, 0.25, 0.24, 0.12, 0.26, 0.29, 0.25, 0.46, 0.54, 0.25, 0.18, 0.56, 0.54, 0.29, 0.25, 0.28, 0.15, 0.44, 0.32, 0.32, 0.56, 0.3, 0.28, 0.23, 0.22, 0.25, 0.47, 0.26, 0.24, 0.25])\n",
    "\n",
    "positive_draw = np.array([0.59, 0.8, 0.66, 0.29, 0.62, 0.76, 0.78, 0.57, 0.72, 0.7, 0.78, 0.73, 0.39, 0.48, 0.65, 0.86])\n",
    "negative_draw = np.array([0.41, 0.2, 0.34, 0.71, 0.38, 0.24, 0.22, 0.43, 0.28, 0.3, 0.22, 0.27, 0.61, 0.52, 0.35, 0.14])\n",
    "\n",
    "positive_loss = np.array([0.7, 0.5, 0.6, 0.69, 0.74, 0.83, 0.62, 0.74, 0.72, 0.64, 0.55, 0.55, 0.65, 0.77, 0.42, 0.43, 0.51, 0.7, 0.66, 0.69, 0.69, 0.85, 0.76, 0.86, 0.73, 0.68, 0.62, 0.67, 0.64, 0.45, 0.66, 0.53, 0.77, 0.54, 0.65])\n",
    "negative_loss = np.array([0.3, 0.5, 0.4, 0.31, 0.26, 0.17, 0.38, 0.26, 0.28, 0.36, 0.45, 0.45, 0.35, 0.23, 0.58, 0.57, 0.49, 0.3, 0.34, 0.31, 0.31, 0.15, 0.24, 0.14, 0.27, 0.32, 0.38, 0.33, 0.36, 0.55, 0.34, 0.47, 0.23, 0.46, 0.35])\n",
    "\n",
    "# Combine data into single arrays\n",
    "positive_sentiment = np.concatenate([positive_win, positive_draw, positive_loss])\n",
    "negative_sentiment = np.concatenate([negative_win, negative_draw, negative_loss])\n",
    "match_outcomes = np.array(['win'] * len(positive_win) + ['draw'] * len(positive_draw) + ['loss'] * len(positive_loss))\n",
    "\n",
    "# Create binary outcome variables\n",
    "is_win = (match_outcomes == 'win').astype(int)\n",
    "is_draw = (match_outcomes == 'draw').astype(int)\n",
    "is_loss = (match_outcomes == 'loss').astype(int)\n",
    "\n",
    "# Calculate Spearman's rho correlations\n",
    "corr_positive_win, _ = spearmanr(positive_sentiment, is_win)\n",
    "corr_negative_loss, _ = spearmanr(negative_sentiment, is_loss)\n",
    "corr_positive_draw, _ = spearmanr(positive_sentiment, is_draw)\n",
    "corr_negative_draw, _ = spearmanr(negative_sentiment, is_draw)\n",
    "\n",
    "# Print correlations\n",
    "print(f\"Correlation between positive sentiment and match win: {corr_positive_win}\")\n",
    "print(f\"Correlation between negative sentiment and match loss: {corr_negative_loss}\")\n",
    "print(f\"Correlation between positive sentiment and match draw: {corr_positive_draw}\")\n",
    "print(f\"Correlation between negative sentiment and match draw: {corr_negative_draw}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for predicting wins:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    win   R-squared:                       0.025\n",
      "Model:                            OLS   Adj. R-squared:                  0.013\n",
      "Method:                 Least Squares   F-statistic:                     2.121\n",
      "Date:                Tue, 09 May 2023   Prob (F-statistic):              0.149\n",
      "Time:                        12:38:34   Log-Likelihood:                -59.831\n",
      "No. Observations:                  86   AIC:                             123.7\n",
      "Df Residuals:                      84   BIC:                             128.6\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                  0.2024      0.059      3.430      0.001       0.085       0.320\n",
      "positive_sentiment     0.4106      0.190      2.165      0.033       0.033       0.788\n",
      "negative_sentiment    -0.2082      0.237     -0.879      0.382      -0.679       0.263\n",
      "==============================================================================\n",
      "Omnibus:                     1283.242   Durbin-Watson:                   0.080\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               13.106\n",
      "Skew:                           0.365   Prob(JB):                      0.00143\n",
      "Kurtosis:                       1.232   Cond. No.                     5.40e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 4.6e-30. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "\n",
      "Model for predicting draws:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   draw   R-squared:                       0.005\n",
      "Model:                            OLS   Adj. R-squared:                 -0.007\n",
      "Method:                 Least Squares   F-statistic:                    0.4131\n",
      "Date:                Tue, 09 May 2023   Prob (F-statistic):              0.522\n",
      "Time:                        12:38:34   Log-Likelihood:                -40.651\n",
      "No. Observations:                  86   AIC:                             85.30\n",
      "Df Residuals:                      84   BIC:                             90.21\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                  0.1484      0.047      3.142      0.002       0.054       0.242\n",
      "positive_sentiment    -0.0351      0.152     -0.231      0.818      -0.337       0.267\n",
      "negative_sentiment     0.1835      0.189      0.968      0.336      -0.193       0.560\n",
      "==============================================================================\n",
      "Omnibus:                       26.334   Durbin-Watson:                   0.162\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               38.237\n",
      "Skew:                           1.605   Prob(JB):                     4.98e-09\n",
      "Kurtosis:                       3.608   Cond. No.                     5.40e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 4.6e-30. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Your data\n",
    "positive_win = np.array([0.67, 0.5, 0.73, 0.72, 0.89, 0.71, 0.75, 0.76, 0.88, 0.74, 0.71, 0.75, 0.54, 0.46, 0.75, 0.82, 0.44, 0.46, 0.71, 0.75, 0.72, 0.85, 0.56, 0.68, 0.68, 0.44, 0.7, 0.72, 0.77, 0.78, 0.75, 0.53, 0.74, 0.76, 0.75])\n",
    "negative_win = np.array([0.33, 0.5, 0.27, 0.28, 0.11, 0.29, 0.25, 0.24, 0.12, 0.26, 0.29, 0.25, 0.46, 0.54, 0.25, 0.18, 0.56, 0.54, 0.29, 0.25, 0.28, 0.15, 0.44, 0.32, 0.32, 0.56, 0.3, 0.28, 0.23, 0.22, 0.25, 0.47, 0.26, 0.24, 0.25])\n",
    "\n",
    "positive_draw = np.array([0.59, 0.8, 0.66, 0.29, 0.62, 0.76, 0.78, 0.57, 0.72, 0.7, 0.78, 0.73, 0.39, 0.48, 0.65, 0.86])\n",
    "negative_draw = np.array([0.41, 0.2, 0.34, 0.71, 0.38, 0.24, 0.22, 0.43, 0.28, 0.3, 0.22, 0.27, 0.61, 0.52, 0.35, 0.14])\n",
    "\n",
    "positive_loss = np.array([0.7, 0.5, 0.6, 0.69, 0.74, 0.83, 0.62, 0.74, 0.72, 0.64, 0.55, 0.55, 0.65, 0.77, 0.42, 0.43, 0.51, 0.7, 0.66, 0.69, 0.69, 0.85, 0.76, 0.86, 0.73, 0.68, 0.62, 0.67, 0.64, 0.45, 0.66, 0.53, 0.77, 0.54, 0.65])\n",
    "negative_loss = np.array([0.3, 0.5, 0.4, 0.31, 0.26, 0.17, 0.38, 0.26, 0.28, 0.36, 0.45, 0.45, 0.35, 0.23, 0.58, 0.57, 0.49, 0.3, 0.34, 0.31, 0.31, 0.15, 0.24, 0.14, 0.27, 0.32, 0.38, 0.33, 0.36, 0.55, 0.34, 0.47, 0.23, 0.46, 0.35])\n",
    "\n",
    "\n",
    "# Combine data into single arrays\n",
    "positive_sentiment = np.concatenate([positive_win, positive_draw, positive_loss])\n",
    "negative_sentiment = np.concatenate([negative_win, negative_draw, negative_loss])\n",
    "match_outcomes = np.array(['win'] * len(positive_win) + ['draw'] * len(positive_draw) + ['loss'] * len(positive_loss))\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "data = pd.DataFrame({\n",
    "    'positive_sentiment': positive_sentiment,\n",
    "    'negative_sentiment': negative_sentiment,\n",
    "    'match_outcome': match_outcomes\n",
    "})\n",
    "\n",
    "# Create dummy variables for the match outcomes\n",
    "match_outcome_dummies = pd.get_dummies(data['match_outcome'])\n",
    "data = pd.concat([data, match_outcome_dummies], axis=1)\n",
    "\n",
    "# Define the independent (X) and dependent (y) variables\n",
    "X = data[['positive_sentiment', 'negative_sentiment']]\n",
    "y_win = data['win']\n",
    "y_draw = data['draw']\n",
    "\n",
    "# Add a constant to the independent variables (X) for the intercept term\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the multiple regression models\n",
    "win_model = sm.OLS(y_win, X).fit()\n",
    "draw_model = sm.OLS(y_draw, X).fit()\n",
    "\n",
    "# Print the results\n",
    "print(\"Model for predicting wins:\")\n",
    "print(win_model.summary())\n",
    "print(\"\\nModel for predicting draws:\")\n",
    "print(draw_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   loss   R-squared:                       0.010\n",
      "Model:                            OLS   Adj. R-squared:                 -0.001\n",
      "Method:                 Least Squares   F-statistic:                    0.8744\n",
      "Date:                Tue, 09 May 2023   Prob (F-statistic):              0.352\n",
      "Time:                        12:39:26   Log-Likelihood:                -60.458\n",
      "No. Observations:                  86   AIC:                             124.9\n",
      "Df Residuals:                      84   BIC:                             129.8\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                  0.3159      0.059      5.313      0.000       0.198       0.434\n",
      "positive_sentiment    -0.0422      0.191     -0.221      0.826      -0.422       0.338\n",
      "negative_sentiment     0.3581      0.239      1.501      0.137      -0.116       0.832\n",
      "==============================================================================\n",
      "Omnibus:                     1074.906   Durbin-Watson:                   0.059\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               13.806\n",
      "Skew:                           0.367   Prob(JB):                      0.00100\n",
      "Kurtosis:                       1.180   Cond. No.                     5.40e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 4.6e-30. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Create binary outcome variables\n",
    "is_win = (match_outcomes == 'win').astype(int)\n",
    "is_draw = (match_outcomes == 'draw').astype(int)\n",
    "is_loss = (match_outcomes == 'loss').astype(int)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({'positive_sentiment': positive_sentiment,\n",
    "                     'negative_sentiment': negative_sentiment,\n",
    "                     'win': is_win,\n",
    "                     'draw': is_draw,\n",
    "                     'loss': is_loss})\n",
    "\n",
    "# Perform the regression for match loss\n",
    "X_loss = sm.add_constant(data[['positive_sentiment', 'negative_sentiment']])\n",
    "y_loss = data['loss']\n",
    "\n",
    "model_loss = sm.OLS(y_loss, X_loss).fit()\n",
    "print(model_loss.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.137\n",
      "Model:                            OLS   Adj. R-squared:                  0.096\n",
      "Method:                 Least Squares   F-statistic:                     3.346\n",
      "Date:                Tue, 09 May 2023   Prob (F-statistic):             0.0816\n",
      "Time:                        12:49:33   Log-Likelihood:                 16.108\n",
      "No. Observations:                  23   AIC:                            -28.22\n",
      "Df Residuals:                      21   BIC:                            -25.94\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.6382      0.038     16.837      0.000       0.559       0.717\n",
      "x1             0.0960      0.052      1.829      0.082      -0.013       0.205\n",
      "==============================================================================\n",
      "Omnibus:                        7.846   Durbin-Watson:                   2.010\n",
      "Prob(Omnibus):                  0.020   Jarque-Bera (JB):                5.591\n",
      "Skew:                          -0.966   Prob(JB):                       0.0611\n",
      "Kurtosis:                       4.450   Cond. No.                         2.67\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "# Match Win (1 for win, 0 otherwise)\n",
    "match_win = np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "# Positive Sentiment Analysis Percentage\n",
    "positive_sentiment = np.array([0.67, 0.5, 0.73, 0.72, 0.89, 0.71, 0.75, 0.76, 0.88, 0.74, 0.71, 0.75, 0.59, 0.8, 0.66, 0.29, 0.7, 0.5, 0.6, 0.69, 0.74, 0.83,\t0.62])\n",
    "\n",
    "# Add a constant to the independent variable (match outcome)\n",
    "X = sm.add_constant(match_win)\n",
    "\n",
    "# Estimate the linear regression model\n",
    "model = sm.OLS(positive_sentiment, X).fit()\n",
    "\n",
    "# Print the model summary\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept odds: [2.93744819]\n",
      "Win odds: [[6.00016893]]\n",
      "Intercept probability: [0.7460284]\n",
      "Win probability: [[0.8571463]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Match Win (1 for win, 0 otherwise)\n",
    "match_win = np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "# Positive Sentiment Analysis Percentage\n",
    "positive_sentiment = np.array([0.67, 0.5, 0.73, 0.72, 0.89, 0.71, 0.75, 0.76, 0.88, 0.74, 0.71, 0.75, 0.59, 0.8, 0.66, 0.29, 0.7, 0.5, 0.6, 0.69, 0.74])\n",
    "\n",
    "# Convert positive sentiment analysis percentages into binary values\n",
    "# You can choose a threshold, for example, 0.6 to differentiate between high (1) and low (0) sentiment\n",
    "binary_sentiment = np.where(positive_sentiment >= 0.6, 1, 0)\n",
    "\n",
    "# Create and fit the logistic regression model\n",
    "logistic_model = LogisticRegression(solver='lbfgs')\n",
    "logistic_model.fit(match_win.reshape(-1, 1), binary_sentiment)\n",
    "\n",
    "# Calculate odds and probabilities\n",
    "intercept_odds = np.exp(logistic_model.intercept_)\n",
    "win_odds = np.exp(logistic_model.intercept_ + logistic_model.coef_)\n",
    "\n",
    "intercept_prob = intercept_odds / (1 + intercept_odds)\n",
    "win_prob = win_odds / (1 + win_odds)\n",
    "\n",
    "print(\"Intercept odds:\", intercept_odds)\n",
    "print(\"Win odds:\", win_odds)\n",
    "print(\"Intercept probability:\", intercept_prob)\n",
    "print(\"Win probability:\", win_prob)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept odds: [0.0968153]\n",
      "Loss odds: [[0.12255768]]\n",
      "Intercept probability: [0.08826947]\n",
      "Loss probability: [[0.10917717]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Match Loss (1 for loss, 0 otherwise)\n",
    "match_loss = np.array([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "# Negative Sentiment Analysis Percentage\n",
    "negative_sentiment = np.array([0.3, 0.5, 0.4, 0.31, 0.26, 0.17, 0.38, 0.33, 0.5, 0.27, 0.28, 0.11, 0.29, 0.25, 0.24, 0.12, 0.26, 0.29, 0.25, 0.41, 0.2])\n",
    "\n",
    "# Convert negative sentiment analysis percentages into binary values\n",
    "# You can choose a threshold, for example, 0.3 to differentiate between high (1) and low (0) sentiment\n",
    "binary_sentiment = np.where(negative_sentiment >= 0.5, 1, 0)\n",
    "\n",
    "# Create and fit the logistic regression model\n",
    "logistic_model = LogisticRegression(solver='lbfgs')\n",
    "logistic_model.fit(match_loss.reshape(-1, 1), binary_sentiment)\n",
    "\n",
    "# Calculate odds and probabilities\n",
    "intercept_odds = np.exp(logistic_model.intercept_)\n",
    "loss_odds = np.exp(logistic_model.intercept_ + logistic_model.coef_)\n",
    "\n",
    "intercept_prob = intercept_odds / (1 + intercept_odds)\n",
    "loss_prob = loss_odds / (1 + loss_odds)\n",
    "\n",
    "print(\"Intercept odds:\", intercept_odds)\n",
    "print(\"Loss odds:\", loss_odds)\n",
    "print(\"Intercept probability:\", intercept_prob)\n",
    "print(\"Loss probability:\", loss_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept odds: [0.44250151]\n",
      "High PPG odds: [[1.61484583]]\n",
      "Intercept probability: [0.30675983]\n",
      "High PPG probability: [[0.61756828]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# High PPG (1 for high PPG, 0 otherwise)\n",
    "high_ppg = np.array([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "# Positive Sentiment Analysis Percentage\n",
    "positive_sentiment = np.array([0.81, 0.64, 0.49, 0.71, 0.6, 0.66, 0.46, 0.51, 0.55, 0.68, 0.53, 0.59, 0.68, 0.55, 0.62, 0.46, 0.5, 0.49, 0.47, 0.54])\n",
    "\n",
    "# Convert positive sentiment analysis percentages into binary values\n",
    "# You can choose a threshold, for example, 0.6 to differentiate between high (1) and low (0) sentiment\n",
    "binary_sentiment = np.where(positive_sentiment >= 0.6, 1, 0)\n",
    "\n",
    "# Create and fit the logistic regression model\n",
    "logistic_model = LogisticRegression(solver='lbfgs')\n",
    "logistic_model.fit(high_ppg.reshape(-1, 1), binary_sentiment)\n",
    "\n",
    "# Calculate odds and probabilities\n",
    "intercept_odds = np.exp(logistic_model.intercept_)\n",
    "high_ppg_odds = np.exp(logistic_model.intercept_ + logistic_model.coef_)\n",
    "\n",
    "intercept_prob = intercept_odds / (1 + intercept_odds)\n",
    "high_ppg_prob = high_ppg_odds / (1 + high_ppg_odds)\n",
    "\n",
    "print(\"Intercept odds:\", intercept_odds)\n",
    "print(\"High PPG odds:\", high_ppg_odds)\n",
    "print(\"Intercept probability:\", intercept_prob)\n",
    "print(\"High PPG probability:\", high_ppg_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Average positive sentiment percentages for each PPG category\n",
    "high_ppg_avg_positive = np.mean([0.81, 0.64, 0.49, 0.71, 0.6, 0.66])\n",
    "medium_ppg_avg_positive = np.mean([0.46, 0.51, 0.55, 0.68, 0.53, 0.59, 0.68, 0.55, 0.62])\n",
    "low_ppg_avg_positive = np.mean([0.46, 0.5, 0.49, 0.47, 0.54])\n",
    "\n",
    "# PPG categories and their corresponding average positive sentiment percentages\n",
    "ppg_categories = ['High PPG', 'Medium PPG', 'Low PPG']\n",
    "avg_positive_sentiments = [high_ppg_avg_positive, medium_ppg_avg_positive, low_ppg_avg_positive]\n",
    "\n",
    "# Create a bar chart\n",
    "plt.bar(ppg_categories, avg_positive_sentiments)\n",
    "\n",
    "# Customize the chart\n",
    "plt.xlabel('PPG Categories')\n",
    "plt.ylabel('Average Positive Sentiment Percentage')\n",
    "plt.title('Positive Sentiment Percentage by PPG Category')\n",
    "\n",
    "# Display the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win probability given a positive sentiment of 0.7: 0.5230277569296156\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Match outcome (1 for win, 0 for draw, -1 for loss)\n",
    "match_outcome = np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, -1])\n",
    "\n",
    "# Positive Sentiment Analysis Percentage\n",
    "positive_sentiment = np.array([0.67, 0.5, 0.73, 0.72, 0.89, 0.71, 0.75, 0.76, 0.88, 0.74, 0.71, 0.75, 0.59, 0.8, 0.66, 0.29, 0.7, 0.5, 0.6, 0.69, 0.74, 0.83, 0.62])\n",
    "\n",
    "# Create and fit the logistic regression model\n",
    "logistic_model = LogisticRegression(solver='lbfgs', multi_class='ovr')\n",
    "logistic_model.fit(positive_sentiment.reshape(-1, 1), match_outcome)\n",
    "\n",
    "# Calculate the probability of a win given a positive sentiment (e.g., 0.7)\n",
    "positive_sentiment_example = 0.7\n",
    "win_probability_given_positive_sentiment = logistic_model.predict_proba([[positive_sentiment_example]])[0][2]\n",
    "\n",
    "print(\"Win probability given a positive sentiment of {}:\".format(positive_sentiment_example), win_probability_given_positive_sentiment)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression - Win probability with sentiment > 60% of positive tweets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept odds: [0.60764941]\n",
      "Win odds: [[0.72858565]]\n",
      "Intercept probability: [0.37797383]\n",
      "Win probability: [[0.42149236]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Match Win (1 for win, 0 otherwise)\n",
    "match_win = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "\n",
    "# Positive Sentiment Analysis Percentage\n",
    "positive_sentiment = np.array([0.67,0.5,0.73,0.72,0.89,0.71,0.75,0.76,0.88,0.74,0.71,0.75,0.54,0.46,0.75,0.82,0.44,0.46,0.71,0.75,0.72,0.85,0.56,0.68,0.68,0.44,0.7,0.72,0.77,0.78,0.75,0.53,0.74,0.76,0.75\n",
    "                               ,0.59,0.8,0.66,0.29,0.62,0.76,0.78,0.57,0.72,0.7,0.78,0.73,0.39,0.48,0.65,0.86,0.7,0.5,0.6,0.69,0.74,0.83,0.62,0.74,0.72,0.64,0.55,0.55,0.65,0.77,0.42,0.43,0.51,0.7,0.66,0.69,0.69,0.85,0.76,0.86,0.73,0.68,0.62,0.67,0.64,0.45,0.66,0.53,0.77,0.54\n",
    "])\n",
    "\n",
    "# Convert positive sentiment analysis percentages into binary values\n",
    "# Change the threshold to 0.55 to differentiate between high (1) and low (0) sentiment\n",
    "binary_sentiment = np.where(positive_sentiment > 0.55, 1, 0)\n",
    "\n",
    "# Create and fit the logistic regression model\n",
    "logistic_model = LogisticRegression(solver='lbfgs')\n",
    "logistic_model.fit(binary_sentiment.reshape(-1, 1), match_win)\n",
    "\n",
    "# Calculate odds and probabilities\n",
    "intercept_odds = np.exp(logistic_model.intercept_)\n",
    "win_odds = np.exp(logistic_model.intercept_ + logistic_model.coef_)\n",
    "\n",
    "intercept_prob = intercept_odds / (1 + intercept_odds)\n",
    "win_prob = win_odds / (1 + win_odds)\n",
    "\n",
    "print(\"Intercept odds:\", intercept_odds)\n",
    "print(\"Win odds:\", win_odds)\n",
    "print(\"Intercept probability:\", intercept_prob)\n",
    "print(\"Win probability:\", win_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept odds: [1.28883849]\n",
      "Loss odds: [[0.14925389]]\n",
      "Intercept probability: [0.56309718]\n",
      "Loss probability: [[0.12987025]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Match Win (1 for loss, 0 otherwise)\n",
    "match_loss = np.array([0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1])\n",
    "\n",
    "# Positive Sentiment Analysis Percentage\n",
    "negative_sentiment = np.array([0.67,\t0.5,\t0.73,\t0.72,\t0.89,\t0.71,\t0.75,\t0.76,\t0.88,\t0.74,\t0.71,\t0.75,\t0.54,\t0.46,\t0.75,\t0.82,\t0.44,\t0.46,\t0.71,\t0.75,\t0.72,\t0.85,\t0.56,\t0.68,\t0.68,\t0.44,\t0.7,\t0.72,\t0.77,\t0.78,\t0.75,\t0.53,\t0.74,\t0.76,\t0.75, 0.41,\t0.2,\t0.34,\t0.71,\t0.38,\t0.24,\t0.22,\t0.43,\t0.28,\t0.3,\t0.22,\t0.27,\t0.61,\t0.52,\t0.35,\t0.14,\n",
    "0.3,\t0.5,\t0.4,\t0.31,\t0.26,\t0.17,\t0.38,\t0.26,\t0.28,\t0.36,\t0.45,\t0.45,\t0.35,\t0.23,\t0.58,\t0.57,\t0.49,\t0.3,\t0.34,\t0.31,\t0.31,\t0.15,\t0.24,\t0.14,\t0.27,\t0.32,\t0.38,\t0.33,\t0.36,\t0.55,\t0.34,\t0.47,\t0.23,\t0.46])\n",
    "\n",
    "# Convert positive sentiment analysis percentages into binary values\n",
    "# Change the threshold to 0.55 to differentiate between high (1) and low (0) sentiment\n",
    "binary_sentiment = np.where(negative_sentiment > 0.55, 1, 0)\n",
    "\n",
    "# Create and fit the logistic regression model\n",
    "logistic_model = LogisticRegression(solver='lbfgs')\n",
    "logistic_model.fit(binary_sentiment.reshape(-1, 1), match_loss)\n",
    "\n",
    "# Calculate odds and probabilities\n",
    "intercept_odds = np.exp(logistic_model.intercept_)\n",
    "loss_odds = np.exp(logistic_model.intercept_ + logistic_model.coef_)\n",
    "\n",
    "intercept_prob = intercept_odds / (1 + intercept_odds)\n",
    "loss_prob = loss_odds / (1 + loss_odds)\n",
    "\n",
    "print(\"Intercept odds:\", intercept_odds)\n",
    "print(\"Loss odds:\", loss_odds)\n",
    "print(\"Intercept probability:\", intercept_prob)\n",
    "print(\"Loss probability:\", loss_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for Low PPG, Medium PPG, and High PPG when positive sentiment is 0.6: [[0.25277252 0.45062645 0.29660103]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# High PPG (1), Medium PPG (0), Low PPG (-1)\n",
    "PPG = np.array([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1])\n",
    "\n",
    "# Positive Sentiment Analysis Percentage\n",
    "positive_sentiment = np.array([0.81, 0.64, 0.49, 0.71, 0.6, 0.66, 0.46, 0.51, 0.55, 0.68, 0.53, 0.59, 0.68, 0.55, 0.62, 0.46, 0.5, 0.49, 0.47, 0.54])\n",
    "\n",
    "# Create and fit the logistic regression model\n",
    "logistic_model = LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
    "logistic_model.fit(positive_sentiment.reshape(-1, 1), PPG)\n",
    "\n",
    "# Calculate probabilities\n",
    "probs = logistic_model.predict_proba([[0.55]])\n",
    "\n",
    "print(\"Probabilities for Low PPG, Medium PPG, and High PPG when positive sentiment is 0.6:\", probs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Middle of Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for Low PPG, Medium PPG, and High PPG when positive sentiment is 0.6: [[0.2459022  0.50124686 0.25285093]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# High PPG (1), Medium PPG (0), Low PPG (-1)\n",
    "PPG = np.array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1])\n",
    "\n",
    "# Positive Sentiment Analysis Percentage\n",
    "positive_sentiment = np.array([0.51, 0.59, 0.57, 0.54, 0.52, 0.6, 0.58, 0.54, 0.46, 0.6, 0.44, 0.45, 0.63, 0.23, 0.51, 0.48, 0.45, 0.49, 0.37, 0.39])\n",
    "\n",
    "# Create and fit the logistic regression model\n",
    "logistic_model = LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
    "logistic_model.fit(positive_sentiment.reshape(-1, 1), PPG)\n",
    "\n",
    "# Calculate probabilities\n",
    "probs = logistic_model.predict_proba([[0.55]])\n",
    "\n",
    "print(\"Probabilities for Low PPG, Medium PPG, and High PPG when positive sentiment is 0.6:\", probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept odds: [0.5239536]\n",
      "Win odds: [[0.89409346]]\n",
      "Intercept probability: [0.34381204]\n",
      "Win probability: [[0.47204295]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Match Win (1 for win, 0 otherwise)\n",
    "match_win = np.array([1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0])\n",
    "\n",
    "# Positive Sentiment Analysis Percentage\n",
    "positive_sentiment = np.array([0.53,\t0.32,\t0.51,\t0.69,\t0.8,\t0.66,\t0.59,\t0.64,\t0.5,\t0.62,\t0.69,\t0.67,\t0.52,\t0.38,\t0.44,\t0.42,\t0.63,\t0.63,\t0.72,\t0.56,\t0.5,\t0.55,\t0.58,\t0.51,\t0.58,\t0.69,\t0.33,\t0.62,\t0.57,\t0.55,\t0.63,\t0.51,\t0.23,\t0.18,\t0.13,0.49,\t0.53,\t0.65,\t0.48,\t0.54,\t0.58,\t0.37,\t0.3,\t0.62,\t0.67,\t0.67,\t0.62,\t0.76,\t0.36,\t0.65,\t0.51,\t0.62,\t0.19,\t0.11,\n",
    "0.6,\t0.76,\t0.6,\t0.55,\t0.51,\t0.54,\t0.5,\t0.42,\t0.5,\t0.6,\t0.63,\t0.53,\t0.49,\t0.5,\t0.49,\t0.62,\t0.59,\t0.59,\t0.46,\t0.59,\t0.51,\t0.54,\t0.5,\t0.43,\t0.53,\t0.31,\t0.66,\t0.55,\t0.47,\t0.54,\t0.16,\t0.17,\t0.31,\t0.31])\n",
    "\n",
    "# Convert positive sentiment analysis percentages into binary values\n",
    "# Change the threshold to 0.55 to differentiate between high (1) and low (0) sentiment\n",
    "binary_sentiment = np.where(positive_sentiment > 0.55, 1, 0)\n",
    "\n",
    "# Create and fit the logistic regression model\n",
    "logistic_model = LogisticRegression(solver='lbfgs')\n",
    "logistic_model.fit(binary_sentiment.reshape(-1, 1), match_win)\n",
    "\n",
    "# Calculate odds and probabilities\n",
    "intercept_odds = np.exp(logistic_model.intercept_)\n",
    "win_odds = np.exp(logistic_model.intercept_ + logistic_model.coef_)\n",
    "\n",
    "intercept_prob = intercept_odds / (1 + intercept_odds)\n",
    "win_prob = win_odds / (1 + win_odds)\n",
    "\n",
    "print(\"Intercept odds:\", intercept_odds)\n",
    "print(\"Win odds:\", win_odds)\n",
    "print(\"Intercept probability:\", intercept_prob)\n",
    "print(\"Win probability:\", win_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept odds: [0.66520113]\n",
      "Loss odds: [[0.52566027]]\n",
      "Intercept probability: [0.39947194]\n",
      "Loss probability: [[0.34454608]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Match Win (1 for loss, 0 otherwise)\n",
    "match_loss = np.array([1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,\t1,0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0])\n",
    "# Positive Sentiment Analysis Percentage\n",
    "negative_sentiment = np.array([0.4,\t0.24,\t0.4,\t0.45,\t0.49,\t0.46,\t0.5,\t0.58,\t0.5,\t0.4,\t0.37,\t0.47,\t0.51,\t0.5,\t0.51,\t0.38,\t0.41,\t0.41,\t0.54,\t0.41,\t0.49,\t0.46,\t0.5,\t0.57,\t0.47,\t0.69,\t0.33,\t0.45,\t0.53,\t0.46,\t0.84,\t0.83,\t0.69,\t0.69,0.51,\t0.47,\t0.35,\t0.52,\t0.46,\t0.42,\t0.63,\t0.7,\t0.38,\t0.33,\t0.33,\t0.38,\t0.24,\t0.64,\t0.35,\t0.49,\t0.38,\t0.81,\t0.89,\n",
    "0.47,\t0.68,\t0.49,\t0.31,\t0.2,\t0.34,\t1,\t0.36,\t0.5,\t0.38,\t0.31,\t0.36,\t0.48,\t0.62,\t0.56,\t0.58,\t0.37,\t0.37,\t0.28,\t0.44,\t0.5,\t0.45,\t0.42,\t0.49,\t0.42,\t0.31,\t0.66,\t0.38,\t0.43,\t0.45,\t0.37,\t0.49,\t0.77,\t0.82,\t0.87])\n",
    "\n",
    "# Convert positive sentiment analysis percentages into binary values\n",
    "# Change the threshold to 0.55 to differentiate between high (1) and low (0) sentiment\n",
    "binary_sentiment = np.where(negative_sentiment > 0.55, 1, 0)\n",
    "\n",
    "# Create and fit the logistic regression model\n",
    "logistic_model = LogisticRegression(solver='lbfgs')\n",
    "logistic_model.fit(binary_sentiment.reshape(-1, 1), match_loss)\n",
    "\n",
    "# Calculate odds and probabilities\n",
    "intercept_odds = np.exp(logistic_model.intercept_)\n",
    "loss_odds = np.exp(logistic_model.intercept_ + logistic_model.coef_)\n",
    "\n",
    "intercept_prob = intercept_odds / (1 + intercept_odds)\n",
    "loss_prob = loss_odds / (1 + loss_odds)\n",
    "\n",
    "print(\"Intercept odds:\", intercept_odds)\n",
    "print(\"Loss odds:\", loss_odds)\n",
    "print(\"Intercept probability:\", intercept_prob)\n",
    "print(\"Loss probability:\", loss_prob)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-ienv",
   "language": "python",
   "name": "gpu-ienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
