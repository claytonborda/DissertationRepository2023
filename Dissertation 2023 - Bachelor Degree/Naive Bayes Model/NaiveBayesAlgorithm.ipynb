{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_date_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>language</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-08T08:19:09</td>\n",
       "      <td>993767246437666816</td>\n",
       "      <td>Bayer Leverkusen goalkeeper Bernd Leno will no...</td>\n",
       "      <td>en</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>{\"Neutral\":0.7228581905364990234375,\"Negative\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-02T19:28:00.331000</td>\n",
       "      <td>1013866900772835331</td>\n",
       "      <td>Gary Speed v Blackburn at St James in 2001/02 ...</td>\n",
       "      <td>en</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>{\"Neutral\":0.998256266117095947265625,\"Negativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-09-05T12:54:20.408000</td>\n",
       "      <td>1037323043360657408</td>\n",
       "      <td>@ChelseaFC Don't make him regret it and start ...</td>\n",
       "      <td>en</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>{\"Neutral\":0.912796199321746826171875,\"Negativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-08T10:42:17</td>\n",
       "      <td>993803266323550208</td>\n",
       "      <td>@LiverpoolFF @AnfieldEdition He's a liar, made...</td>\n",
       "      <td>en</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>{\"Neutral\":0.3271420896053314208984375,\"Negati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-08-07T07:29:59.136000</td>\n",
       "      <td>1026732168226267136</td>\n",
       "      <td>@theesk @Everton Didn't realise Kenwright is d...</td>\n",
       "      <td>en</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>{\"Neutral\":0.957906246185302734375,\"Negative\":...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tweet_date_created             tweet_id  \\\n",
       "0         2018-05-08T08:19:09   993767246437666816   \n",
       "1  2018-07-02T19:28:00.331000  1013866900772835331   \n",
       "2  2018-09-05T12:54:20.408000  1037323043360657408   \n",
       "3         2018-05-08T10:42:17   993803266323550208   \n",
       "4  2018-08-07T07:29:59.136000  1026732168226267136   \n",
       "\n",
       "                                          tweet_text language sentiment  \\\n",
       "0  Bayer Leverkusen goalkeeper Bernd Leno will no...       en   NEUTRAL   \n",
       "1  Gary Speed v Blackburn at St James in 2001/02 ...       en   NEUTRAL   \n",
       "2  @ChelseaFC Don't make him regret it and start ...       en   NEUTRAL   \n",
       "3  @LiverpoolFF @AnfieldEdition He's a liar, made...       en  NEGATIVE   \n",
       "4  @theesk @Everton Didn't realise Kenwright is d...       en   NEUTRAL   \n",
       "\n",
       "                                     sentiment_score  \n",
       "0  {\"Neutral\":0.7228581905364990234375,\"Negative\"...  \n",
       "1  {\"Neutral\":0.998256266117095947265625,\"Negativ...  \n",
       "2  {\"Neutral\":0.912796199321746826171875,\"Negativ...  \n",
       "3  {\"Neutral\":0.3271420896053314208984375,\"Negati...  \n",
       "4  {\"Neutral\":0.957906246185302734375,\"Negative\":...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib as plt \n",
    "\n",
    "tweets = pd.read_csv('combined.csv', encoding='utf-8')\n",
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>language</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>993767246437666816</td>\n",
       "      <td>Bayer Leverkusen goalkeeper Bernd Leno will no...</td>\n",
       "      <td>en</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>{\"Neutral\":0.7228581905364990234375,\"Negative\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1013866900772835331</td>\n",
       "      <td>Gary Speed v Blackburn at St James in 2001/02 ...</td>\n",
       "      <td>en</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>{\"Neutral\":0.998256266117095947265625,\"Negativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1037323043360657408</td>\n",
       "      <td>@ChelseaFC Don't make him regret it and start ...</td>\n",
       "      <td>en</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>{\"Neutral\":0.912796199321746826171875,\"Negativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>993803266323550208</td>\n",
       "      <td>@LiverpoolFF @AnfieldEdition He's a liar, made...</td>\n",
       "      <td>en</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>{\"Neutral\":0.3271420896053314208984375,\"Negati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1026732168226267136</td>\n",
       "      <td>@theesk @Everton Didn't realise Kenwright is d...</td>\n",
       "      <td>en</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>{\"Neutral\":0.957906246185302734375,\"Negative\":...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                         tweet_text  \\\n",
       "0   993767246437666816  Bayer Leverkusen goalkeeper Bernd Leno will no...   \n",
       "1  1013866900772835331  Gary Speed v Blackburn at St James in 2001/02 ...   \n",
       "2  1037323043360657408  @ChelseaFC Don't make him regret it and start ...   \n",
       "3   993803266323550208  @LiverpoolFF @AnfieldEdition He's a liar, made...   \n",
       "4  1026732168226267136  @theesk @Everton Didn't realise Kenwright is d...   \n",
       "\n",
       "  language sentiment                                    sentiment_score  \n",
       "0       en   NEUTRAL  {\"Neutral\":0.7228581905364990234375,\"Negative\"...  \n",
       "1       en   NEUTRAL  {\"Neutral\":0.998256266117095947265625,\"Negativ...  \n",
       "2       en   NEUTRAL  {\"Neutral\":0.912796199321746826171875,\"Negativ...  \n",
       "3       en  NEGATIVE  {\"Neutral\":0.3271420896053314208984375,\"Negati...  \n",
       "4       en   NEUTRAL  {\"Neutral\":0.957906246185302734375,\"Negative\":...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets.drop(['tweet_date_created'], axis=1)\n",
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 762643 duplicate tweet ids. Removing duplicates...\n"
     ]
    }
   ],
   "source": [
    "duplicates = tweets[tweets.duplicated(subset=['tweet_id'], keep=False)]\n",
    "\n",
    "if not duplicates.empty:\n",
    "    print(f\"Found {len(duplicates)} duplicate tweet ids. Removing duplicates...\")\n",
    "    tweets.drop_duplicates(subset=['tweet_id'], inplace=True)\n",
    "else:\n",
    "    print(\"No duplicate tweet ids found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>language</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>993767246437666816</td>\n",
       "      <td>Bayer Leverkusen goalkeeper Bernd Leno will no...</td>\n",
       "      <td>en</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1013866900772835331</td>\n",
       "      <td>Gary Speed v Blackburn at St James in 2001/02 ...</td>\n",
       "      <td>en</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1037323043360657408</td>\n",
       "      <td>@ChelseaFC Don't make him regret it and start ...</td>\n",
       "      <td>en</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>993803266323550208</td>\n",
       "      <td>@LiverpoolFF @AnfieldEdition He's a liar, made...</td>\n",
       "      <td>en</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1026732168226267136</td>\n",
       "      <td>@theesk @Everton Didn't realise Kenwright is d...</td>\n",
       "      <td>en</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                         tweet_text  \\\n",
       "0   993767246437666816  Bayer Leverkusen goalkeeper Bernd Leno will no...   \n",
       "1  1013866900772835331  Gary Speed v Blackburn at St James in 2001/02 ...   \n",
       "2  1037323043360657408  @ChelseaFC Don't make him regret it and start ...   \n",
       "3   993803266323550208  @LiverpoolFF @AnfieldEdition He's a liar, made...   \n",
       "4  1026732168226267136  @theesk @Everton Didn't realise Kenwright is d...   \n",
       "\n",
       "  language sentiment  \n",
       "0       en   NEUTRAL  \n",
       "1       en   NEUTRAL  \n",
       "2       en   NEUTRAL  \n",
       "3       en  NEGATIVE  \n",
       "4       en   NEUTRAL  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets.drop(['sentiment_score'], axis=1)\n",
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_id      0\n",
      "tweet_text    0\n",
      "language      0\n",
      "sentiment     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "tweets = tweets.dropna()\n",
    "print(tweets.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All values in the 'language' column are 'en'\n"
     ]
    }
   ],
   "source": [
    "all_english = (tweets['language'] == 'en').all()\n",
    "\n",
    "\n",
    "if all_english:\n",
    "    print(\"All values in the 'language' column are 'en'\")\n",
    "else:\n",
    "    print(\"Not all values in the 'language' column are 'en'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>993767246437666816</td>\n",
       "      <td>Bayer Leverkusen goalkeeper Bernd Leno will no...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1013866900772835331</td>\n",
       "      <td>Gary Speed v Blackburn at St James in 2001/02 ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1037323043360657408</td>\n",
       "      <td>@ChelseaFC Don't make him regret it and start ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>993803266323550208</td>\n",
       "      <td>@LiverpoolFF @AnfieldEdition He's a liar, made...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1026732168226267136</td>\n",
       "      <td>@theesk @Everton Didn't realise Kenwright is d...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                         tweet_text  \\\n",
       "0   993767246437666816  Bayer Leverkusen goalkeeper Bernd Leno will no...   \n",
       "1  1013866900772835331  Gary Speed v Blackburn at St James in 2001/02 ...   \n",
       "2  1037323043360657408  @ChelseaFC Don't make him regret it and start ...   \n",
       "3   993803266323550208  @LiverpoolFF @AnfieldEdition He's a liar, made...   \n",
       "4  1026732168226267136  @theesk @Everton Didn't realise Kenwright is d...   \n",
       "\n",
       "  sentiment  \n",
       "0   NEUTRAL  \n",
       "1   NEUTRAL  \n",
       "2   NEUTRAL  \n",
       "3  NEGATIVE  \n",
       "4   NEUTRAL  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets.drop(['language'], axis=1)\n",
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bayer Leverkusen goalkeeper Bernd Leno will no...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gary Speed v Blackburn at St James in 2001/02 ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ChelseaFC Don't make him regret it and start ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@LiverpoolFF @AnfieldEdition He's a liar, made...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@theesk @Everton Didn't realise Kenwright is d...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text sentiment\n",
       "0  Bayer Leverkusen goalkeeper Bernd Leno will no...   NEUTRAL\n",
       "1  Gary Speed v Blackburn at St James in 2001/02 ...   NEUTRAL\n",
       "2  @ChelseaFC Don't make him regret it and start ...   NEUTRAL\n",
       "3  @LiverpoolFF @AnfieldEdition He's a liar, made...  NEGATIVE\n",
       "4  @theesk @Everton Didn't realise Kenwright is d...   NEUTRAL"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets.drop(['tweet_id'], axis=1)\n",
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique sentiment values in the 'sentiment' column:\n",
      "NEUTRAL\n",
      "NEGATIVE\n",
      "POSITIVE\n",
      "MIXED\n"
     ]
    }
   ],
   "source": [
    "# Get all unique sentiment values in the 'sentiment' column\n",
    "unique_sentiments = tweets['sentiment'].unique()\n",
    "\n",
    "# Print the unique sentiment values\n",
    "print(\"Unique sentiment values in the 'sentiment' column:\")\n",
    "for sentiment in unique_sentiments:\n",
    "    print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          0\n",
      "1          0\n",
      "2          0\n",
      "3         -1\n",
      "4          0\n",
      "          ..\n",
      "5393957    0\n",
      "5393958   -1\n",
      "5393959    0\n",
      "5393960    0\n",
      "5393961    0\n",
      "Name: sentiment_values, Length: 5012534, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define a dictionary that maps sentiment labels to numeric values\n",
    "sentiment_map = {\"NEUTRAL\": 0, \"POSITIVE\": 1, \"MIXED\": 2, \"NEGATIVE\": -1}\n",
    "\n",
    "# Map the sentiment labels to their numeric values\n",
    "tweets['sentiment_values'] = tweets['sentiment'].map(sentiment_map)\n",
    "\n",
    "# Print the new column that contains the mapped values\n",
    "print(tweets['sentiment_values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bayer Leverkusen goalkeeper Bernd Leno will no...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gary Speed v Blackburn at St James in 2001/02 ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ChelseaFC Don't make him regret it and start ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@LiverpoolFF @AnfieldEdition He's a liar, made...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@theesk @Everton Didn't realise Kenwright is d...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text sentiment  \\\n",
       "0  Bayer Leverkusen goalkeeper Bernd Leno will no...   NEUTRAL   \n",
       "1  Gary Speed v Blackburn at St James in 2001/02 ...   NEUTRAL   \n",
       "2  @ChelseaFC Don't make him regret it and start ...   NEUTRAL   \n",
       "3  @LiverpoolFF @AnfieldEdition He's a liar, made...  NEGATIVE   \n",
       "4  @theesk @Everton Didn't realise Kenwright is d...   NEUTRAL   \n",
       "\n",
       "   sentiment_values  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                -1  \n",
       "4                 0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bayer Leverkusen goalkeeper Bernd Leno will no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gary Speed v Blackburn at St James in 2001/02 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ChelseaFC Don't make him regret it and start ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@LiverpoolFF @AnfieldEdition He's a liar, made...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@theesk @Everton Didn't realise Kenwright is d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  sentiment_values\n",
       "0  Bayer Leverkusen goalkeeper Bernd Leno will no...                 0\n",
       "1  Gary Speed v Blackburn at St James in 2001/02 ...                 0\n",
       "2  @ChelseaFC Don't make him regret it and start ...                 0\n",
       "3  @LiverpoolFF @AnfieldEdition He's a liar, made...                -1\n",
       "4  @theesk @Everton Didn't realise Kenwright is d...                 0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets.drop(['sentiment'], axis=1)\n",
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bayer Leverkusen goalkeeper Bernd Leno will no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gary Speed v Blackburn at St James in 2001/02 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ChelseaFC Don't make him regret it and start ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@LiverpoolFF @AnfieldEdition He's a liar, made...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@theesk @Everton Didn't realise Kenwright is d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  sentiment_values\n",
       "0  Bayer Leverkusen goalkeeper Bernd Leno will no...                 0\n",
       "1  Gary Speed v Blackburn at St James in 2001/02 ...                 0\n",
       "2  @ChelseaFC Don't make him regret it and start ...                 0\n",
       "3  @LiverpoolFF @AnfieldEdition He's a liar, made...                 3\n",
       "4  @theesk @Everton Didn't realise Kenwright is d...                 0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['sentiment_values']=tweets['sentiment_values'].replace(-1, 3)\n",
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          tweet_text  sentiment_values\n",
      "0  Bayer Leverkusen goalkeeper Bernd Leno will no...                 0\n",
      "1  Gary Speed v Blackburn at St James in 2001/02 ...                 0\n",
      "2  @ChelseaFC Don't make him regret it and start ...                 0\n",
      "3  @LiverpoolFF @AnfieldEdition He's a liar, made...                 3\n",
      "4  @theesk @Everton Didn't realise Kenwright is d...                 0\n"
     ]
    }
   ],
   "source": [
    "# Find the indices of rows with Mixed sentiment\n",
    "mixed_indices = tweets[tweets['sentiment_values'] == 2].index\n",
    "\n",
    "# Delete the rows with Mixed sentiment\n",
    "tweets = tweets.drop(mixed_indices)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(tweets.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of positive tagged tweets is: 1070334\n",
      "No of negative tagged tweets is: 354501\n",
      "No of neutral tagged tweets is: 3549918\n",
      "No of mixed tagged tweets is: 0\n"
     ]
    }
   ],
   "source": [
    "positive_tweets = tweets[tweets['sentiment_values'] == 1]\n",
    "negative_tweets = tweets[tweets['sentiment_values'] == 3]\n",
    "neutral_tweets = tweets[tweets['sentiment_values'] == 0]\n",
    "mixed_tweets = tweets[tweets['sentiment_values'] == 2]\n",
    "\n",
    "print('No of positive tagged tweets is: {}'.format(len(positive_tweets)))\n",
    "print('No of negative tagged tweets is: {}'.format(len(negative_tweets)))\n",
    "print('No of neutral tagged tweets is: {}'.format(len(neutral_tweets)))\n",
    "print('No of mixed tagged tweets is: {}'.format(len(mixed_tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of positive tagged tweets is: 354501\n",
      "No of negative tagged tweets is: 354501\n",
      "No of neutral tagged tweets is: 354501\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Shuffle the DataFrame to ensure that the downsampling is random\n",
    "tweets = tweets.sample(frac=1, random_state=42)\n",
    "\n",
    "# Count the number of tweets in each sentiment class\n",
    "counts = tweets['sentiment_values'].value_counts()\n",
    "\n",
    "# Find the smallest class size\n",
    "smallest_size = counts.min()\n",
    "\n",
    "# Downsample each class to the smallest size\n",
    "positive_tweets = tweets[tweets['sentiment_values'] == 1].sample(n=smallest_size, random_state=42)\n",
    "negative_tweets = tweets[tweets['sentiment_values'] == 3].sample(n=smallest_size, random_state=42)\n",
    "neutral_tweets = tweets[tweets['sentiment_values'] == 0].sample(n=smallest_size, random_state=42)\n",
    "\n",
    "# Concatenate the downsampled DataFrames\n",
    "tweets = pd.concat([positive_tweets, negative_tweets, neutral_tweets], ignore_index=True)\n",
    "\n",
    "# Print the new counts of tweets in each class\n",
    "print('No of positive tagged tweets is: {}'.format(len(tweets[tweets['sentiment_values'] == 1])))\n",
    "print('No of negative tagged tweets is: {}'.format(len(tweets[tweets['sentiment_values'] == 3])))\n",
    "print('No of neutral tagged tweets is: {}'.format(len(tweets[tweets['sentiment_values'] == 0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['tweet_text'] = tweets['tweet_text'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stopword = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "urlPattern = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
    "userPattern = '@[^\\s]+'\n",
    "some = 'amp,today,tomorrow,going,girl'\n",
    "\n",
    "def process_tweets(tweet):\n",
    "  # Lower Casing\n",
    "    tweet = re.sub(r\"he's\", \"he is\", tweet)\n",
    "    tweet = re.sub(r\"there's\", \"there is\", tweet)\n",
    "    tweet = re.sub(r\"We're\", \"We are\", tweet)\n",
    "    tweet = re.sub(r\"That's\", \"That is\", tweet)\n",
    "    tweet = re.sub(r\"won't\", \"will not\", tweet)\n",
    "    tweet = re.sub(r\"they're\", \"they are\", tweet)\n",
    "    tweet = re.sub(r\"Can't\", \"Cannot\", tweet)\n",
    "    tweet = re.sub(r\"wasn't\", \"was not\", tweet)\n",
    "    tweet = re.sub(r\"don\\x89Ûªt\", \"do not\", tweet)\n",
    "    tweet = re.sub(r\"aren't\", \"are not\", tweet)\n",
    "    tweet = re.sub(r\"isn't\", \"is not\", tweet)\n",
    "    tweet = re.sub(r\"What's\", \"What is\", tweet)\n",
    "    tweet = re.sub(r\"haven't\", \"have not\", tweet)\n",
    "    tweet = re.sub(r\"hasn't\", \"has not\", tweet)\n",
    "    tweet = re.sub(r\"There's\", \"There is\", tweet)\n",
    "    tweet = re.sub(r\"He's\", \"He is\", tweet)\n",
    "    tweet = re.sub(r\"It's\", \"It is\", tweet)\n",
    "    tweet = re.sub(r\"You're\", \"You are\", tweet)\n",
    "    tweet = re.sub(r\"I'M\", \"I am\", tweet)\n",
    "    tweet = re.sub(r\"shouldn't\", \"should not\", tweet)\n",
    "    tweet = re.sub(r\"wouldn't\", \"would not\", tweet)\n",
    "    tweet = re.sub(r\"i'm\", \"I am\", tweet)\n",
    "    tweet = re.sub(r\"I\\x89Ûªm\", \"I am\", tweet)\n",
    "    tweet = re.sub(r\"I'm\", \"I am\", tweet)\n",
    "    tweet = re.sub(r\"Isn't\", \"is not\", tweet)\n",
    "    tweet = re.sub(r\"Here's\", \"Here is\", tweet)\n",
    "    tweet = re.sub(r\"you've\", \"you have\", tweet)\n",
    "    tweet = re.sub(r\"you\\x89Ûªve\", \"you have\", tweet)\n",
    "    tweet = re.sub(r\"we're\", \"we are\", tweet)\n",
    "    tweet = re.sub(r\"what's\", \"what is\", tweet)\n",
    "    tweet = re.sub(r\"couldn't\", \"could not\", tweet)\n",
    "    tweet = re.sub(r\"we've\", \"we have\", tweet)\n",
    "    tweet = re.sub(r\"it\\x89Ûªs\", \"it is\", tweet)\n",
    "    tweet = re.sub(r\"doesn\\x89Ûªt\", \"does not\", tweet)\n",
    "    tweet = re.sub(r\"It\\x89Ûªs\", \"It is\", tweet)\n",
    "    tweet = re.sub(r\"Here\\x89Ûªs\", \"Here is\", tweet)\n",
    "    tweet = re.sub(r\"who's\", \"who is\", tweet)\n",
    "    tweet = re.sub(r\"I\\x89Ûªve\", \"I have\", tweet)\n",
    "    tweet = re.sub(r\"y'all\", \"you all\", tweet)\n",
    "    tweet = re.sub(r\"can\\x89Ûªt\", \"cannot\", tweet)\n",
    "    tweet = re.sub(r\"would've\", \"would have\", tweet)\n",
    "    tweet = re.sub(r\"it'll\", \"it will\", tweet)\n",
    "    tweet = re.sub(r\"we'll\", \"we will\", tweet)\n",
    "    tweet = re.sub(r\"wouldn\\x89Ûªt\", \"would not\", tweet)\n",
    "    tweet = re.sub(r\"We've\", \"We have\", tweet)\n",
    "    tweet = re.sub(r\"he'll\", \"he will\", tweet)\n",
    "    tweet = re.sub(r\"Y'all\", \"You all\", tweet)\n",
    "    tweet = re.sub(r\"Weren't\", \"Were not\", tweet)\n",
    "    tweet = re.sub(r\"Didn't\", \"Did not\", tweet)\n",
    "    tweet = re.sub(r\"they'll\", \"they will\", tweet)\n",
    "    tweet = re.sub(r\"they'd\", \"they would\", tweet)\n",
    "    tweet = re.sub(r\"DON'T\", \"DO NOT\", tweet)\n",
    "    tweet = re.sub(r\"That\\x89Ûªs\", \"That is\", tweet)\n",
    "    tweet = re.sub(r\"they've\", \"they have\", tweet)\n",
    "    tweet = re.sub(r\"i'd\", \"I would\", tweet)\n",
    "    tweet = re.sub(r\"should've\", \"should have\", tweet)\n",
    "    tweet = re.sub(r\"You\\x89Ûªre\", \"You are\", tweet)\n",
    "    tweet = re.sub(r\"where's\", \"where is\", tweet)\n",
    "    tweet = re.sub(r\"Don\\x89Ûªt\", \"Do not\", tweet)\n",
    "    tweet = re.sub(r\"we'd\", \"we would\", tweet)\n",
    "    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n",
    "    tweet = re.sub(r\"weren't\", \"were not\", tweet)\n",
    "    tweet = re.sub(r\"They're\", \"They are\", tweet)\n",
    "    tweet = re.sub(r\"Can\\x89Ûªt\", \"Cannot\", tweet)\n",
    "    tweet = re.sub(r\"you\\x89Ûªll\", \"you will\", tweet)\n",
    "    tweet = re.sub(r\"I\\x89Ûªd\", \"I would\", tweet)\n",
    "    tweet = re.sub(r\"let's\", \"let us\", tweet)\n",
    "    tweet = re.sub(r\"it's\", \"it is\", tweet)\n",
    "    tweet = re.sub(r\"can't\", \"cannot\", tweet)\n",
    "    tweet = re.sub(r\"don't\", \"do not\", tweet)\n",
    "    tweet = re.sub(r\"you're\", \"you are\", tweet)\n",
    "    tweet = re.sub(r\"i've\", \"I have\", tweet)\n",
    "    tweet = re.sub(r\"that's\", \"that is\", tweet)\n",
    "    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n",
    "    tweet = re.sub(r\"doesn't\", \"does not\", tweet)\n",
    "    tweet = re.sub(r\"i'd\", \"I would\", tweet)\n",
    "    tweet = re.sub(r\"didn't\", \"did not\", tweet)\n",
    "    tweet = re.sub(r\"ain't\", \"am not\", tweet)\n",
    "    tweet = re.sub(r\"you'll\", \"you will\", tweet)\n",
    "    tweet = re.sub(r\"I've\", \"I have\", tweet)\n",
    "    tweet = re.sub(r\"Don't\", \"do not\", tweet)\n",
    "    tweet = re.sub(r\"I'll\", \"I will\", tweet)\n",
    "    tweet = re.sub(r\"I'd\", \"I would\", tweet)\n",
    "    tweet = re.sub(r\"Let's\", \"Let us\", tweet)\n",
    "    tweet = re.sub(r\"you'd\", \"You would\", tweet)\n",
    "    tweet = re.sub(r\"It's\", \"It is\", tweet)\n",
    "    tweet = re.sub(r\"Ain't\", \"am not\", tweet)\n",
    "    tweet = re.sub(r\"Haven't\", \"Have not\", tweet)\n",
    "    tweet = re.sub(r\"Could've\", \"Could have\", tweet)\n",
    "    tweet = re.sub(r\"youve\", \"you have\", tweet)  \n",
    "    tweet = re.sub(r\"donå«t\", \"do not\", tweet)  \n",
    "    \n",
    "    tweet = re.sub(r\"some1\", \"someone\", tweet)\n",
    "    tweet = re.sub(r\"yrs\", \"years\", tweet)\n",
    "    tweet = re.sub(r\"hrs\", \"hours\", tweet)\n",
    "    tweet = re.sub(r\"2morow|2moro\", \"tomorrow\", tweet)\n",
    "    tweet = re.sub(r\"2day\", \"today\", tweet)\n",
    "    tweet = re.sub(r\"4got|4gotten\", \"forget\", tweet)\n",
    "    tweet = re.sub(r\"b-day|bday\", \"b-day\", tweet)\n",
    "    tweet = re.sub(r\"mother's\", \"mother\", tweet)\n",
    "    tweet = re.sub(r\"mom's\", \"mom\", tweet)\n",
    "    tweet = re.sub(r\"dad's\", \"dad\", tweet)\n",
    "    tweet = re.sub(r\"hahah|hahaha|hahahaha\", \"haha\", tweet)\n",
    "    tweet = re.sub(r\"lmao|lolz|rofl\", \"lol\", tweet)\n",
    "    tweet = re.sub(r\"thanx|thnx\", \"thanks\", tweet)\n",
    "    tweet = re.sub(r\"goood\", \"good\", tweet)\n",
    "    tweet = re.sub(r\"some1\", \"someone\", tweet)\n",
    "    tweet = re.sub(r\"some1\", \"someone\", tweet)\n",
    "    tweet = tweet.lower()\n",
    "    tweet=tweet[1:]\n",
    "\n",
    "    # Removing all URls \n",
    "    tweet = re.sub(urlPattern,'',tweet)\n",
    "    # Removing all @username.\n",
    "    tweet = re.sub(userPattern,'', tweet) \n",
    "    #remove some words\n",
    "    tweet= re.sub(some,'',tweet)\n",
    "    #Remove punctuations\n",
    "    tweet = tweet.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "    #tokenizing words\n",
    "    tokens = word_tokenize(tweet)\n",
    "    #tokens = [w for w in tokens if len(w)>2]\n",
    "    #Removing Stop Words\n",
    "    final_tokens = [w for w in tokens if w not in stopword]\n",
    "    #reducing a word to its word stem \n",
    "    wordLemm = WordNetLemmatizer()\n",
    "    finalwords=[]\n",
    "    for w in final_tokens:\n",
    "      if len(w)>1:\n",
    "        word = wordLemm.lemmatize(w)\n",
    "        finalwords.append(word)\n",
    "    return ' '.join(finalwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviations = {\n",
    "    \"$\" : \" dollar \",\n",
    "    \"€\" : \" euro \",\n",
    "    \"4ao\" : \"for adults only\",\n",
    "    \"a.m\" : \"before midday\",\n",
    "    \"a3\" : \"anytime anywhere anyplace\",\n",
    "    \"aamof\" : \"as a matter of fact\",\n",
    "    \"acct\" : \"account\",\n",
    "    \"adih\" : \"another day in hell\",\n",
    "    \"afaic\" : \"as far as i am concerned\",\n",
    "    \"afaict\" : \"as far as i can tell\",\n",
    "    \"afaik\" : \"as far as i know\",\n",
    "    \"afair\" : \"as far as i remember\",\n",
    "    \"afk\" : \"away from keyboard\",\n",
    "    \"app\" : \"application\",\n",
    "    \"approx\" : \"approximately\",\n",
    "    \"apps\" : \"applications\",\n",
    "    \"asap\" : \"as soon as possible\",\n",
    "    \"asl\" : \"age, sex, location\",\n",
    "    \"atk\" : \"at the keyboard\",\n",
    "    \"ave.\" : \"avenue\",\n",
    "    \"aymm\" : \"are you my mother\",\n",
    "    \"ayor\" : \"at your own risk\", \n",
    "    \"b&b\" : \"bed and breakfast\",\n",
    "    \"b+b\" : \"bed and breakfast\",\n",
    "    \"b.c\" : \"before christ\",\n",
    "    \"b2b\" : \"business to business\",\n",
    "    \"b2c\" : \"business to customer\",\n",
    "    \"b4\" : \"before\",\n",
    "    \"b4n\" : \"bye for now\",\n",
    "    \"b@u\" : \"back at you\",\n",
    "    \"bae\" : \"before anyone else\",\n",
    "    \"bak\" : \"back at keyboard\",\n",
    "    \"bbbg\" : \"bye bye be good\",\n",
    "    \"bbc\" : \"british broadcasting corporation\",\n",
    "    \"bbias\" : \"be back in a second\",\n",
    "    \"bbl\" : \"be back later\",\n",
    "    \"bbs\" : \"be back soon\",\n",
    "    \"be4\" : \"before\",\n",
    "    \"bfn\" : \"bye for now\",\n",
    "    \"blvd\" : \"boulevard\",\n",
    "    \"bout\" : \"about\",\n",
    "    \"brb\" : \"be right back\",\n",
    "    \"bros\" : \"brothers\",\n",
    "    \"brt\" : \"be right there\",\n",
    "    \"bsaaw\" : \"big smile and a wink\",\n",
    "    \"btw\" : \"by the way\",\n",
    "    \"bwl\" : \"bursting with laughter\",\n",
    "    \"c/o\" : \"care of\",\n",
    "    \"cet\" : \"central european time\",\n",
    "    \"cf\" : \"compare\",\n",
    "    \"cia\" : \"central intelligence agency\",\n",
    "    \"csl\" : \"can not stop laughing\",\n",
    "    \"cu\" : \"see you\",\n",
    "    \"cul8r\" : \"see you later\",\n",
    "    \"cv\" : \"curriculum vitae\",\n",
    "    \"cwot\" : \"complete waste of time\",\n",
    "    \"cya\" : \"see you\",\n",
    "    \"cyt\" : \"see you tomorrow\",\n",
    "    \"dae\" : \"does anyone else\",\n",
    "    \"dbmib\" : \"do not bother me i am busy\",\n",
    "    \"diy\" : \"do it yourself\",\n",
    "    \"dm\" : \"direct message\",\n",
    "    \"dwh\" : \"during work hours\",\n",
    "    \"e123\" : \"easy as one two three\",\n",
    "    \"eet\" : \"eastern european time\",\n",
    "    \"eg\" : \"example\",\n",
    "    \"embm\" : \"early morning business meeting\",\n",
    "    \"encl\" : \"enclosed\",\n",
    "    \"encl.\" : \"enclosed\",\n",
    "    \"etc\" : \"and so on\",\n",
    "    \"faq\" : \"frequently asked questions\",\n",
    "    \"fawc\" : \"for anyone who cares\",\n",
    "    \"fb\" : \"facebook\",\n",
    "    \"fc\" : \"fingers crossed\",\n",
    "    \"fig\" : \"figure\",\n",
    "    \"fimh\" : \"forever in my heart\", \n",
    "    \"ft.\" : \"feet\",\n",
    "    \"ft\" : \"featuring\",\n",
    "    \"ftl\" : \"for the loss\",\n",
    "    \"ftw\" : \"for the win\",\n",
    "    \"fwiw\" : \"for what it is worth\",\n",
    "    \"fyi\" : \"for your information\",\n",
    "    \"g9\" : \"genius\",\n",
    "    \"gahoy\" : \"get a hold of yourself\",\n",
    "    \"gal\" : \"get a life\",\n",
    "    \"gcse\" : \"general certificate of secondary education\",\n",
    "    \"gfn\" : \"gone for now\",\n",
    "    \"gg\" : \"good game\",\n",
    "    \"gl\" : \"good luck\",\n",
    "    \"glhf\" : \"good luck have fun\",\n",
    "    \"gmt\" : \"greenwich mean time\",\n",
    "    \"gmta\" : \"great minds think alike\",\n",
    "    \"gn\" : \"good night\",\n",
    "    \"g.o.a.t\" : \"greatest of all time\",\n",
    "    \"goat\" : \"greatest of all time\",\n",
    "    \"goi\" : \"get over it\",\n",
    "    \"gps\" : \"global positioning system\",\n",
    "    \"gr8\" : \"great\",\n",
    "    \"gratz\" : \"congratulations\",\n",
    "    \"gyal\" : \"girl\",\n",
    "    \"h&c\" : \"hot and cold\",\n",
    "    \"hp\" : \"horsepower\",\n",
    "    \"hr\" : \"hour\",\n",
    "    \"hrh\" : \"his royal highness\",\n",
    "    \"ht\" : \"height\",\n",
    "    \"ibrb\" : \"i will be right back\",\n",
    "    \"ic\" : \"i see\",\n",
    "    \"icq\" : \"i seek you\",\n",
    "    \"icymi\" : \"in case you missed it\",\n",
    "    \"idc\" : \"i do not care\",\n",
    "    \"idgadf\" : \"i do not give a damn fuck\",\n",
    "    \"idgaf\" : \"i do not give a fuck\",\n",
    "    \"idk\" : \"i do not know\",\n",
    "    \"ie\" : \"that is\",\n",
    "    \"i.e\" : \"that is\",\n",
    "    \"ifyp\" : \"i feel your pain\",\n",
    "    \"IG\" : \"instagram\",\n",
    "    \"iirc\" : \"if i remember correctly\",\n",
    "    \"ilu\" : \"i love you\",\n",
    "    \"ily\" : \"i love you\",\n",
    "    \"imho\" : \"in my humble opinion\",\n",
    "    \"imo\" : \"in my opinion\",\n",
    "    \"imu\" : \"i miss you\",\n",
    "    \"iow\" : \"in other words\",\n",
    "    \"irl\" : \"in real life\",\n",
    "    \"j4f\" : \"just for fun\",\n",
    "    \"jic\" : \"just in case\",\n",
    "    \"jk\" : \"just kidding\",\n",
    "    \"jsyk\" : \"just so you know\",\n",
    "    \"l8r\" : \"later\",\n",
    "    \"lb\" : \"pound\",\n",
    "    \"lbs\" : \"pounds\",\n",
    "    \"ldr\" : \"long distance relationship\",\n",
    "    \"lmao\" : \"laugh my ass off\",\n",
    "    \"lmfao\" : \"laugh my fucking ass off\",\n",
    "    \"lol\" : \"laughing out loud\",\n",
    "    \"ltd\" : \"limited\",\n",
    "    \"ltns\" : \"long time no see\",\n",
    "    \"m8\" : \"mate\",\n",
    "    \"mf\" : \"motherfucker\",\n",
    "    \"mfs\" : \"motherfuckers\",\n",
    "    \"mfw\" : \"my face when\",\n",
    "    \"mofo\" : \"motherfucker\",\n",
    "    \"mph\" : \"miles per hour\",\n",
    "    \"mr\" : \"mister\",\n",
    "    \"mrw\" : \"my reaction when\",\n",
    "    \"ms\" : \"miss\",\n",
    "    \"mte\" : \"my thoughts exactly\",\n",
    "    \"nagi\" : \"not a good idea\",\n",
    "    \"nbc\" : \"national broadcasting company\",\n",
    "    \"nbd\" : \"not big deal\",\n",
    "    \"nfs\" : \"not for sale\",\n",
    "    \"ngl\" : \"not going to lie\",\n",
    "    \"nhs\" : \"national health service\",\n",
    "    \"nrn\" : \"no reply necessary\",\n",
    "    \"nsfl\" : \"not safe for life\",\n",
    "    \"nsfw\" : \"not safe for work\",\n",
    "    \"nth\" : \"nice to have\",\n",
    "    \"nvr\" : \"never\",\n",
    "    \"nyc\" : \"new york city\",\n",
    "    \"oc\" : \"original content\",\n",
    "    \"og\" : \"original\",\n",
    "    \"ohp\" : \"overhead projector\",\n",
    "    \"oic\" : \"oh i see\",\n",
    "    \"omdb\" : \"over my dead body\",\n",
    "    \"omg\" : \"oh my god\",\n",
    "    \"omw\" : \"on my way\",\n",
    "    \"p.a\" : \"per annum\",\n",
    "    \"p.m\" : \"after midday\",\n",
    "    \"pm\" : \"prime minister\",\n",
    "    \"poc\" : \"people of color\",\n",
    "    \"pov\" : \"point of view\",\n",
    "    \"pp\" : \"pages\",\n",
    "    \"ppl\" : \"people\",\n",
    "    \"prw\" : \"parents are watching\",\n",
    "    \"ps\" : \"postscript\",\n",
    "    \"pt\" : \"point\",\n",
    "    \"ptb\" : \"please text back\",\n",
    "    \"pto\" : \"please turn over\",\n",
    "    \"qpsa\" : \"what happens\", \n",
    "    \"ratchet\" : \"rude\",\n",
    "    \"rbtl\" : \"read between the lines\",\n",
    "    \"rlrt\" : \"real life retweet\", \n",
    "    \"rofl\" : \"rolling on the floor laughing\",\n",
    "    \"roflol\" : \"rolling on the floor laughing out loud\",\n",
    "    \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n",
    "    \"rt\" : \"retweet\",\n",
    "    \"ruok\" : \"are you ok\",\n",
    "    \"sfw\" : \"safe for work\",\n",
    "     \"sk8\" : \"skate\",\n",
    "    \"smh\" : \"shake my head\",\n",
    "    \"sq\" : \"square\",\n",
    "    \"srsly\" : \"seriously\", \n",
    "    \"ssdd\" : \"same stuff different day\",\n",
    "    \"tbh\" : \"to be honest\",\n",
    "    \"tbs\" : \"tablespooful\",\n",
    "    \"tbsp\" : \"tablespooful\",\n",
    "    \"tfw\" : \"that feeling when\",\n",
    "    \"thks\" : \"thank you\",\n",
    "    \"tho\" : \"though\",\n",
    "    \"thx\" : \"thank you\",\n",
    "    \"tia\" : \"thanks in advance\",\n",
    "    \"til\" : \"today i learned\",\n",
    "    \"tl;dr\" : \"too long i did not read\",\n",
    "    \"tldr\" : \"too long i did not read\",\n",
    "    \"tmb\" : \"tweet me back\",\n",
    "    \"tntl\" : \"trying not to laugh\",\n",
    "    \"ttyl\" : \"talk to you later\",\n",
    "    \"u\" : \"you\",\n",
    "    \"u2\" : \"you too\",\n",
    "    \"u4e\" : \"yours for ever\",\n",
    "    \"utc\" : \"coordinated universal time\",\n",
    "    \"w/\" : \"with\",\n",
    "    \"w/o\" : \"without\",\n",
    "    \"w8\" : \"wait\",\n",
    "    \"wassup\" : \"what is up\",\n",
    "    \"wb\" : \"welcome back\",\n",
    "    \"wtf\" : \"what the fuck\",\n",
    "    \"wtg\" : \"way to go\",\n",
    "    \"wtpa\" : \"where the party at\",\n",
    "    \"wuf\" : \"where are you from\",\n",
    "    \"wuzup\" : \"what is up\",\n",
    "    \"wywh\" : \"wish you were here\",\n",
    "    \"yd\" : \"yard\",\n",
    "    \"ygtr\" : \"you got that right\",\n",
    "    \"ynk\" : \"you never know\",\n",
    "    \"zzz\" : \"sleeping bored and tired\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_abbrev_in_text(tweets):\n",
    "    t = []\n",
    "    words = tweets.split() \n",
    "    t = [abbreviations[w.lower()] if w.lower() in abbreviations.keys() else w for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove mentions\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Remove hashtags\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove whitespace\n",
    "    text = text.strip()\n",
    "    # Tokenize the text\n",
    "    text = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    text = set(stopwords.words('english'))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Apply the preprocessing function to the 'text' column\n",
    "tweets['processed_text'] = tweets['tweet_text'].apply(preprocess_text)\n",
    "\n",
    "tweets =  shuffle(tweets).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment_values</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Its an absolute disgrace @Arsenal that this m...</td>\n",
       "      <td>3</td>\n",
       "      <td>its an absolute disgrace  that this man is all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Think can believe Jorgensen is decent .@premie...</td>\n",
       "      <td>0</td>\n",
       "      <td>think can believe jorgensen is decent  standar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@refmillerafc @CheckatradeTrpy @Arsenal Can't ...</td>\n",
       "      <td>3</td>\n",
       "      <td>cant wait tbh mate shame we didnt get a nice l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@DanielPoynter9 @LFC Not judging at all! I hop...</td>\n",
       "      <td>1</td>\n",
       "      <td>not judging at all i hope it was out of passio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@BBCMOTD Best game: France - Argentina 4-3\\n\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>best game france  argentina 43\\n\\nbest goal be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  sentiment_values  \\\n",
       "0  Its an absolute disgrace @Arsenal that this m...                 3   \n",
       "1  Think can believe Jorgensen is decent .@premie...                 0   \n",
       "2  @refmillerafc @CheckatradeTrpy @Arsenal Can't ...                 3   \n",
       "3  @DanielPoynter9 @LFC Not judging at all! I hop...                 1   \n",
       "4  @BBCMOTD Best game: France - Argentina 4-3\\n\\n...                 0   \n",
       "\n",
       "                                      processed_text  \n",
       "0  its an absolute disgrace  that this man is all...  \n",
       "1  think can believe jorgensen is decent  standar...  \n",
       "2  cant wait tbh mate shame we didnt get a nice l...  \n",
       "3  not judging at all i hope it was out of passio...  \n",
       "4  best game france  argentina 43\\n\\nbest goal be...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_tweet=tweets['processed_text'].apply(lambda x: x.split())\n",
    "tokenized_tweet.head(5)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(stop_words='english',tokenizer = token.tokenize)\n",
    "text_counts = cv.fit_transform(tweets['processed_text'].values.astype('U'))\n",
    "\n",
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "import nltk\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 744452\n",
      "Validation data size: 159525\n",
      "Testing data size: 159526\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into input (X) and output (y)\n",
    "X = tweets['processed_text'].values\n",
    "y = tweets['sentiment_values'].values\n",
    "\n",
    "# Split the dataset into 70% training and 30% combined validation and testing\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the temporary dataset (30% of the entire dataset) into 50% validation and 50% testing\n",
    "# This results in 15% validation and 15% testing of the entire dataset\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"Training data size:\", len(X_train))\n",
    "print(\"Validation data size:\", len(X_val))\n",
    "print(\"Testing data size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.6894 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 1000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6659 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 1000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.5242 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 1000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6627 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 1000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7291 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 5000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7123 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 5000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6033 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 5000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7072 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 5000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7300 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 10000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7233 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6308 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7185 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 10000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7102 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': None, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6954 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6520 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': None, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6874 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': None, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.6893 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 1000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6659 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 1000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.5242 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 1000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6626 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 1000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7291 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 5000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7123 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 5000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6032 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 5000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7072 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 5000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7308 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 10000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7233 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6308 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7185 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 10000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7223 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': None, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7167 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6728 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': None, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7068 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': None, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.6891 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6658 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.5242 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 1000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6625 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7293 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7121 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6027 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 5000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7071 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7328 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7229 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6303 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7181 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7301 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': None, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7147 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6778 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': None, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6992 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': None, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.6879 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6645 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.5236 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 1000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6614 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7263 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7101 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6001 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 5000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7056 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7263 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7193 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6267 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7143 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.6838 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': None, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6427 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6344 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': None, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6359 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': None, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.6786 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6578 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.5201 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 1000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6552 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.6725 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6808 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.5806 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 5000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6771 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.6430 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6652 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.5933 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6629 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.5790 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': None, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.5806 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.5919 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': None, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.5824 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': None, 'vect__ngram_range': (1, 3)}\n",
      "Best parameters:  {'clf__alpha': 1.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 1)}\n",
      "Accuracy on test data: 0.7404\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "import dill\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features=None, ngram_range=(1,2))),\n",
    "    ('clf', MultinomialNB(alpha=0.1))\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'vect__ngram_range': [(1,1), (1,2), (2,2), (1,3)],\n",
    "    'vect__max_features': [1000, 5000, 10000, None],\n",
    "    'clf__alpha': [0.01, 0.1, 0.5, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(text_clf, params, cv=5, n_jobs=1, scoring='accuracy')\n",
    " \n",
    "grid_search.fit(X_val.tolist(), y_val)\n",
    "\n",
    "# Print the mean test scores and corresponding hyperparameter combinations\n",
    "for mean_score, params in zip(grid_search.cv_results_['mean_test_score'], grid_search.cv_results_['params']):\n",
    "    print(\"Mean accuracy: {:.4f} | Hyperparameters: {}\".format(mean_score, params))\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "# Train the model with the best hyperparameters on the entire training set\n",
    "best_clf = grid_search.best_estimator_\n",
    "best_clf.fit(X_train.tolist(), y_train)\n",
    "\n",
    "y_pred = best_clf.predict(X_test.tolist())\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy on test data: {:.4f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "        0      1      3\n",
      "0  29701  10563  12955\n",
      "1   5604  42555   4973\n",
      "3   4602   2715  45858\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display the confusion matrix as a DataFrame\n",
    "labels = sorted(set(y_test))\n",
    "cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "print(\"Confusion Matrix:\\n\", cm_df)\n",
    "\n",
    "# Visualize the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_df, annot=True, fmt='d', cmap='coolwarm')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 33\u001b[0m\n\u001b[0;32m     21\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[0;32m     22\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtfidf__max_features\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39mNone\u001b[39;00m, \u001b[39m5000\u001b[39m, \u001b[39m10000\u001b[39m],\n\u001b[0;32m     23\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mclf__alpha\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0.1\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m1.0\u001b[39m, \u001b[39m10.0\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mclf__fit_prior\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39mTrue\u001b[39;00m, \u001b[39mFalse\u001b[39;00m]\n\u001b[0;32m     30\u001b[0m }\n\u001b[0;32m     32\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(text_clf, params, cv\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(X_val\u001b[39m.\u001b[39;49mtolist(), y_val)\n\u001b[0;32m     35\u001b[0m \u001b[39m# Print the mean test scores and corresponding hyperparameter combinations\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39mfor\u001b[39;00m mean_score, params \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(grid_search\u001b[39m.\u001b[39mcv_results_[\u001b[39m'\u001b[39m\u001b[39mmean_test_score\u001b[39m\u001b[39m'\u001b[39m], grid_search\u001b[39m.\u001b[39mcv_results_[\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m]):\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:708\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    705\u001b[0m result[\u001b[39m\"\u001b[39m\u001b[39mfit_error\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    707\u001b[0m fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n\u001b[1;32m--> 708\u001b[0m test_scores \u001b[39m=\u001b[39m _score(estimator, X_test, y_test, scorer, error_score)\n\u001b[0;32m    709\u001b[0m score_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time \u001b[39m-\u001b[39m fit_time\n\u001b[0;32m    710\u001b[0m \u001b[39mif\u001b[39;00m return_train_score:\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:767\u001b[0m, in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[0;32m    765\u001b[0m         scores \u001b[39m=\u001b[39m scorer(estimator, X_test)\n\u001b[0;32m    766\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 767\u001b[0m         scores \u001b[39m=\u001b[39m scorer(estimator, X_test, y_test)\n\u001b[0;32m    768\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    769\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[0;32m    770\u001b[0m         \u001b[39m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[0;32m    771\u001b[0m         \u001b[39m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:234\u001b[0m, in \u001b[0;36m_BaseScorer.__call__\u001b[1;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, estimator, X, y_true, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    212\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Evaluate predicted target values for X relative to y_true.\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \n\u001b[0;32m    214\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39m        Score function applied to prediction of estimator on X.\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_score(\n\u001b[0;32m    235\u001b[0m         partial(_cached_call, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    236\u001b[0m         estimator,\n\u001b[0;32m    237\u001b[0m         X,\n\u001b[0;32m    238\u001b[0m         y_true,\n\u001b[0;32m    239\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    240\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:276\u001b[0m, in \u001b[0;36m_PredictScorer._score\u001b[1;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_score\u001b[39m(\u001b[39mself\u001b[39m, method_caller, estimator, X, y_true, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    249\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Evaluate predicted target values for X relative to y_true.\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \n\u001b[0;32m    251\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[39m        Score function applied to prediction of estimator on X.\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 276\u001b[0m     y_pred \u001b[39m=\u001b[39m method_caller(estimator, \u001b[39m\"\u001b[39;49m\u001b[39mpredict\u001b[39;49m\u001b[39m\"\u001b[39;49m, X)\n\u001b[0;32m    277\u001b[0m     \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    278\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sign \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_score_func(\n\u001b[0;32m    279\u001b[0m             y_true, y_pred, sample_weight\u001b[39m=\u001b[39msample_weight, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kwargs\n\u001b[0;32m    280\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:73\u001b[0m, in \u001b[0;36m_cached_call\u001b[1;34m(cache, estimator, method, *args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call estimator with method and args and kwargs.\"\"\"\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[39mif\u001b[39;00m cache \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(estimator, method)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     75\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m     \u001b[39mreturn\u001b[39;00m cache[method]\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\pipeline.py:480\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    478\u001b[0m Xt \u001b[39m=\u001b[39m X\n\u001b[0;32m    479\u001b[0m \u001b[39mfor\u001b[39;00m _, name, transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(with_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 480\u001b[0m     Xt \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39;49mtransform(Xt)\n\u001b[0;32m    481\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mpredict(Xt, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpredict_params)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2155\u001b[0m, in \u001b[0;36mTfidfVectorizer.transform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   2138\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Transform documents to document-term matrix.\u001b[39;00m\n\u001b[0;32m   2139\u001b[0m \n\u001b[0;32m   2140\u001b[0m \u001b[39mUses the vocabulary and document frequencies (df) learned by fit (or\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2151\u001b[0m \u001b[39m    Tf-idf-weighted document-term matrix.\u001b[39;00m\n\u001b[0;32m   2152\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2153\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m, msg\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe TF-IDF vectorizer is not fitted\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 2155\u001b[0m X \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mtransform(raw_documents)\n\u001b[0;32m   2156\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf\u001b[39m.\u001b[39mtransform(X, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1432\u001b[0m, in \u001b[0;36mCountVectorizer.transform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   1429\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_vocabulary()\n\u001b[0;32m   1431\u001b[0m \u001b[39m# use the same matrix-building strategy as fit_transform\u001b[39;00m\n\u001b[1;32m-> 1432\u001b[0m _, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, fixed_vocab\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   1433\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[0;32m   1434\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1286\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1283\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m     j_indices\u001b[39m.\u001b[39mextend(feature_counter\u001b[39m.\u001b[39mkeys())\n\u001b[1;32m-> 1286\u001b[0m     values\u001b[39m.\u001b[39;49mextend(feature_counter\u001b[39m.\u001b[39mvalues())\n\u001b[0;32m   1287\u001b[0m     indptr\u001b[39m.\u001b[39mappend(\u001b[39mlen\u001b[39m(j_indices))\n\u001b[0;32m   1289\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fixed_vocab:\n\u001b[0;32m   1290\u001b[0m     \u001b[39m# disable defaultdict behaviour\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "import dill\n",
    "\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,2))),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'tfidf__max_features': [None, 5000, 10000],\n",
    "    'clf__alpha': [0.1, 0.5, 1.0, 10.0],\n",
    "    'tfidf__min_df': [1, 2],\n",
    "    'tfidf__max_df': [0.75, 1.0],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3), (2,2)],\n",
    "    'tfidf__use_idf': [True, False],\n",
    "    'tfidf__norm': ['l1', 'l2'],\n",
    "    'clf__fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(text_clf, params, cv=10, n_jobs=1, scoring='accuracy')\n",
    "grid_search.fit(X_val.tolist(), y_val)\n",
    "\n",
    "# Print the mean test scores and corresponding hyperparameter combinations\n",
    "for mean_score, params in zip(grid_search.cv_results_['mean_test_score'], grid_search.cv_results_['params']):\n",
    "    print(\"Mean accuracy: {:.4f} | Hyperparameters: {}\".format(mean_score, params))\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "# Train the model with the best hyperparameters on the entire training set\n",
    "best_clf = grid_search.best_estimator_\n",
    "best_clf.fit(X_train.tolist(), y_train)\n",
    "\n",
    "y_pred = best_clf.predict(X_test.tolist())\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy on test data: {:.4f}\".format(accuracy))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Classification Report\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", cr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.6899 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 1000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6664 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 1000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.5251 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 1000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6630 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 1000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7328 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 5000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7155 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 5000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6061 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 5000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7104 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 5000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7391 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 10000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7264 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6372 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7213 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 10000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7294 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': None, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7194 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6871 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': None, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7122 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': None, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.6899 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 1000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6664 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 1000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.5251 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 1000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6630 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 1000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7328 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 5000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7155 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 5000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6061 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 5000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7104 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 5000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7391 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 10000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7264 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6372 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7213 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 10000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7359 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': None, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7359 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.7064 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': None, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7286 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': None, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.6898 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6664 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.5251 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 1000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6630 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7329 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7154 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6061 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 5000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7103 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7391 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7263 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6368 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7213 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7398 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': None, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7344 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.7086 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': None, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7197 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': None, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.6897 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6662 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.5250 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 1000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6629 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7323 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7148 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6051 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 5000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7098 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7380 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7255 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6354 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7204 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7130 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': None, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6698 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6624 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': None, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6597 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': None, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.6875 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6643 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.5237 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 1000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6615 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7220 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7097 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.5995 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 5000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7051 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7157 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7154 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6241 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7114 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.6179 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': None, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6134 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6200 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': None, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6148 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': None, 'vect__ngram_range': (1, 3)}\n",
      "Best parameters:  {'clf__alpha': 1.0, 'vect__max_features': None, 'vect__ngram_range': (1, 1)}\n",
      "Accuracy on test data: 0.7398\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "import dill\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features=None, ngram_range=(1,2))),\n",
    "    ('clf', MultinomialNB(alpha=0.1))\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'vect__ngram_range': [(1,1), (1,2), (2,2), (1,3)],\n",
    "    'vect__max_features': [1000, 5000, 10000, None],\n",
    "    'clf__alpha': [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(text_clf, params, cv=5, n_jobs=1)\n",
    " \n",
    "grid_search.fit(X_train.tolist(), y_train)\n",
    "\n",
    "# Print the mean test scores and corresponding hyperparameter combinations\n",
    "for mean_score, params in zip(grid_search.cv_results_['mean_test_score'], grid_search.cv_results_['params']):\n",
    "    print(\"Mean accuracy: {:.4f} | Hyperparameters: {}\".format(mean_score, params))\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "y_pred = grid_search.predict(X_test.tolist())\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy on test data: {:.4f}\".format(accuracy))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best accuracy model to test on 80% training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import FunctionTransformer\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# from nltk.corpus import stopwords\n",
    "# import string\n",
    "# import nltk\n",
    "# import dill\n",
    "\n",
    "# # Define the pipeline with given parameters\n",
    "# text_clf = Pipeline([\n",
    "#     ('vect', CountVectorizer(ngram_range=(1, 2), max_features=None)), \n",
    "#     ('tfidf', TfidfTransformer(norm='l1', use_idf=True)), \n",
    "#     ('clf', MultinomialNB(alpha=0.1))\n",
    "# ])\n",
    "\n",
    "# text_clf.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate the classifier on the test set\n",
    "# y_pred = text_clf.predict(X_test.tolist())\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# # Print the classification report\n",
    "# print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Accuracy: {:.4f}\".format(accuracy))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tri-grams Hyper-Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39m# Perform grid search to find the best hyperparameters\u001b[39;00m\n\u001b[0;32m     34\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(text_clf, params, cv\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(X_val\u001b[39m.\u001b[39;49mtolist(), y_val)\n\u001b[0;32m     37\u001b[0m \u001b[39m# Print the mean test scores and corresponding hyperparameter combinations\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[39mfor\u001b[39;00m mean_score, params \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(grid_search\u001b[39m.\u001b[39mcv_results_[\u001b[39m'\u001b[39m\u001b[39mmean_test_score\u001b[39m\u001b[39m'\u001b[39m], grid_search\u001b[39m.\u001b[39mcv_results_[\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m]):\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\pipeline.py:401\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \n\u001b[0;32m    377\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    400\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m--> 401\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps)\n\u001b[0;32m    402\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[0;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\pipeline.py:359\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    357\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[0;32m    358\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    360\u001b[0m     cloned_transformer,\n\u001b[0;32m    361\u001b[0m     X,\n\u001b[0;32m    362\u001b[0m     y,\n\u001b[0;32m    363\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    364\u001b[0m     message_clsname\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    365\u001b[0m     message\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(step_idx),\n\u001b[0;32m    366\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps[name],\n\u001b[0;32m    367\u001b[0m )\n\u001b[0;32m    368\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    892\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 893\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit_transform(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    895\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1387\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1379\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1380\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1381\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1382\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1384\u001b[0m             )\n\u001b[0;32m   1385\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> 1387\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[0;32m   1389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[0;32m   1390\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1278\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1276\u001b[0m feature_idx \u001b[39m=\u001b[39m vocabulary[feature]\n\u001b[0;32m   1277\u001b[0m \u001b[39mif\u001b[39;00m feature_idx \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m feature_counter:\n\u001b[1;32m-> 1278\u001b[0m     feature_counter[feature_idx] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1279\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1280\u001b[0m     feature_counter[feature_idx] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from numba import jit, cuda\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from scipy.stats import uniform\n",
    "import nltk\n",
    "import dill\n",
    "\n",
    "# Define the pipeline \n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()), \n",
    "    ('tfidf', TfidfTransformer()), \n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Define the hyperparameters for GridSearchCV\n",
    "params = {\n",
    "    'vect__ngram_range': [(1,1), (1,2), (1,3), (2,2)],\n",
    "    'vect__max_features': [1000, 5000, 10000, None],\n",
    "    'tfidf__use_idf': [True, False],\n",
    "    'tfidf__norm': ['l1', 'l2'],\n",
    "    'clf__alpha': [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "}\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(text_clf, params, cv=10, n_jobs=1, scoring='accuracy')\n",
    "grid_search.fit(X_val.tolist(), y_val)\n",
    "\n",
    "# Print the mean test scores and corresponding hyperparameter combinations\n",
    "for mean_score, params in zip(grid_search.cv_results_['mean_test_score'], grid_search.cv_results_['params']):\n",
    "    print(\"Mean accuracy: {:.4f} | Hyperparameters: {}\".format(mean_score, params))\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "# Train the classifier with the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Train the classifier with the best hyperparameters\n",
    "text_clf1 = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=best_params['vect__ngram_range'], max_features=best_params['vect__max_features'])), \n",
    "    ('tfidf', TfidfTransformer(use_idf=best_params['tfidf__use_idf'], norm=best_params['tfidf__norm'])),\n",
    "    ('clf', MultinomialNB(alpha=best_params['clf__alpha']))\n",
    "])\n",
    "\n",
    "text_clf1.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "y_pred = text_clf1.predict(X_test.tolist())\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Final Hyper-Parameter Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 39\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39m# # Perform randomized search to find the best hyperparameters\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39m# random_search = RandomizedSearchCV(text_clf, params, cv=5, n_iter=50, n_jobs=1, random_state=19)\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39m# random_search.fit(X_train.tolist(), y_train)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m random_search2 \u001b[39m=\u001b[39m RandomizedSearchCV(text_clf, params, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, n_iter\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)  \u001b[39m# Change random_state\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m random_search2\u001b[39m.\u001b[39;49mfit(X_train\u001b[39m.\u001b[39;49mtolist(), y_train)\n\u001b[0;32m     41\u001b[0m \u001b[39m# Print the mean test scores and corresponding hyperparameter combinations\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[39mfor\u001b[39;00m mean_score, params \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(random_search2\u001b[39m.\u001b[39mcv_results_[\u001b[39m'\u001b[39m\u001b[39mmean_test_score\u001b[39m\u001b[39m'\u001b[39m], random_search2\u001b[39m.\u001b[39mcv_results_[\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m]):\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1768\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1766\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1767\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1768\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1769\u001b[0m         ParameterSampler(\n\u001b[0;32m   1770\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[0;32m   1771\u001b[0m         )\n\u001b[0;32m   1772\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\pipeline.py:401\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \n\u001b[0;32m    377\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    400\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m--> 401\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps)\n\u001b[0;32m    402\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[0;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\pipeline.py:359\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    357\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[0;32m    358\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    360\u001b[0m     cloned_transformer,\n\u001b[0;32m    361\u001b[0m     X,\n\u001b[0;32m    362\u001b[0m     y,\n\u001b[0;32m    363\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    364\u001b[0m     message_clsname\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    365\u001b[0m     message\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(step_idx),\n\u001b[0;32m    366\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps[name],\n\u001b[0;32m    367\u001b[0m )\n\u001b[0;32m    368\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    892\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 893\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit_transform(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    895\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1387\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1379\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1380\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1381\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1382\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1384\u001b[0m             )\n\u001b[0;32m   1385\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> 1387\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[0;32m   1389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[0;32m   1390\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1276\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1274\u001b[0m \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m analyze(doc):\n\u001b[0;32m   1275\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1276\u001b[0m         feature_idx \u001b[39m=\u001b[39m vocabulary[feature]\n\u001b[0;32m   1277\u001b[0m         \u001b[39mif\u001b[39;00m feature_idx \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m feature_counter:\n\u001b[0;32m   1278\u001b[0m             feature_counter[feature_idx] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from numba import jit, cuda\n",
    "# from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import FunctionTransformer\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# from nltk.corpus import stopwords\n",
    "# import string\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from scipy.stats import uniform\n",
    "# import nltk\n",
    "# import dill\n",
    "\n",
    "# # Define the pipeline \n",
    "# text_clf = Pipeline([\n",
    "#     ('vect', CountVectorizer()), # This step converts the collection of text into a matrix of token counts. It creates a vocabulary of all the unique words in the corpus and assigns a numerical value to each word.\n",
    "#     ('tfidf', TfidfTransformer()), # This step converts the raw term frequency matrix generated by CountVectorizer into a normalized term frequency-inverse document frequency (TF-IDF) representation.\n",
    "#     ('clf', MultinomialNB())\n",
    "# ])\n",
    "\n",
    "# # Define the hyperparameters for RandomizedSearchCV\n",
    "# params = {\n",
    "#     'vect__ngram_range': [(1,1), (1,2), (1,3), (2,2)],\n",
    "#     'vect__max_features': [1000, 5000, 10000, None],\n",
    "#     'tfidf__use_idf': [True, False],\n",
    "#     'tfidf__norm': ['l1', 'l2'],\n",
    "#     'clf__alpha': [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "# }\n",
    "\n",
    "# # # Perform randomized search to find the best hyperparameters\n",
    "# # random_search = RandomizedSearchCV(text_clf, params, cv=5, n_iter=50, n_jobs=1, random_state=19)\n",
    "# # random_search.fit(X_train.tolist(), y_train)\n",
    "\n",
    "# random_search2 = RandomizedSearchCV(text_clf, params, cv=10, n_iter=10, n_jobs=1, random_state=42)  # Change random_state\n",
    "# random_search2.fit(X_train.tolist(), y_train)\n",
    "\n",
    "# # Print the mean test scores and corresponding hyperparameter combinations\n",
    "# for mean_score, params in zip(random_search2.cv_results_['mean_test_score'], random_search2.cv_results_['params']):\n",
    "#     print(\"Mean accuracy: {:.4f} | Hyperparameters: {}\".format(mean_score, params))\n",
    "\n",
    "# print(\"Best parameters: \", random_search2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numba import jit, cuda\n",
    "# import spacy\n",
    "# import numpy as np\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# # Define the set of best parameters\n",
    "# best_params = {'vect__ngram_range': (1,2), 'vect__max_features': None, 'tfidf__use_idf': True, 'tfidf__norm': 'l1', 'clf__alpha': 1.0}\n",
    "\n",
    "# # Define a custom transformer for part-of-speech tagging\n",
    "# class POSTagger:\n",
    "#     def transform(self, X):\n",
    "#         return [self.tag_text(text) for text in X]\n",
    "    \n",
    "#     def tag_text(self, text):\n",
    "#         doc = nlp(text)\n",
    "#         return ' '.join([token.pos_ for token in doc])\n",
    "\n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "\n",
    "# # Train and evaluate the classifier using part-of-speech tagging\n",
    "# text_clf = Pipeline([\n",
    "#     ('pos_tagger', POSTagger()),\n",
    "#     ('vect', CountVectorizer()),\n",
    "#     ('tfidf', TfidfTransformer()),\n",
    "#     ('clf', MultinomialNB(alpha=best_params['clf__alpha']))\n",
    "# ])\n",
    "\n",
    "# scores = cross_val_score(text_clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "# print(\"Accuracy scores with part-of-speech tagging: \", scores)\n",
    "# print(\"Mean accuracy with part-of-speech tagging: \", np.mean(scores))\n",
    "\n",
    "# # Save the model using dill\n",
    "\n",
    "# import dill\n",
    "\n",
    "# filename = 'my_model.pkl'\n",
    "# with open(filename, 'wb') as file:\n",
    "#     dill.dump(text_clf, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# # Define the first set of best parameters\n",
    "# best_params1 = {'vect__ngram_range': (1,3), 'vect__max_features': None, 'tfidf__use_idf': True, 'tfidf__norm': 'l1', 'clf__alpha': 1.0}\n",
    "\n",
    "# # Define the second set of best parameters\n",
    "# best_params2 = {'clf__alpha': 0.651484771857788, 'tfidf__use_idf': True, 'vect__max_df': 0.8, 'vect__max_features': None, 'vect__min_df': 3, 'vect__ngram_range': (1,2)}\n",
    "\n",
    "# # Train and evaluate the classifier using the first set of best parameters\n",
    "# text_clf1 = Pipeline([\n",
    "#     ('vect', CountVectorizer(ngram_range=best_params1['vect__ngram_range'], max_features=best_params1['vect__max_features'])), \n",
    "#     ('tfidf', TfidfTransformer(use_idf=best_params1['tfidf__use_idf'], norm=best_params1['tfidf__norm'])),\n",
    "#     ('clf', MultinomialNB(alpha=best_params1['clf__alpha']))\n",
    "# ])\n",
    "\n",
    "# scores1 = cross_val_score(text_clf1, X_train, y_train, cv=5, scoring='accuracy')\n",
    "# print(\"Accuracy scores with best parameters 1: \", scores1)\n",
    "# print(\"Mean accuracy with best parameters 1: \", np.mean(scores1))\n",
    "\n",
    "# # Fit the model with the whole training set\n",
    "# text_clf1.fit(X_train, y_train)\n",
    "\n",
    "# # # Save the model to a file\n",
    "# # filename = 'naive_bayes_modelFinal.sav'\n",
    "# # dill.dump(text_clf1, open(filename, 'wb'))\n",
    "\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# # Evaluate the classifier on the test set\n",
    "# y_pred = text_clf1.predict(X_test.tolist())  # Change text_clf to text_clf1\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# # Print the classification report\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# # # Train and evaluate the classifier using the second set of best parameters\n",
    "# # text_clf2 = Pipeline([\n",
    "# #     ('vect', CountVectorizer(ngram_range=best_params2['vect__ngram_range'], min_df=best_params2['vect__min_df'], \n",
    "# #                               max_df=best_params2['vect__max_df'], max_features=best_params2['vect__max_features'])),\n",
    "# #     ('tfidf', TfidfTransformer(use_idf=best_params2['tfidf__use_idf'])),\n",
    "# #     ('clf', MultinomialNB(alpha=best_params2['clf__alpha']))\n",
    "# # ])\n",
    "\n",
    "# # scores2 = cross_val_score(text_clf2, X_train, y_train, cv=10, scoring='accuracy')\n",
    "# # print(\"Accuracy scores with best parameters 2: \", scores2)\n",
    "# # print(\"Mean accuracy with best parameters 2: \", np.mean(scores2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# pipeline = joblib.load('nbmodelwithdifferenthp2.sav')\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# # Read CSV file into a pandas DataFrame\n",
    "# df = pd.read_csv('SampleTweets.csv')\n",
    "\n",
    "# # Extract preprocessed text data as a list\n",
    "# preprocessed_data = df['processed_text'].tolist()\n",
    "\n",
    "# predictions = pipeline.predict(preprocessed_data)\n",
    "\n",
    "# for text, prediction in zip(preprocessed_data, predictions):\n",
    "#     print(f'Text: {text} | Prediction: {prediction}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dissertation 2023",
   "language": "python",
   "name": "dissertation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c5394edd7dbe54ff5ee01d77964ae3a51c12f52fc62d5a457fcc64c12a95467e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
