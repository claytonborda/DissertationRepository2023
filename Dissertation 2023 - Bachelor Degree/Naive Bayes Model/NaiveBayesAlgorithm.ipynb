{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib as plt \n",
    "\n",
    "tweets = pd.read_csv('combined.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>language</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>993767246437666816</td>\n",
       "      <td>Bayer Leverkusen goalkeeper Bernd Leno will no...</td>\n",
       "      <td>en</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>{\"Neutral\":0.7228581905364990234375,\"Negative\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1013866900772835331</td>\n",
       "      <td>Gary Speed v Blackburn at St James in 2001/02 ...</td>\n",
       "      <td>en</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>{\"Neutral\":0.998256266117095947265625,\"Negativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1037323043360657408</td>\n",
       "      <td>@ChelseaFC Don't make him regret it and start ...</td>\n",
       "      <td>en</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>{\"Neutral\":0.912796199321746826171875,\"Negativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>993803266323550208</td>\n",
       "      <td>@LiverpoolFF @AnfieldEdition He's a liar, made...</td>\n",
       "      <td>en</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>{\"Neutral\":0.3271420896053314208984375,\"Negati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1026732168226267136</td>\n",
       "      <td>@theesk @Everton Didn't realise Kenwright is d...</td>\n",
       "      <td>en</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>{\"Neutral\":0.957906246185302734375,\"Negative\":...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                         tweet_text  \\\n",
       "0   993767246437666816  Bayer Leverkusen goalkeeper Bernd Leno will no...   \n",
       "1  1013866900772835331  Gary Speed v Blackburn at St James in 2001/02 ...   \n",
       "2  1037323043360657408  @ChelseaFC Don't make him regret it and start ...   \n",
       "3   993803266323550208  @LiverpoolFF @AnfieldEdition He's a liar, made...   \n",
       "4  1026732168226267136  @theesk @Everton Didn't realise Kenwright is d...   \n",
       "\n",
       "  language sentiment                                    sentiment_score  \n",
       "0       en   NEUTRAL  {\"Neutral\":0.7228581905364990234375,\"Negative\"...  \n",
       "1       en   NEUTRAL  {\"Neutral\":0.998256266117095947265625,\"Negativ...  \n",
       "2       en   NEUTRAL  {\"Neutral\":0.912796199321746826171875,\"Negativ...  \n",
       "3       en  NEGATIVE  {\"Neutral\":0.3271420896053314208984375,\"Negati...  \n",
       "4       en   NEUTRAL  {\"Neutral\":0.957906246185302734375,\"Negative\":...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets.drop(['tweet_date_created'], axis=1)\n",
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 762643 duplicate tweet ids. Removing duplicates...\n"
     ]
    }
   ],
   "source": [
    "duplicates = tweets[tweets.duplicated(subset=['tweet_id'], keep=False)]\n",
    "\n",
    "if not duplicates.empty:\n",
    "    print(f\"Found {len(duplicates)} duplicate tweet ids. Removing duplicates...\")\n",
    "    tweets.drop_duplicates(subset=['tweet_id'], inplace=True)\n",
    "else:\n",
    "    print(\"No duplicate tweet ids found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>language</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>993767246437666816</td>\n",
       "      <td>Bayer Leverkusen goalkeeper Bernd Leno will no...</td>\n",
       "      <td>en</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1013866900772835331</td>\n",
       "      <td>Gary Speed v Blackburn at St James in 2001/02 ...</td>\n",
       "      <td>en</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1037323043360657408</td>\n",
       "      <td>@ChelseaFC Don't make him regret it and start ...</td>\n",
       "      <td>en</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>993803266323550208</td>\n",
       "      <td>@LiverpoolFF @AnfieldEdition He's a liar, made...</td>\n",
       "      <td>en</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1026732168226267136</td>\n",
       "      <td>@theesk @Everton Didn't realise Kenwright is d...</td>\n",
       "      <td>en</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                         tweet_text  \\\n",
       "0   993767246437666816  Bayer Leverkusen goalkeeper Bernd Leno will no...   \n",
       "1  1013866900772835331  Gary Speed v Blackburn at St James in 2001/02 ...   \n",
       "2  1037323043360657408  @ChelseaFC Don't make him regret it and start ...   \n",
       "3   993803266323550208  @LiverpoolFF @AnfieldEdition He's a liar, made...   \n",
       "4  1026732168226267136  @theesk @Everton Didn't realise Kenwright is d...   \n",
       "\n",
       "  language sentiment  \n",
       "0       en   NEUTRAL  \n",
       "1       en   NEUTRAL  \n",
       "2       en   NEUTRAL  \n",
       "3       en  NEGATIVE  \n",
       "4       en   NEUTRAL  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets.drop(['sentiment_score'], axis=1)\n",
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_id      0\n",
      "tweet_text    0\n",
      "language      0\n",
      "sentiment     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "tweets = tweets.dropna()\n",
    "print(tweets.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All values in the 'language' column are 'en'\n"
     ]
    }
   ],
   "source": [
    "all_english = (tweets['language'] == 'en').all()\n",
    "\n",
    "\n",
    "if all_english:\n",
    "    print(\"All values in the 'language' column are 'en'\")\n",
    "else:\n",
    "    print(\"Not all values in the 'language' column are 'en'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>993767246437666816</td>\n",
       "      <td>Bayer Leverkusen goalkeeper Bernd Leno will no...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1013866900772835331</td>\n",
       "      <td>Gary Speed v Blackburn at St James in 2001/02 ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1037323043360657408</td>\n",
       "      <td>@ChelseaFC Don't make him regret it and start ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>993803266323550208</td>\n",
       "      <td>@LiverpoolFF @AnfieldEdition He's a liar, made...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1026732168226267136</td>\n",
       "      <td>@theesk @Everton Didn't realise Kenwright is d...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                         tweet_text  \\\n",
       "0   993767246437666816  Bayer Leverkusen goalkeeper Bernd Leno will no...   \n",
       "1  1013866900772835331  Gary Speed v Blackburn at St James in 2001/02 ...   \n",
       "2  1037323043360657408  @ChelseaFC Don't make him regret it and start ...   \n",
       "3   993803266323550208  @LiverpoolFF @AnfieldEdition He's a liar, made...   \n",
       "4  1026732168226267136  @theesk @Everton Didn't realise Kenwright is d...   \n",
       "\n",
       "  sentiment  \n",
       "0   NEUTRAL  \n",
       "1   NEUTRAL  \n",
       "2   NEUTRAL  \n",
       "3  NEGATIVE  \n",
       "4   NEUTRAL  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets.drop(['language'], axis=1)\n",
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bayer Leverkusen goalkeeper Bernd Leno will no...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gary Speed v Blackburn at St James in 2001/02 ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ChelseaFC Don't make him regret it and start ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@LiverpoolFF @AnfieldEdition He's a liar, made...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@theesk @Everton Didn't realise Kenwright is d...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text sentiment\n",
       "0  Bayer Leverkusen goalkeeper Bernd Leno will no...   NEUTRAL\n",
       "1  Gary Speed v Blackburn at St James in 2001/02 ...   NEUTRAL\n",
       "2  @ChelseaFC Don't make him regret it and start ...   NEUTRAL\n",
       "3  @LiverpoolFF @AnfieldEdition He's a liar, made...  NEGATIVE\n",
       "4  @theesk @Everton Didn't realise Kenwright is d...   NEUTRAL"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets.drop(['tweet_id'], axis=1)\n",
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique sentiment values in the 'sentiment' column:\n",
      "NEUTRAL\n",
      "NEGATIVE\n",
      "POSITIVE\n",
      "MIXED\n"
     ]
    }
   ],
   "source": [
    "# Get all unique sentiment values in the 'sentiment' column\n",
    "unique_sentiments = tweets['sentiment'].unique()\n",
    "\n",
    "# Print the unique sentiment values\n",
    "print(\"Unique sentiment values in the 'sentiment' column:\")\n",
    "for sentiment in unique_sentiments:\n",
    "    print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          0\n",
      "1          0\n",
      "2          0\n",
      "3         -1\n",
      "4          0\n",
      "          ..\n",
      "5393957    0\n",
      "5393958   -1\n",
      "5393959    0\n",
      "5393960    0\n",
      "5393961    0\n",
      "Name: sentiment_values, Length: 5012534, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define a dictionary that maps sentiment labels to numeric values\n",
    "sentiment_map = {\"NEUTRAL\": 0, \"POSITIVE\": 1, \"MIXED\": 2, \"NEGATIVE\": -1}\n",
    "\n",
    "# Map the sentiment labels to their numeric values\n",
    "tweets['sentiment_values'] = tweets['sentiment'].map(sentiment_map)\n",
    "\n",
    "# Print the new column that contains the mapped values\n",
    "print(tweets['sentiment_values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bayer Leverkusen goalkeeper Bernd Leno will no...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gary Speed v Blackburn at St James in 2001/02 ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ChelseaFC Don't make him regret it and start ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@LiverpoolFF @AnfieldEdition He's a liar, made...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@theesk @Everton Didn't realise Kenwright is d...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text sentiment  \\\n",
       "0  Bayer Leverkusen goalkeeper Bernd Leno will no...   NEUTRAL   \n",
       "1  Gary Speed v Blackburn at St James in 2001/02 ...   NEUTRAL   \n",
       "2  @ChelseaFC Don't make him regret it and start ...   NEUTRAL   \n",
       "3  @LiverpoolFF @AnfieldEdition He's a liar, made...  NEGATIVE   \n",
       "4  @theesk @Everton Didn't realise Kenwright is d...   NEUTRAL   \n",
       "\n",
       "   sentiment_values  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                -1  \n",
       "4                 0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bayer Leverkusen goalkeeper Bernd Leno will no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gary Speed v Blackburn at St James in 2001/02 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ChelseaFC Don't make him regret it and start ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@LiverpoolFF @AnfieldEdition He's a liar, made...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@theesk @Everton Didn't realise Kenwright is d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  sentiment_values\n",
       "0  Bayer Leverkusen goalkeeper Bernd Leno will no...                 0\n",
       "1  Gary Speed v Blackburn at St James in 2001/02 ...                 0\n",
       "2  @ChelseaFC Don't make him regret it and start ...                 0\n",
       "3  @LiverpoolFF @AnfieldEdition He's a liar, made...                -1\n",
       "4  @theesk @Everton Didn't realise Kenwright is d...                 0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets.drop(['sentiment'], axis=1)\n",
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bayer Leverkusen goalkeeper Bernd Leno will no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gary Speed v Blackburn at St James in 2001/02 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ChelseaFC Don't make him regret it and start ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@LiverpoolFF @AnfieldEdition He's a liar, made...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@theesk @Everton Didn't realise Kenwright is d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  sentiment_values\n",
       "0  Bayer Leverkusen goalkeeper Bernd Leno will no...                 0\n",
       "1  Gary Speed v Blackburn at St James in 2001/02 ...                 0\n",
       "2  @ChelseaFC Don't make him regret it and start ...                 0\n",
       "3  @LiverpoolFF @AnfieldEdition He's a liar, made...                 3\n",
       "4  @theesk @Everton Didn't realise Kenwright is d...                 0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['sentiment_values']=tweets['sentiment_values'].replace(-1, 3)\n",
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          tweet_text  sentiment_values\n",
      "0  Bayer Leverkusen goalkeeper Bernd Leno will no...                 0\n",
      "1  Gary Speed v Blackburn at St James in 2001/02 ...                 0\n",
      "2  @ChelseaFC Don't make him regret it and start ...                 0\n",
      "3  @LiverpoolFF @AnfieldEdition He's a liar, made...                 3\n",
      "4  @theesk @Everton Didn't realise Kenwright is d...                 0\n"
     ]
    }
   ],
   "source": [
    "# Find the indices of rows with Mixed sentiment\n",
    "mixed_indices = tweets[tweets['sentiment_values'] == 2].index\n",
    "\n",
    "# Delete the rows with Mixed sentiment\n",
    "tweets = tweets.drop(mixed_indices)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(tweets.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of positive tagged tweets is: 1070334\n",
      "No of negative tagged tweets is: 354501\n",
      "No of neutral tagged tweets is: 3549918\n",
      "No of mixed tagged tweets is: 0\n"
     ]
    }
   ],
   "source": [
    "positive_tweets = tweets[tweets['sentiment_values'] == 1]\n",
    "negative_tweets = tweets[tweets['sentiment_values'] == 3]\n",
    "neutral_tweets = tweets[tweets['sentiment_values'] == 0]\n",
    "mixed_tweets = tweets[tweets['sentiment_values'] == 2]\n",
    "\n",
    "print('No of positive tagged tweets is: {}'.format(len(positive_tweets)))\n",
    "print('No of negative tagged tweets is: {}'.format(len(negative_tweets)))\n",
    "print('No of neutral tagged tweets is: {}'.format(len(neutral_tweets)))\n",
    "print('No of mixed tagged tweets is: {}'.format(len(mixed_tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of positive tagged tweets is: 354501\n",
      "No of negative tagged tweets is: 354501\n",
      "No of neutral tagged tweets is: 354501\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Shuffle the DataFrame to ensure that the downsampling is random\n",
    "tweets = tweets.sample(frac=1, random_state=42)\n",
    "\n",
    "# Count the number of tweets in each sentiment class\n",
    "counts = tweets['sentiment_values'].value_counts()\n",
    "\n",
    "# Find the smallest class size\n",
    "smallest_size = counts.min()\n",
    "\n",
    "# Downsample each class to the smallest size\n",
    "positive_tweets = tweets[tweets['sentiment_values'] == 1].sample(n=smallest_size, random_state=42)\n",
    "negative_tweets = tweets[tweets['sentiment_values'] == 3].sample(n=smallest_size, random_state=42)\n",
    "neutral_tweets = tweets[tweets['sentiment_values'] == 0].sample(n=smallest_size, random_state=42)\n",
    "\n",
    "# Concatenate the downsampled DataFrames\n",
    "tweets = pd.concat([positive_tweets, negative_tweets, neutral_tweets], ignore_index=True)\n",
    "\n",
    "# Print the new counts of tweets in each class\n",
    "print('No of positive tagged tweets is: {}'.format(len(tweets[tweets['sentiment_values'] == 1])))\n",
    "print('No of negative tagged tweets is: {}'.format(len(tweets[tweets['sentiment_values'] == 3])))\n",
    "print('No of neutral tagged tweets is: {}'.format(len(tweets[tweets['sentiment_values'] == 0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['tweet_text'] = tweets['tweet_text'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove mentions\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Remove hashtags\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove whitespace\n",
    "    text = text.strip()\n",
    "    # Remove stopwords and join the words in a single string\n",
    "    #text = ' '.join([word for word in text.split() if word not in stopwords.words('english')])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string \n",
    "import pandas as pd\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "english_stopwords = stopwords.words('english')\n",
    "\n",
    "# Add custom stopwords\n",
    "#custom_stopwords = ['dont', 'shouldve', 'arent', 'couldnt', 'didnt', 'doesnt', 'hadnt', 'havent', 'mustnt', 'shouldnt', 'wasnt', 'werent', \n",
    "#                    'wont', 'wouldnt']\n",
    "#english_stopwords.extend(custom_stopwords)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Get the default NLTK English stopwords\n",
    "    \n",
    "    # List of words to keep\n",
    "    words_to_keep = {\"off\", \"over\", \"under\", \"few\", \"more\", \"no\", \"not\", \"don't\", \"should\", \"should've\", \"aren't\", \n",
    "                     \"couldn't\", \"didn't\", \"doesn't\", \"hadn't\", \"haven't\", \"mustn't\", \"shouldn't\", \"wasn't\", \"weren't\",\n",
    "                     \"won't\", \"wouldn't\"}\n",
    "\n",
    "    custom_stopwords = english_stopwords - words_to_keep\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove mentions\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Remove hashtags\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove whitespace\n",
    "    text = text.strip()\n",
    "    # Remove custom stopwords and join the words in a single string\n",
    "    text = ' '.join([word for word in text.split() if word not in custom_stopwords])\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'list' and 'set'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtokenize\u001b[39;00m \u001b[39mimport\u001b[39;00m word_tokenize\n\u001b[0;32m      6\u001b[0m \u001b[39m# Apply the preprocessing function to the 'text' column\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m tweets[\u001b[39m'\u001b[39m\u001b[39mprocessed_text\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m tweets[\u001b[39m'\u001b[39;49m\u001b[39mtweet_text\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(preprocess_text)\n\u001b[0;32m      9\u001b[0m tweets \u001b[39m=\u001b[39m  shuffle(tweets)\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\pandas\\core\\apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\pandas\\core\\apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1175\u001b[0m             values,\n\u001b[0;32m   1176\u001b[0m             f,\n\u001b[0;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1178\u001b[0m         )\n\u001b[0;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[17], line 22\u001b[0m, in \u001b[0;36mpreprocess_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess_text\u001b[39m(text):\n\u001b[0;32m     15\u001b[0m     \u001b[39m# Get the default NLTK English stopwords\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \n\u001b[0;32m     17\u001b[0m     \u001b[39m# List of words to keep\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     words_to_keep \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39moff\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mover\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39munder\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfew\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmore\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mno\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnot\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdon\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mshould\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mshould\u001b[39m\u001b[39m'\u001b[39m\u001b[39mve\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39maren\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[0;32m     19\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mcouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdidn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdoesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhadn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhaven\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmustn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mshouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwasn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mweren\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     20\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mwon\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m---> 22\u001b[0m     custom_stopwords \u001b[39m=\u001b[39m english_stopwords \u001b[39m-\u001b[39;49m words_to_keep\n\u001b[0;32m     23\u001b[0m     \u001b[39m# Convert to lowercase\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     text \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mlower()\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'list' and 'set'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Apply the preprocessing function to the 'text' column\n",
    "tweets['processed_text'] = tweets['tweet_text'].apply(preprocess_text)\n",
    "\n",
    "tweets =  shuffle(tweets).reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Get the default NLTK English stopwords\n",
    "    \n",
    "    # List of words to keep\n",
    "    words_to_keep = {\"off\", \"over\", \"under\", \"few\", \"more\", \"no\", \"not\", \"don't\", \"should\", \"should've\", \"aren't\", \n",
    "                     \"couldn't\", \"didn't\", \"doesn't\", \"hadn't\", \"haven't\", \"mustn't\", \"shouldn't\", \"wasn't\", \"weren't\",\n",
    "                     \"won't\", \"wouldn't\"}\n",
    "\n",
    "    # Convert english_stopwords to a set, perform the subtraction, and convert the result back to a list\n",
    "    custom_stopwords = list(set(english_stopwords) - words_to_keep)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove mentions\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Remove hashtags\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove whitespace\n",
    "    text = text.strip()\n",
    "    # Remove custom stopwords and join the words in a single string\n",
    "    text = ' '.join([word for word in text.split() if word not in custom_stopwords])\n",
    "    \n",
    "    return text\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Apply the preprocessing function to the 'text' column\n",
    "tweets['processed_text'] = tweets['tweet_text'].apply(preprocess_text)\n",
    "\n",
    "tweets =  shuffle(tweets).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment_values</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Annmariolsen All I thought was that I wish Gi...</td>\n",
       "      <td>1</td>\n",
       "      <td>thought wish giggsy still team form wished all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Newcastle are a joke, fans must be fuming, cla...</td>\n",
       "      <td>3</td>\n",
       "      <td>newcastle joke fans must fuming claim no money...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@kirksavage @WayneRooney Sshhh ? @dcunited are...</td>\n",
       "      <td>0</td>\n",
       "      <td>sshhh american team</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@_TrueBlueNews @ChelseaFC @rubey_lcheek I thin...</td>\n",
       "      <td>1</td>\n",
       "      <td>think well chelsea showing good business terms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@SkySportsNews @ManUtd Must be a slow news day...</td>\n",
       "      <td>3</td>\n",
       "      <td>must slow news day breaking news</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  sentiment_values  \\\n",
       "0  @Annmariolsen All I thought was that I wish Gi...                 1   \n",
       "1  Newcastle are a joke, fans must be fuming, cla...                 3   \n",
       "2  @kirksavage @WayneRooney Sshhh ? @dcunited are...                 0   \n",
       "3  @_TrueBlueNews @ChelseaFC @rubey_lcheek I thin...                 1   \n",
       "4  @SkySportsNews @ManUtd Must be a slow news day...                 3   \n",
       "\n",
       "                                      processed_text  \n",
       "0  thought wish giggsy still team form wished all...  \n",
       "1  newcastle joke fans must fuming claim no money...  \n",
       "2                                sshhh american team  \n",
       "3  think well chelsea showing good business terms...  \n",
       "4                   must slow news day breaking news  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment_values</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Its an absolute disgrace @Arsenal that this m...</td>\n",
       "      <td>3</td>\n",
       "      <td>its an absolute disgrace  that this man is all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Think can believe Jorgensen is decent .@premie...</td>\n",
       "      <td>0</td>\n",
       "      <td>think can believe jorgensen is decent  standar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@refmillerafc @CheckatradeTrpy @Arsenal Can't ...</td>\n",
       "      <td>3</td>\n",
       "      <td>cant wait tbh mate shame we didnt get a nice l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@DanielPoynter9 @LFC Not judging at all! I hop...</td>\n",
       "      <td>1</td>\n",
       "      <td>not judging at all i hope it was out of passio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@BBCMOTD Best game: France - Argentina 4-3\\n\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>best game france  argentina 43\\n\\nbest goal be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  sentiment_values  \\\n",
       "0  Its an absolute disgrace @Arsenal that this m...                 3   \n",
       "1  Think can believe Jorgensen is decent .@premie...                 0   \n",
       "2  @refmillerafc @CheckatradeTrpy @Arsenal Can't ...                 3   \n",
       "3  @DanielPoynter9 @LFC Not judging at all! I hop...                 1   \n",
       "4  @BBCMOTD Best game: France - Argentina 4-3\\n\\n...                 0   \n",
       "\n",
       "                                      processed_text  \n",
       "0  its an absolute disgrace  that this man is all...  \n",
       "1  think can believe jorgensen is decent  standar...  \n",
       "2  cant wait tbh mate shame we didnt get a nice l...  \n",
       "3  not judging at all i hope it was out of passio...  \n",
       "4  best game france  argentina 43\\n\\nbest goal be...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_tweet=tweets['processed_text'].apply(lambda x: x.split())\n",
    "tokenized_tweet.head(5)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(stop_words='english',tokenizer = token.tokenize)\n",
    "text_counts = cv.fit_transform(tweets['processed_text'].values.astype('U'))\n",
    "\n",
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "import nltk\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 744452\n",
      "Validation data size: 159525\n",
      "Testing data size: 159526\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into input (X) and output (y)\n",
    "X = tweets['processed_text'].values\n",
    "y = tweets['sentiment_values'].values\n",
    "\n",
    "# Split the dataset into 70% training and 30% combined validation and testing\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the temporary dataset (30% of the entire dataset) into 50% validation and 50% testing\n",
    "# This results in 15% validation and 15% testing of the entire dataset\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"Training data size:\", len(X_train))\n",
    "print(\"Validation data size:\", len(X_val))\n",
    "print(\"Testing data size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.6921 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 1000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6677 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 1000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.5658 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 1000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6643 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 1000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7314 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 5000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7147 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 5000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6246 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 5000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7104 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 5000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7338 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 10000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7247 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6491 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7195 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 10000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7136 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': None, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6967 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6607 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': None, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6881 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': None, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.6920 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 1000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6677 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 1000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.5658 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 1000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6643 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 1000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7316 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 5000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7147 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 5000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6246 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 5000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7104 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 5000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7344 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 10000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7246 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6491 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7194 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 10000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7257 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': None, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7181 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6799 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': None, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7076 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': None, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.6920 | Hyperparameters: {'clf__alpha': 0.5, 'vect__max_features': 1000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6676 | Hyperparameters: {'clf__alpha': 0.5, 'vect__max_features': 1000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.5658 | Hyperparameters: {'clf__alpha': 0.5, 'vect__max_features': 1000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6642 | Hyperparameters: {'clf__alpha': 0.5, 'vect__max_features': 1000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7318 | Hyperparameters: {'clf__alpha': 0.5, 'vect__max_features': 5000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7145 | Hyperparameters: {'clf__alpha': 0.5, 'vect__max_features': 5000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6245 | Hyperparameters: {'clf__alpha': 0.5, 'vect__max_features': 5000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7103 | Hyperparameters: {'clf__alpha': 0.5, 'vect__max_features': 5000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7352 | Hyperparameters: {'clf__alpha': 0.5, 'vect__max_features': 10000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7245 | Hyperparameters: {'clf__alpha': 0.5, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6489 | Hyperparameters: {'clf__alpha': 0.5, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7192 | Hyperparameters: {'clf__alpha': 0.5, 'vect__max_features': 10000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7325 | Hyperparameters: {'clf__alpha': 0.5, 'vect__max_features': None, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7249 | Hyperparameters: {'clf__alpha': 0.5, 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6897 | Hyperparameters: {'clf__alpha': 0.5, 'vect__max_features': None, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7114 | Hyperparameters: {'clf__alpha': 0.5, 'vect__max_features': None, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.6919 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6676 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.5655 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 1000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6642 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7318 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7143 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6243 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 5000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7102 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7354 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7244 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6485 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7190 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7328 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': None, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7179 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6861 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': None, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7012 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': None, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.6913 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6668 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.5646 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 1000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6639 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7287 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7127 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6221 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 5000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7085 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7300 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7219 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6447 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7163 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.6887 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': None, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6475 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6429 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': None, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6398 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': None, 'vect__ngram_range': (1, 3)}\n",
      "Best parameters:  {'clf__alpha': 1.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 1)}\n",
      "Accuracy on test data: 0.7397\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "import dill\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features=None, ngram_range=(1,2))),\n",
    "    ('clf', MultinomialNB(alpha=0.1))\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'vect__ngram_range': [(1,1), (1,2), (2,2), (1,3)],\n",
    "    'vect__max_features': [1000, 5000, 10000, None],\n",
    "    'clf__alpha': [0.01, 0.1, 0.5, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(text_clf, params, cv=10, n_jobs=1, scoring='accuracy')\n",
    " \n",
    "grid_search.fit(X_val.tolist(), y_val)\n",
    "\n",
    "# Print the mean test scores and corresponding hyperparameter combinations\n",
    "for mean_score, params in zip(grid_search.cv_results_['mean_test_score'], grid_search.cv_results_['params']):\n",
    "    print(\"Mean accuracy: {:.4f} | Hyperparameters: {}\".format(mean_score, params))\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "# Train the model with the best hyperparameters on the entire training set\n",
    "best_clf = grid_search.best_estimator_\n",
    "best_clf.fit(X_train.tolist(), y_train)\n",
    "\n",
    "y_pred = best_clf.predict(X_test.tolist())\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy on test data: {:.4f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7397\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7402    0.5583    0.6365     53000\n",
      "           1     0.7625    0.7976    0.7797     53214\n",
      "           3     0.7195    0.8622    0.7844     53312\n",
      "\n",
      "    accuracy                         0.7397    159526\n",
      "   macro avg     0.7407    0.7394    0.7335    159526\n",
      "weighted avg     0.7407    0.7397    0.7337    159526\n",
      "\n",
      "Confusion Matrix:\n",
      "        0      1      3\n",
      "0  29590  10500  12910\n",
      "1   5759  42445   5010\n",
      "3   4624   2722  45966\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApoAAAIjCAYAAACjybtCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABy8ElEQVR4nO3deVhUZfsH8O/MAMM6rLIJIoobiaJoOOWaKCqmppZbhmthaArmQrlrUZZralammGkulfYqiRLkluSC4S6JoqisLoBsA8zM7w9+HJ1AhfIIMt/PdZ3rZZ5zn+c8Z/KFe+7znGckWq1WCyIiIiKip0xa0wMgIiIiorqJiSYRERERiYKJJhERERGJgokmEREREYmCiSYRERERiYKJJhERERGJgokmEREREYmCiSYRERERiYKJJhERERGJgokmET3W5cuX0bNnT1haWkIikWDXrl1Ptf9r165BIpEgIiLiqfb7POvatSu6du1a08MgIvrPmGgSPQeuXLmCd955B40aNYKxsTEUCgVefvllrFixAoWFhaKeOzAwEGfPnsVHH32ETZs2oV27dqKe71kaNWoUJBIJFApFpe/j5cuXIZFIIJFI8Pnnn1e7/9TUVMybNw8JCQlPYbRERM8fg5oeABE9XmRkJF5//XXI5XK89dZbaNmyJYqLi3HkyBFMmzYN58+fx9dffy3KuQsLCxEXF4cPP/wQEydOFOUcbm5uKCwshKGhoSj9P4mBgQEKCgqwe/duvPHGGzr7Nm/eDGNjYxQVFf2rvlNTUzF//nw0bNgQ3t7eVT5u//79/+p8RES1DRNNolosOTkZQ4cOhZubG2JjY+Hk5CTsCw4ORlJSEiIjI0U7f1ZWFgDAyspKtHNIJBIYGxuL1v+TyOVyvPzyy/jhhx8qJJpbtmxBQEAAfvrpp2cyloKCApiamsLIyOiZnI+ISGy8dU5Uiy1evBh5eXn49ttvdZLMch4eHpg8ebLwurS0FAsXLkTjxo0hl8vRsGFDfPDBB1CpVDrHNWzYEH379sWRI0fw4osvwtjYGI0aNcJ3330nxMybNw9ubm4AgGnTpkEikaBhw4YAym45l//8sHnz5kEikei0RUdHo2PHjrCysoK5uTmaNWuGDz74QNj/qDmasbGx6NSpE8zMzGBlZYX+/fvj4sWLlZ4vKSkJo0aNgpWVFSwtLTF69GgUFBQ8+o39h+HDh2Pv3r3Izs4W2k6cOIHLly9j+PDhFeLv3r2L999/H15eXjA3N4dCoUDv3r1x+vRpIebAgQNo3749AGD06NHCLfjy6+zatStatmyJ+Ph4dO7cGaampsL78s85moGBgTA2Nq5w/f7+/rC2tkZqamqVr5WI6FlioklUi+3evRuNGjXCSy+9VKX4cePGYc6cOWjbti2WLVuGLl26IDw8HEOHDq0Qm5SUhMGDB6NHjx5YsmQJrK2tMWrUKJw/fx4AMHDgQCxbtgwAMGzYMGzatAnLly+v1vjPnz+Pvn37QqVSYcGCBViyZAn69euHP/7447HH/fbbb/D390dmZibmzZuH0NBQHD16FC+//DKuXbtWIf6NN97A/fv3ER4ejjfeeAMRERGYP39+lcc5cOBASCQS/Pzzz0Lbli1b0Lx5c7Rt27ZC/NWrV7Fr1y707dsXS5cuxbRp03D27Fl06dJFSPpatGiBBQsWAADefvttbNq0CZs2bULnzp2Ffu7cuYPevXvD29sby5cvR7du3Sod34oVK1CvXj0EBgZCrVYDAL766ivs378fX3zxBZydnat8rUREz5SWiGqlnJwcLQBt//79qxSfkJCgBaAdN26cTvv777+vBaCNjY0V2tzc3LQAtIcOHRLaMjMztXK5XDt16lShLTk5WQtA+9lnn+n0GRgYqHVzc6swhrlz52of/rWybNkyLQBtVlbWI8ddfo4NGzYIbd7e3lp7e3vtnTt3hLbTp09rpVKp9q233qpwvjFjxuj0+dprr2ltbW0fec6Hr8PMzEyr1Wq1gwcP1nbv3l2r1Wq1arVa6+joqJ0/f36l70FRUZFWrVZXuA65XK5dsGCB0HbixIkK11auS5cuWgDatWvXVrqvS5cuOm379u3TAtAuWrRIe/XqVa25ubl2wIABT7xGIqKaxIomUS2Vm5sLALCwsKhS/K+//goACA0N1WmfOnUqAFSYy+np6YlOnToJr+vVq4dmzZrh6tWr/3rM/1Q+t/OXX36BRqOp0jFpaWlISEjAqFGjYGNjI7S3atUKPXr0EK7zYUFBQTqvO3XqhDt37gjvYVUMHz4cBw4cQHp6OmJjY5Genl7pbXOgbF6nVFr261OtVuPOnTvCtIBTp05V+ZxyuRyjR4+uUmzPnj3xzjvvYMGCBRg4cCCMjY3x1VdfVflcREQ1gYkmUS2lUCgAAPfv369S/PXr1yGVSuHh4aHT7ujoCCsrK1y/fl2nvUGDBhX6sLa2xr179/7liCsaMmQIXn75ZYwbNw4ODg4YOnQotm/f/tiks3yczZo1q7CvRYsWuH37NvLz83Xa/3kt1tbWAFCta+nTpw8sLCywbds2bN68Ge3bt6/wXpbTaDRYtmwZmjRpArlcDjs7O9SrVw9nzpxBTk5Olc9Zv379aj348/nnn8PGxgYJCQlYuXIl7O3tq3wsEVFNYKJJVEspFAo4Ozvj3Llz1Trunw/jPIpMJqu0XavV/utzlM8fLGdiYoJDhw7ht99+w8iRI3HmzBkMGTIEPXr0qBD7X/yXayknl8sxcOBAbNy4ETt37nxkNRMAPv74Y4SGhqJz5874/vvvsW/fPkRHR+OFF16ocuUWKHt/quOvv/5CZmYmAODs2bPVOpaIqCYw0SSqxfr27YsrV64gLi7uibFubm7QaDS4fPmyTntGRgays7OFJ8ifBmtra50ntMv9s2oKAFKpFN27d8fSpUtx4cIFfPTRR4iNjcXvv/9ead/l40xMTKyw79KlS7Czs4OZmdl/u4BHGD58OP766y/cv3+/0geoyv3444/o1q0bvv32WwwdOhQ9e/aEn59fhfekqkl/VeTn52P06NHw9PTE22+/jcWLF+PEiRNPrX8iIjEw0SSqxaZPnw4zMzOMGzcOGRkZFfZfuXIFK1asAFB26xdAhSfDly5dCgAICAh4auNq3LgxcnJycObMGaEtLS0NO3fu1Im7e/duhWPLFy7/55JL5ZycnODt7Y2NGzfqJG7nzp3D/v37hesUQ7du3bBw4UKsWrUKjo6Oj4yTyWQVqqU7duzArVu3dNrKE+LKkvLqmjFjBlJSUrBx40YsXboUDRs2RGBg4CPfRyKi2oALthPVYo0bN8aWLVswZMgQtGjRQuebgY4ePYodO3Zg1KhRAIDWrVsjMDAQX3/9NbKzs9GlSxccP34cGzduxIABAx65dM6/MXToUMyYMQOvvfYa3nvvPRQUFODLL79E06ZNdR6GWbBgAQ4dOoSAgAC4ubkhMzMTa9asgYuLCzp27PjI/j/77DP07t0bSqUSY8eORWFhIb744gtYWlpi3rx5T+06/kkqlWLWrFlPjOvbty8WLFiA0aNH46WXXsLZs2exefNmNGrUSCeucePGsLKywtq1a2FhYQEzMzP4+vrC3d29WuOKjY3FmjVrMHfuXGG5pQ0bNqBr166YPXs2Fi9eXK3+iIieFVY0iWq5fv364cyZMxg8eDB++eUXBAcHY+bMmbh27RqWLFmClStXCrHr1q3D/PnzceLECUyZMgWxsbEICwvD1q1bn+qYbG1tsXPnTpiammL69OnYuHEjwsPD8eqrr1YYe4MGDbB+/XoEBwdj9erV6Ny5M2JjY2FpafnI/v38/BAVFQVbW1vMmTMHn3/+OTp06IA//vij2kmaGD744ANMnToV+/btw+TJk3Hq1ClERkbC1dVVJ87Q0BAbN26ETCZDUFAQhg0bhoMHD1brXPfv38eYMWPQpk0bfPjhh0J7p06dMHnyZCxZsgR//vnnU7kuIqKnTaKtzmx5IiIiIqIqYkWTiIiIiETBRJOIiIiIRMFEk4iIiIhEwUSTiIiIiETBRJOIiIiIRMFEk4iIiIhEwUSTiIiIiERRJ78ZKP/ozzU9BKIK5p/pXdNDINJhayev6SEQ6ZgxuObqX5GGzUTrO6AkUbS+aztWNImIiIhIFHWyoklERERUHRJDSU0PoU5ioklERER6T2rARFMMvHVORERERKJgRZOIiIj0nsSQtTcx8F0lIiIiqqU++eQTSCQSTJkyRWjr2rUrJBKJzhYUFKRzXEpKCgICAmBqagp7e3tMmzYNpaWlOjEHDhxA27ZtIZfL4eHhgYiIiArnX716NRo2bAhjY2P4+vri+PHj1Ro/K5pERESk92rjHM0TJ07gq6++QqtWrSrsGz9+PBYsWCC8NjU1FX5Wq9UICAiAo6Mjjh49irS0NLz11lswNDTExx9/DABITk5GQEAAgoKCsHnzZsTExGDcuHFwcnKCv78/AGDbtm0IDQ3F2rVr4evri+XLl8Pf3x+JiYmwt7ev0jWwoklERERUy+Tl5WHEiBH45ptvYG1tXWG/qakpHB0dhU2hUAj79u/fjwsXLuD777+Ht7c3evfujYULF2L16tUoLi4GAKxduxbu7u5YsmQJWrRogYkTJ2Lw4MFYtmyZ0M/SpUsxfvx4jB49Gp6enli7di1MTU2xfv36Kl8HE00iIiLSexJDiWibSqVCbm6uzqZSqR47nuDgYAQEBMDPz6/S/Zs3b4adnR1atmyJsLAwFBQUCPvi4uLg5eUFBwcHoc3f3x+5ubk4f/68EPPPvv39/REXFwcAKC4uRnx8vE6MVCqFn5+fEFMVTDSJiIiIRBQeHg5LS0udLTw8/JHxW7duxalTpx4ZM3z4cHz//ff4/fffERYWhk2bNuHNN98U9qenp+skmQCE1+np6Y+Nyc3NRWFhIW7fvg21Wl1pTHkfVcE5mkRERKT3xJyjGRYWhtDQUJ02ubzyr4C9ceMGJk+ejOjoaBgbG1ca8/bbbws/e3l5wcnJCd27d8eVK1fQuHHjpzfwp4CJJhEREek9Mb8ZSC6XPzKx/Kf4+HhkZmaibdu2QptarcahQ4ewatUqqFQqyGQynWN8fX0BAElJSWjcuDEcHR0rPB2ekZEBAHB0dBT+t7zt4RiFQgETExPIZDLIZLJKY8r7qAreOiciIiKqJbp3746zZ88iISFB2Nq1a4cRI0YgISGhQpIJAAkJCQAAJycnAIBSqcTZs2eRmZkpxERHR0OhUMDT01OIiYmJ0eknOjoaSqUSAGBkZAQfHx+dGI1Gg5iYGCGmKljRJCIiIr1XW5Y3srCwQMuWLXXazMzMYGtri5YtW+LKlSvYsmUL+vTpA1tbW5w5cwYhISHo3LmzsAxSz5494enpiZEjR2Lx4sVIT0/HrFmzEBwcLFRWg4KCsGrVKkyfPh1jxoxBbGwstm/fjsjISOG8oaGhCAwMRLt27fDiiy9i+fLlyM/Px+jRo6t8PUw0iYiIiJ4TRkZG+O2334Skz9XVFYMGDcKsWbOEGJlMhj179mDChAlQKpUwMzNDYGCgzrqb7u7uiIyMREhICFasWAEXFxesW7dOWEMTAIYMGYKsrCzMmTMH6enp8Pb2RlRUVIUHhB5HotVqtU/n0muP/KM/1/QQiCqYf6Z3TQ+BSIetXdXmjBE9KzMG19yMvkMt24jWd+dzf4nWd23HOZpEREREJAreOiciIiK9J5XVjjmadQ0rmkREREQkClY0iYiISO9JpKxoioGJJhEREek9iYw3ecXAd5WIiIiIRMGKJhEREek9PgwkDlY0iYiIiEgUrGgSERGR3uPDQOJgRZOIiIiIRMGKJhEREek9ztEUByuaRERERCQKVjSJiIhI70lY0RQFE00iIiLSexIpb/KKge8qEREREYmCFU0iIiLSe1zeSBysaBIRERGRKFjRJCIiIr3H5Y3EwYomEREREYmCFU0iIiLSe5yjKQ5WNImIiIhIFKxoEhERkd7jOpriYKJJREREeo+3zsXB9J2IiIiIRMGKJhEREek9Lm8kDlY0iYiIiEgUrGgSERGR3uMcTXGwoklEREREomBFk4iIiPQelzcSB99VIiIiIhIFK5pERESk9zhHUxxMNImIiEjvMdEUB2+dExEREZEoWNEkIiIivceKpjhY0SQiIiIiUbCiSURERHqPyxuJg+8qEREREYmCFU0iIiLSe1IZ52iKgRVNIiIiIhIFK5pERESk9/jUuTiYaBIREZHe48NA4uC7SkRERESiYEWTiIiI9B5vnYuDFU0iIiKiWuqTTz6BRCLBlClThLaioiIEBwfD1tYW5ubmGDRoEDIyMnSOS0lJQUBAAExNTWFvb49p06ahtLRUJ+bAgQNo27Yt5HI5PDw8EBERUeH8q1evRsOGDWFsbAxfX18cP368WuNnoklERER6TyKViLb9WydOnMBXX32FVq1a6bSHhIRg9+7d2LFjBw4ePIjU1FQMHDhQ2K9WqxEQEIDi4mIcPXoUGzduREREBObMmSPEJCcnIyAgAN26dUNCQgKmTJmCcePGYd++fULMtm3bEBoairlz5+LUqVNo3bo1/P39kZmZWeVrYKJJREREJCKVSoXc3FydTaVSPfaYvLw8jBgxAt988w2sra2F9pycHHz77bdYunQpXnnlFfj4+GDDhg04evQo/vzzTwDA/v37ceHCBXz//ffw9vZG7969sXDhQqxevRrFxcUAgLVr18Ld3R1LlixBixYtMHHiRAwePBjLli0TzrV06VKMHz8eo0ePhqenJ9auXQtTU1OsX7++ytfORJOIiIj0nkQqFW0LDw+HpaWlzhYeHv7Y8QQHByMgIAB+fn467fHx8SgpKdFpb968ORo0aIC4uDgAQFxcHLy8vODg4CDE+Pv7Izc3F+fPnxdi/tm3v7+/0EdxcTHi4+N1YqRSKfz8/ISYquDDQEREREQiCgsLQ2hoqE6bXC5/ZPzWrVtx6tQpnDhxosK+9PR0GBkZwcrKSqfdwcEB6enpQszDSWb5/vJ9j4vJzc1FYWEh7t27B7VaXWnMpUuXHnO1uphoEhERkd4T86lzuVz+2MTyYTdu3MDkyZMRHR0NY2Nj0cb0rPDWOREREek9MW+dV0d8fDwyMzPRtm1bGBgYwMDAAAcPHsTKlSthYGAABwcHFBcXIzs7W+e4jIwMODo6AgAcHR0rPIVe/vpJMQqFAiYmJrCzs4NMJqs0pryPqmCiSURERFRLdO/eHWfPnkVCQoKwtWvXDiNGjBB+NjQ0RExMjHBMYmIiUlJSoFQqAQBKpRJnz57VeTo8OjoaCoUCnp6eQszDfZTHlPdhZGQEHx8fnRiNRoOYmBghpip465yIiIhIUjsWbLewsEDLli112szMzGBrayu0jx07FqGhobCxsYFCocCkSZOgVCrRoUMHAEDPnj3h6emJkSNHYvHixUhPT8esWbMQHBws3MIPCgrCqlWrMH36dIwZMwaxsbHYvn07IiMjhfOGhoYiMDAQ7dq1w4svvojly5cjPz8fo0ePrvL1MNEkIiIieo4sW7YMUqkUgwYNgkqlgr+/P9asWSPsl8lk2LNnDyZMmAClUgkzMzMEBgZiwYIFQoy7uzsiIyMREhKCFStWwMXFBevWrYO/v78QM2TIEGRlZWHOnDlIT0+Ht7c3oqKiKjwg9DgSrVarfTqXXXvkH/25podAVMH8M71reghEOmztqvZwAtGzMmNwzc3ouzV5iGh911+xTbS+aztWNOuQ9XsOIDb+HK6lZ0FuaIjWHm547/VeaOhUT4i5kXkHy7f9ir/+vo6S0lK85NUU00e8CltLCyEm4P1PkXYnW6fvSYP9MTqgq/B6//EzWL/nAFIybsPKwgxDuisR2LuzzjEnL13F0h8icSU1Aw42lhj36ivo19FHlGun2svdSYourQ3gUk8KhZkEG6NUOH9NoxPTs50BXmxhABM5cC1dg52HS3A758Fn4Jkj5LCx0P0D9OufJTiQ8ODr1BxtJHitkyFc6kmRX6TFH+fUOJig+3VrXo2k8G9vCGsLCW7naLH3WAkupeiOheq+9OQTOHt4PW6nnkfh/Sx0H/EF3DzL1grUqEsQH70CN/8+hPt3b8LQ2BzOjZVo7z8Vpgp7oY/bt87j5L4luH3rHCQSKdxe6AnfPjNgKDcTYv7c8xEyrp/CvYzLsKrXGAMm7awwlrvpiYj730LcvnUWxmY2aNFhBFp1Hif+m0D0jDDRrEPiE6/ije5KvODuArVag1U/7cO7S9bjp49CYCI3QqGqGMGfr0cTVyd8Nb3sF9mXO6MxZcV32DhrAqQPPRk34TU/vNblReG1mfGDyscfZxIx6+ttmD6iHzq80ATJaZlYGPEz5IYGGOr3EgDgVtZdvLcsAoO7+WLRO0Nw/EISFm74GXaWFnjJq+kzekeoNjAyANLuaHDiUikCe1WsoHX1NsDLXgbY9nsx7uZq4d/eEGMDjLBkmwql6gdx+46X4NjFB4mjquTBPrkhML6vHJdvqvHzIRUcbaR4vashilRaHLtY1ombgxTD/YwQdawUF6+r4d1Ehrf8jbDiRxUy7tW5Gzv0GCXFhbBxaoYmPgMRu+U9nX2lJUW4k3oBrbtNgK1jc6gKc/BnZDiiN72L/sE/AgAKcjMRtWEsGnn1gvLV2ShW5eFYZDgO//QBXhm+Qqe/Jj4DkXXjDO6l/11hHMVFedi3YRycGyvxUv+5uJfxNw7/PAtGxgo0f/EN8d4AqlR1nw6nqmGiWYesnjpG5/X8sYPRffJHuHDtFnyauSPh8jWk3r6HLfMnwdykbG2u+eNeR9eJC3Di4lX4vuAhHGtqLIfdQ1XOh0Ue/Qtd23hicDdfAICLvQ3GBHTFxl8PYUh3JSQSCX78/Rjq17NB6NAAAEAjZ3skXL6OzfuPMNHUM4k3NEi88eiqYUcvA8ScKsWF/69ybvu9GLPfMsYLDWU4feVBpqkq0SKvsPI+2jSRQSYFdhwogVoDZNxTw9lOgk6tDIREs6OXDH/f0ODg6bJkdf+JUjRxkeHllgb4+XBJ5R1TneTarDNcm3WudJ+RsQV6jdH9ej3lq7Ow+8s3kJedCnMrZ6RcOgCp1ADKV+cIyclL/edh1xf9kXvnOhS2bgCADn0/BACcyr9XaaJ55fRuqNUl6DhwEWQGRrB2aII7aZdw/o8IJppUZzB9r8PuFxYBACzNTAAAxaVqSCQSGBk8+HwhNzSAVCLBX5ev6RwbEXkQ3SYuwLC5K7Fx7yGUqh/8wS8uLYWRoe5nFLmhITLu5Qi33M9cScGLno11YpQtm+DslZSndXlUB9hYSKAwk+DyzQf/voqKgRuZGrg56v566tbGEHNHGWPyYDm6tDbAw2sruzlIcTVNA/VD+ezfNzSwt5bCxKjsdQMHqc55ymLUaODAX4P0eMVF9wGJBEbGCgCARl0MmYGhTgXMwLCsWp9x/VSV+81MSYBjw3aQGRgJbS5NOiLndjJUhTlPafRUVRKpRLRNn9VoRfP27dtYv3494uLihK9EcnR0xEsvvYRRo0ahXr16T+iBHkWj0eDzH/bAu4kbPFzKFlZt1cgVJnJDrNixFxMHlT1VtnJHFNQaDW5n3xeOHdbjJTR3qw+FmQnOJKXgix+jcDs7F1OH9QUAKFs2xZIf9uDYhSS0b94INzLvYNO+wwCArOxcONtZ407OfdgqdCuitgpz5BWqUFRcAmMjw2fxNlAtZ2Fa9gs4r1D31vX9Qi0sTB68/uOsGrdua1BQpEVDRyl6+RrCwlSCPXElQj9371fso3xfYbEWFqaSChXRvEKtMAaiypSWqHBy3xI0ahUAI2NzAIBTI18c+/VTnD38LTyVI1FaUoiT+5YCAAruZ1W578K827CwdtFpMza3Ldt3/zbkJpZP6SqIak6NJZonTpyAv78/TE1N4efnh6ZNy26nZmRkYOXKlfjkk0+wb98+tGvX7rH9qFQqqFQqnbbS4hLI9TyR+eT7/+HKzQys/yBIaLNWmOPTd4cj/LtfsPW3OEglEvj7tkJzN2dIH/rE9aZ/J+Hnpq5OMJDJ8PF3OzFpcC8YGRpgYJf2uJl5B1OWb0SpWgMzEzmG+b2Er36JgbSWrENGdcvhMw/mZqbfVaNUDQzqbIi9x0p0qphET5NGXYLft4YAWi1e6jdXaLd2aILOg8Nx/NdPcXL/MkgkUngqR8LE3A4S/g58bnGOpjhqLNGcNGkSXn/9daxdu7bC/zG1Wi2CgoIwadIkxMXFPbaf8PBwzJ8/X6ctbMwb+HCseMsU1HafbPoFhxMuYV3Y23Cw0f1ErGzZFP9bPA337ufDQCaFhakJekz+CPXr2TyyP6/GrihVa5B6+x4aOtWDRCLB5Dd6Y+Jgf9zJuQ9rCzMcv3AFAODy//3YWlrgTu59nX7u5ObB3ETOaiYJ7heUVR3NTSTCzwBgYSJB6p1HP6BzI1MDmUwCGwsJsnK0uF+ghbmJ7u8Ri/9/Xd5vWYxuP/88L1E5jboEsT+EIC87Fb3HbhCqmeUat+6Lxq37ojDvNgwMTQCJBOf/iICFtWuVz2FibofCvDs6bUX//9rEwu6/XwRVi77f4hZLjaXvp0+fRkhISKWf/iQSCUJCQpCQkPDEfsLCwpCTk6OzvT9yoAgjrv20Wi0+2fQLfj91AV9NH/fY5NHawgwWpiY4fuEK7t7PRxfvFo+MTUxJhVQigY1C9xetTCqFvbUlDA0MEHXsNFo1bgDr/49p1bgBTvx/8lnu2PkkeDVu8B+ukOqau/e1yM3Xokl9mdAmNwRc7aW4nv7oUqWznRQajVa45X49Q4NGTlI8XJBo4iJF5j0NCovLXqdkaODx0HnKY1IyWBIlXeVJZu6d6+g1Zj2MTa0fGWtibgdDuRmSz+yFzEAOZ4+Xqnwe+wbeSL92Ehr1g4fRbiUdhaWdO2+bU51RYxVNR0dHHD9+HM2bN690//Hjx6u08rxcLhe+Tqlcvp5WzD7Z9Av2/nkay94bCVMTOW7nlFUUzU2MhSriL4dPwt3ZHtYWZjiTlILPt+zGiJ4vC2ttnk66jnNXb6B988YwNZbjzJXrWPJDJPoovaH4/4eK7t3PR8zJc/Bp7o7iklL873A8fjtxFt/MfFsYy+BuvtgWE4fl2/eifycfnLh4BdEnzmLFlMBn/K5QTTMyAGwtH3ygtFFI4GQrQaEKyM7T4sjZUrziY4DbORrcva9Fz/aGyC3Q4vy1sgd3GjhI0cBegiupGqiKATdHKV59yRCnLquFJDIhSY0e7QzxehdDHEgohaONFB29DLD76IM/4EfOqhHUzwidWxngYooa3h4yuNST4qeDulNvqO4rUeUj986DBxPv37uJO6kXITe1hKlFPcRumYI7aRfgN/JLaDVqYd6l3MRSeHDnQtxm2DfwhqHcFLeSjuJE1Odo1zMUchOF0G/unesoURWg8P5tlJYW4U7qRQCAlX1jyAyM0Lh1XyTErsHhn2ehVedxuJdxGReObsKLfWY+w3eDyrGiKY4a+2ag1atXY+rUqXjnnXfQvXt3IanMyMhATEwMvvnmG3z++ed49913q923vn4zUNvRYZW2zxs7WFgofeWOKOw+Eo+c/EI421lhcDdfjOjZUagsX7x2C+GbfsG1tCyUlJbCuZ4NApRt8KZ/R+FJ83v38zFlxUYk3cyAVqtFK48GCB7Ys0K18uSlq1jywx5cTc2Eg7UlxvXT7wXb9fWbgRo5SxHUr+L6mScTS7H997JEsGc7A/h6GsDYqOKC7fXtJBjQyQj2VhIYyIC7uVqcuqzGodOlOvMzdRdsB46eK9VZ0B0oW7C914sPFmz/9U/9XrBdX78ZKO3qcez9tuKHXo82A9Cm+0Ts+Nyv0uN6j90Ip0Zl6wsf3DEDNxMPoqS4AJb1GsGr42h4tOmvE//rureQnnyiQj+vv/8bLKzrA9BdsF1uag1P5Qi06jz+v17ic6smvxkoM+wt0fq2D/9OtL5ruxr9Cspt27Zh2bJliI+Ph/r/l8+RyWTw8fFBaGgo3njj360jpq+JJtVu+ppoUu2lr4km1V41mmh+OEq0vu0/ihCt79quRpc3GjJkCIYMGYKSkhLcvn0bAGBnZwdDQ/289U1ERERUl9SKbwYyNDSEk5NTTQ+DiIiI9BSXphIHF40iIiIiIlHUioomERERUU3igu3iYKJJREREeo/LG4mD6TsRERERiYIVTSIiIiLeOhcF31UiIiIiEgUrmkRERKT3OEdTHKxoEhEREZEoWNEkIiIivSeRsPYmBr6rRERERCQKVjSJiIiIOEdTFEw0iYiISO/xm4HEwXeViIiIiETBiiYRERHpPS5vJA5WNImIiIhIFKxoEhEREXF5I1HwXSUiIiIiUbCiSURERHqPczTFwYomEREREYmCFU0iIiIirqMpCiaaREREpPckEt46FwPTdyIiIiISBSuaRERERLx1Lgq+q0REREQkClY0iYiISO9xeSNxsKJJRERERKJgRZOIiIiIX0EpCr6rRERERCQKVjSJiIiIOEdTFKxoEhERkd6TSKSibdXx5ZdfolWrVlAoFFAoFFAqldi7d6+wv2vXrpBIJDpbUFCQTh8pKSkICAiAqakp7O3tMW3aNJSWlurEHDhwAG3btoVcLoeHhwciIiIqjGX16tVo2LAhjI2N4evri+PHj1frWgAmmkRERES1houLCz755BPEx8fj5MmTeOWVV9C/f3+cP39eiBk/fjzS0tKEbfHixcI+tVqNgIAAFBcX4+jRo9i4cSMiIiIwZ84cISY5ORkBAQHo1q0bEhISMGXKFIwbNw779u0TYrZt24bQ0FDMnTsXp06dQuvWreHv74/MzMxqXY9Eq9Vq/8P7USvlH/25podAVMH8M71reghEOmzt5DU9BCIdMwbXXP0r/5tZovVtNn7RfzrexsYGn332GcaOHYuuXbvC29sby5cvrzR279696Nu3L1JTU+Hg4AAAWLt2LWbMmIGsrCwYGRlhxowZiIyMxLlz54Tjhg4diuzsbERFRQEAfH190b59e6xatQoAoNFo4OrqikmTJmHmzJlVHjsrmkREREQiUqlUyM3N1dlUKtUTj1Or1di6dSvy8/OhVCqF9s2bN8POzg4tW7ZEWFgYCgoKhH1xcXHw8vISkkwA8Pf3R25urlAVjYuLg5+fn865/P39ERcXBwAoLi5GfHy8ToxUKoWfn58QU1VMNImIiEjvSaRS0bbw8HBYWlrqbOHh4Y8cy9mzZ2Fubg65XI6goCDs3LkTnp6eAIDhw4fj+++/x++//46wsDBs2rQJb775pnBsenq6TpIJQHidnp7+2Jjc3FwUFhbi9u3bUKvVlcaU91FVfOqciIiISERhYWEIDQ3VaZPLHz11pVmzZkhISEBOTg5+/PFHBAYG4uDBg/D09MTbb78txHl5ecHJyQndu3fHlStX0LhxY9Gu4d9ioklEREQkEW95I7lc/tjE8p+MjIzg4eEBAPDx8cGJEyewYsUKfPXVVxVifX19AQBJSUlo3LgxHB0dKzwdnpGRAQBwdHQU/re87eEYhUIBExMTyGQyyGSySmPK+6gq3jonIiIiqsU0Gs0j53QmJCQAAJycnAAASqUSZ8+e1Xk6PDo6GgqFQrj9rlQqERMTo9NPdHS0MA/UyMgIPj4+OjEajQYxMTE6c0WrghVNIiIiImntqL2FhYWhd+/eaNCgAe7fv48tW7bgwIED2LdvH65cuYItW7agT58+sLW1xZkzZxASEoLOnTujVatWAICePXvC09MTI0eOxOLFi5Geno5Zs2YhODhYqKoGBQVh1apVmD59OsaMGYPY2Fhs374dkZGRwjhCQ0MRGBiIdu3a4cUXX8Ty5cuRn5+P0aNHV+t6mGgSERERiXjrvDoyMzPx1ltvIS0tDZaWlmjVqhX27duHHj164MaNG/jtt9+EpM/V1RWDBg3CrFkPlmaSyWTYs2cPJkyYAKVSCTMzMwQGBmLBggVCjLu7OyIjIxESEoIVK1bAxcUF69atg7+/vxAzZMgQZGVlYc6cOUhPT4e3tzeioqIqPCD0JFxHk+gZ4TqaVNtwHU2qbWpyHc2CjQueHPQvmQbOeXJQHcWKJhEREek9SS25dV7X8F0lIiIiIlGwoklEREQkYe1NDHxXiYiIiEgUrGgSERERSWvHU+d1DSuaRERERCQKVjSJiIhI70k4R1MUTDSJiIiIeOtcFEzfiYiIiEgUrGgSERER8da5KPiuEhEREZEoWNEkIiIiknCOphhY0SQiIiIiUbCiSURERCRl7U0MfFeJiIiISBSsaBIRERHxqXNRMNEkIiIi4oLtomD6TkRERESiYEWTiIiIiLfORcF3lYiIiIhEwYomERERERdsFwUrmkREREQkClY0iYiIiLhguyj4rhIRERGRKFjRJCIiIuIcTVGwoklEREREomBFk4iIiIjraIqCiSYRERERHwYSBd9VIiIiIhIFK5pEREREfBhIFHUy0RzxfcuaHgJRBfOv+tf0EIh0fOCypqaHQKRjxmD+/a5r6mSiSURERFQtfBhIFHxXiYiIiEgUrGgSERERcY6mKFjRJCIiIiJRsKJJRERExHU0RcFEk4iIiPSelrfORcH0nYiIiIhEwYomEREREZc3EgXfVSIiIiISBSuaRERERKxoioLvKhERERGJgokmERER6T2tRCLaVh1ffvklWrVqBYVCAYVCAaVSib179wr7i4qKEBwcDFtbW5ibm2PQoEHIyMjQ6SMlJQUBAQEwNTWFvb09pk2bhtLSUp2YAwcOoG3btpDL5fDw8EBERESFsaxevRoNGzaEsbExfH19cfz48WpdC8BEk4iIiKjWcHFxwSeffIL4+HicPHkSr7zyCvr374/z588DAEJCQrB7927s2LEDBw8eRGpqKgYOHCgcr1arERAQgOLiYhw9ehQbN25EREQE5syZI8QkJycjICAA3bp1Q0JCAqZMmYJx48Zh3759Qsy2bdsQGhqKuXPn4tSpU2jdujX8/f2RmZlZreuRaLVa7X98T2qdAe/+XdNDIKpg/tVxNT0EIh0fuKyp6SEQ6Yhc17LGzl1waLtofZt2fuM/HW9jY4PPPvsMgwcPRr169bBlyxYMHjwYAHDp0iW0aNECcXFx6NChA/bu3Yu+ffsiNTUVDg4OAIC1a9dixowZyMrKgpGREWbMmIHIyEicO3dOOMfQoUORnZ2NqKgoAICvry/at2+PVatWAQA0Gg1cXV0xadIkzJw5s8pjZ0WTiIiISCIRbVOpVMjNzdXZVCrVE4ekVquxdetW5OfnQ6lUIj4+HiUlJfDz8xNimjdvjgYNGiAuLg4AEBcXBy8vLyHJBAB/f3/k5uYKVdG4uDidPspjyvsoLi5GfHy8ToxUKoWfn58QU1VMNImIiIhEFB4eDktLS50tPDz8kfFnz56Fubk55HI5goKCsHPnTnh6eiI9PR1GRkawsrLSiXdwcEB6ejoAID09XSfJLN9fvu9xMbm5uSgsLMTt27ehVqsrjSnvo6q4vBERERGRiN91HhYWhtDQUJ02uVz+yPhmzZohISEBOTk5+PHHHxEYGIiDBw+KNj4xMdEkIiIiEpFcLn9sYvlPRkZG8PDwAAD4+PjgxIkTWLFiBYYMGYLi4mJkZ2frVDUzMjLg6OgIAHB0dKzwdHj5U+kPx/zzSfWMjAwoFAqYmJhAJpNBJpNVGlPeR1Xx1jkRERHpvdqyvFFlNBoNVCoVfHx8YGhoiJiYGGFfYmIiUlJSoFQqAQBKpRJnz57VeTo8OjoaCoUCnp6eQszDfZTHlPdhZGQEHx8fnRiNRoOYmBghpqpY0SQiIiKqJcLCwtC7d280aNAA9+/fx5YtW3DgwAHs27cPlpaWGDt2LEJDQ2FjYwOFQoFJkyZBqVSiQ4cOAICePXvC09MTI0eOxOLFi5Geno5Zs2YhODhYqKoGBQVh1apVmD59OsaMGYPY2Fhs374dkZGRwjhCQ0MRGBiIdu3a4cUXX8Ty5cuRn5+P0aNHV+t6mGgSERER1ZKvoMzMzMRbb72FtLQ0WFpaolWrVti3bx969OgBAFi2bBmkUikGDRoElUoFf39/rFnzYKkymUyGPXv2YMKECVAqlTAzM0NgYCAWLFggxLi7uyMyMhIhISFYsWIFXFxcsG7dOvj7+wsxQ4YMQVZWFubMmYP09HR4e3sjKiqqwgNCT8J1NImeEa6jSbUN19Gk2qYm19HMj9slWt9mygGi9V3bsaJJREREek9bSyqadQ0TTSIiIqKn8NAOVcT0nYiIiIhEwYomERER6T3eOhcH31UiIiIiEgUrmkREREScoykKVjSJiIiISBSsaBIRERFxjqYo+K4SERERkShY0SQiIiK9p+UcTVEw0SQiIiLirXNR8F0lIiIiIlGwoklERER6TwveOhcDK5pEREREJApWNImIiEjv8SsoxcF3lYiIiIhEwYomERERESuaouC7SkRERESiYEWTiIiI9B4XbBcHE00iIiLSe3wYSBx8V4mIiIhIFKxoEhEREfHWuSiqlGj+73//q3KH/fr1+9eDISIiIqK6o0qJ5oABA6rUmUQigVqt/i/jISIiInrmOEdTHFVKNDUajdjjICIiIqI65j/N0SwqKoKxsfHTGgsRERFRjdCCczTFUO06sVqtxsKFC1G/fn2Ym5vj6tWrAIDZs2fj22+/feoDJCIiIqLnU7UTzY8++ggRERFYvHgxjIyMhPaWLVti3bp1T3VwRERERM+CViIVbdNn1b767777Dl9//TVGjBgBmUwmtLdu3RqXLl16qoMjIiIieiYkEvE2PVbtRPPWrVvw8PCo0K7RaFBSUvJUBkVEREREz79qJ5qenp44fPhwhfYff/wRbdq0eSqDIiIiInqWtJCKtumzaj91PmfOHAQGBuLWrVvQaDT4+eefkZiYiO+++w579uwRY4xERERE9Byqdprdv39/7N69G7/99hvMzMwwZ84cXLx4Ebt370aPHj3EGCMRERGRqLQSiWibPvtX62h26tQJ0dHRT3ssRERERFSH/OsF20+ePImLFy8CKJu36ePj89QGRURERPQs6fsyRGKpdqJ58+ZNDBs2DH/88QesrKwAANnZ2XjppZewdetWuLi4PO0xEhEREdFzqNrp+7hx41BSUoKLFy/i7t27uHv3Li5evAiNRoNx48aJMUYiIiIiUWkhEW3TZ9WuaB48eBBHjx5Fs2bNhLZmzZrhiy++QKdOnZ7q4IiIiIieBd46F0e131VXV9dKF2ZXq9VwdnZ+KoMiIiIioudftRPNzz77DJMmTcLJkyeFtpMnT2Ly5Mn4/PPPn+rgiIiIiJ4FLm8kjirdOre2tobkoTcqPz8fvr6+MDAoO7y0tBQGBgYYM2YMBgwYIMpAiYiIiOj5UqVEc/ny5SIPg4iIiKjm6PtDO2KpUqIZGBgo9jiIiIiIqI75T49YFRUVITc3V2cjIiIiet5oJVLRtuoIDw9H+/btYWFhAXt7ewwYMACJiYk6MV27doVEItHZgoKCdGJSUlIQEBAAU1NT2NvbY9q0aSgtLdWJOXDgANq2bQu5XA4PDw9ERERUGM/q1avRsGFDGBsbw9fXF8ePH6/W9VQ70czPz8fEiRNhb28PMzMzWFtb62xERERE9O8cPHgQwcHB+PPPPxEdHY2SkhL07NkT+fn5OnHjx49HWlqasC1evFjYp1arERAQgOLiYhw9ehQbN25EREQE5syZI8QkJycjICAA3bp1Q0JCAqZMmYJx48Zh3759Qsy2bdsQGhqKuXPn4tSpU2jdujX8/f2RmZlZ5eupdqI5ffp0xMbG4ssvv4RcLse6deswf/58ODs747vvvqtud0REREQ1rrYs2B4VFYVRo0bhhRdeQOvWrREREYGUlBTEx8frxJmamsLR0VHYFAqFsG///v24cOECvv/+e3h7e6N3795YuHAhVq9ejeLiYgDA2rVr4e7ujiVLlqBFixaYOHEiBg8ejGXLlgn9LF26FOPHj8fo0aPh6emJtWvXwtTUFOvXr6/y9VQ70dy9ezfWrFmDQYMGwcDAAJ06dcKsWbPw8ccfY/PmzdXtjoiIiKhOU6lUFaYaqlSqKh2bk5MDALCxsdFp37x5M+zs7NCyZUuEhYWhoKBA2BcXFwcvLy84ODgIbf7+/sjNzcX58+eFGD8/P50+/f39ERcXBwAoLi5GfHy8ToxUKoWfn58QUxXVTjTv3r2LRo0aAQAUCgXu3r0LAOjYsSMOHTpU3e6IiIiIapyYczTDw8NhaWmps4WHhz9xTBqNBlOmTMHLL7+Mli1bCu3Dhw/H999/j99//x1hYWHYtGkT3nzzTWF/enq6TpIJQHidnp7+2Jjc3FwUFhbi9u3bUKvVlcaU91EV1f4KykaNGiE5ORkNGjRA8+bNsX37drz44ovYvXs3rKysqtsdiWhogC2GBtjqtN1ML8bEBddgb2OArxc1qvS4xd+k4uhfeQCAXWuaVtj/+bdpOBJ/X3jdu7Ml+nS1gr2NIW7fK8WOqDs4cOx+heOI7N8YAacx7yBr5w6kfvUFZOYWcBw5BuY+7WFUzwGlOdnIiTuM9I3fQlOQX+F4mYUCTdesh1E9e5wd1Aea/LwKMaaeLeHx2UoUXUvG38FjhXaHN0fD8c3ROrFFN64jcfzIp3+h9FwZ3s8eI/rZ67TdSFMhaPZlAIChgQTj3nBE5xctYWggwanzeVizORXZuWoh/p1hTvD0MIWbsxw30lSYtOBKhfM0dJFjwnBnNHU3Qc59NXbH3sFPUbfFvTiqMjGXNwoLC0NoaKhOm1wuf+JxwcHBOHfuHI4cOaLT/vbbbws/e3l5wcnJCd27d8eVK1fQuHHjpzPop6Taiebo0aNx+vRpdOnSBTNnzsSrr76KVatWoaSkBEuXLhVjjPQfXE9VYe7Km8JrtVoLALh9rxSjZur+Iuz5siVe62GDUxd0/8Cv/C5dpy2/QCP83KuTJUb2t8PqLRlIuqZCk4bGCB7hgPwCDU6crZgokP4yadocNn36ofBqktBmaGsHA1s7pH2zBkUp12Bk7wiXSVNhaGOH6x/NqdCHa8gMFCVfhVE9+wr7AEBqZo4G73+IvIRTMLCq+HBi4bWruBr24Je9Vq2uEEP66dqtIsxack14rdZohZ/HD3VEey8LhK+9gYJCNYKGO+PDdxtg2ifJOn3sP3IPzdxN4O5iXKF/E2MpFoU0RMLFfKz+PhUN6xtj8qj6yC9QI+rQPdGui2oHuVxepcTyYRMnTsSePXtw6NAhuLi4PDbW19cXAJCUlITGjRvD0dGxwtPhGRkZAABHR0fhf8vbHo5RKBQwMTGBTCaDTCarNKa8j6qodqIZEhIi/Ozn54dLly4hPj4eHh4eaNWqVXW7I5Fp1FqdT91CuxYV2jt4m+OPU/dRpNLqtOcXqivtAwC6+iqw70gO/ogvqyxl3ClBEzc5Xuthw0STBFJjE7hNn42bKxbDYdhbQnvR9WRcXzRbeF2cloq0jd+gwbRZgFQGaB78u7MN6A+ZuTkyNm+E4sUOlZ7HZdJUZB/4DVqNBpbKjhUD1GqU3rv79C6M6gyNWot7uaUV2k1NpOjZ0RqffXMTZy6V/U5bvuEmvlrUFM0amSDxaiEA4Ksf0gAAlhb2lSaa3TpYwcBAguUbbqFUrUVKqgqNGhhjQA87Jpq1RHWXIRKLVqvFpEmTsHPnThw4cADu7u5PPCYhIQEA4OTkBABQKpX46KOPkJmZCXv7sg/m0dHRUCgU8PT0FGJ+/fVXnX6io6OhVCoBAEZGRvDx8UFMTIzwrY8ajQYxMTGYOHFila+n2onmP7m5ucHNze2/dkMicbI3wvqPG6G4VIPEq0XY9Mtt3L5X8ZdpY1c5Grka46ttFZcseHuIA4JHSJB+uwT7DmcjJu7BeqmGBhKUlOgmpqoSLZo0NIZMCqg1/+yN9FH94BDkHo9D3l/xOolmZWRmZtAUFOgkmfIGbnAYMQqXJ78DIyfnSo+z7tEbcidnpCxeBIfhlZ/DqL4LPDf/DE1xMQounkfahq9QklX1ZTqo7nJ2kOO7z5uhpESLi1cKsPHnDGTdLYGHmwkMDaRIuPBgmsbN9GJk3ilGi8amQqL5JM0bmeDc3wUoVT/4fXnqXB5e710P5qZS5BXwlyWVCQ4OxpYtW/DLL7/AwsJCmA9paWkJExMTXLlyBVu2bEGfPn1ga2uLM2fOICQkBJ07dxYKfj179oSnpydGjhyJxYsXIz09HbNmzUJwcLBQWQ0KCsKqVaswffp0jBkzBrGxsdi+fTsiIyOFsYSGhiIwMBDt2rXDiy++iOXLlyM/Px+jR4+uOPBHqFKiuXLlyip3+N5771U5lsT1d3IhVn6nwq3MYlgrDDA0wBYfh7rivUXXKlQt/V62xI00FRKvFum0b9l9G2cSC6Aq1sK7hSneGWoPY7kUkQeyAQB/XciH38uWOHY6D1duqNC4gRw9Xiqbx6Qwl+HeIyqhpD+surwCE4+muPze20+MlSks4TAsEHf2/k9okxgawm3mXKSuW4OSrMxKE00jZxc4jXkHSe9P1ElQH1Zw6QJuLAmH6mYKDG1s4TBiNDw+X4XEoEBoCquWLFDdlHi1AMvW38TNDBVsLA0x/FV7LJ7hjnfnJMFaYYCSEg3yC3UTwXu5pbBWVL1WY21piIzbxRX6KN+XV1C1J5BJPLXlKyi//PJLAGWLsj9sw4YNGDVqFIyMjPDbb78JSZ+rqysGDRqEWbNmCbEymQx79uzBhAkToFQqYWZmhsDAQCxYsECIcXd3R2RkJEJCQrBixQq4uLhg3bp18Pf3F2KGDBmCrKwszJkzB+np6fD29kZUVFSFB4Qep0r/L3l4TaXHkUgkTzXRvHHjBubOnfvY9ZpUKlWFJQLU6mLIZEZPbRzPq1MXHix1cP1WMS5fK8LXi9zR0ccCvx19UJU0MpSgczsLbN9b8Zbiw23JN1UwlkvxWg9rIdHcvvcurBQG+HR6A0gAZN9X4/djuRjY0wYabYXuSM8Y2tnDOeg9XP0gFNqS4sfGSk1N4b7gUxSlXEP69xuEdqfRb6Mo5TqyY6MfcaAUbjNnI2PTehTfull5DID7J48JPxclX0X+pYvw/G47rDq/grv7Ih95HNV98eceVCuv3VQh8WoBNnzaDJ3aW0JVzEojPVta7eP/eLq6uuLgwYNP7MfNza3CrfF/6tq1K/7666/HxkycOLFat8r/qUqJZnJy8pODRHD37l1s3LjxsYlmeHg45s+fr9PWrN1ENG8/SezhPXfyCzVIzSyBYz3dJPylNuYwMpLi92NP/grRv68VYUgfWxgYSFBaqkVxiRarvs/Al1syYKUwwL2cUvTsaImCQjVy81jN1HcmTZrC0NoGTVetE9okMgOYtWwNu36v4cyrfoBGA6mJCRot+hyawgJcWzALeOghHfPWbWHcsBGsOnUp7wEA0HL7/5DxwyZk7dwB06YtYNK4CeoHT/n/ECkkUilaRcbi6gfvI+/0qQpj0+TnQXXrBoyc64t1+fScyi/U4FaGCk72RvjrQh4MDaUwM5HqVDWtFQaVzul8lHs5JbD6RwW0vCJ6L6fk6Qyc/hOtpHZUNOua/zxH87/43//+99j9V69efWIflS0ZMGJayn8aV11lLJfA0c4QB3J0fzn6vWSJE2fyqpQYurvIcT9fjdJS3U9cag1wJ7us347tLHDyXD6e8KGM9EBeQjwS3wnUaXOdOhNFN1KQtX1LWZJpaopGH30ObUkJkueFVah8Xls0G1KjB09rmjRtjgZTw5D0/iQUp96CpiC/wjls+w6AuXdbXF80B8XpaZWOTWpsAiOn+iiN2f+UrpbqCmO5FE72Roj9MxtJ1wtRUqpB6xbmOHqq7MN4fQcj2Nsa4eKVgif09MClq4V46zV7yGQPPkd5e5rjRpqK8zOpTqvRRHPAgAGQSCSPLRNLnvAJo7IlA3jbvMyogXY4cTYfWXdKYG1lgGEBttBotDh88sEal471DOHpYYKFa25VOL69lxksLWT4O7kIxaVaeDc3xWB/G+z67cETks72hmjS0Bh/JxfB3FSGft2t0MBJjpUbq76YK9VdmsJCFF3XvSOiKSqCOjcXRdeT/z/JXAKpsTGuLV4EmakZYGoGACjNyQY0GhSnpeocL7O0BAAUpVwX1tH85zlKc7KhLS7WaXca9y5yj/2B4swMGNrYwXHkaECtwb0Dvz3ty6bnzNjXHXHsdC4y75TA1soAI/o7QKMBDh7LQUGhBvuP3MP4IY7Iy1ejoEiNoGHOuJhUoPMgkJO9EUzkUlgrDGBkJEUj17Inz1NSVShVa3HgWDaGv1oPkwPr48eo23CrL0d/P1t8s63yD0L07Gm1rGiKoUYTTScnJ6xZswb9+/evdH9CQgJ8fHye8ajqDlsrA0wd7QQLMyly8tS4eKUQMz67oVO59FMqcCe7FAkXK34yL1Vr0aeLFcYOLkvc07OKsf6nLET/kSPESKUS9O9ujfoORihVa3Hu70LM/DwFmXerfkuJ9JeJR1OYtXgBANBiw1adfRcC30BJxtP7wGJoVw9uM+dCZqFAaU428s+fxeWQIKhzcp58MNVpttYGmP62KxRmMuTcV+N8Uj5CP74q/K78Zms6tBrgg3ddYWggxanz97Hme90E8b3A+mjVzEx4/cVcDwDA6BmJyLxTgoJCDWYtu4YJw52xYnZj5N5X44fdmVzaqBbRVv/LEqkKJNonzToVUb9+/eDt7a3zFNTDTp8+jTZt2kCjqd5thQHv/v00hkf0VM2/Oq6mh0Ck4wOXNTU9BCIdketaPjlIJJevXBet7yaN9XcZyBqtaE6bNg35+Y9e1NvDwwO///77MxwRERER6aPasrxRXfOv6sSHDx/Gm2++CaVSiVu3yub2bdq0qcJ3cT5Jp06d0KtXr0fuNzMzQ5cuXR65n4iIiIhqr2onmj/99BP8/f1hYmKCv/76S1jDMicnBx9//PFTHyARERGR2LSQiLbps2onmosWLcLatWvxzTffwNDQUGh/+eWXcepUxbXqiIiIiEg/VXuOZmJiIjp37lyh3dLSEtnZ2U9jTERERETPlL5XHsVS7Yqmo6MjkpKSKrQfOXIEjRo1eiqDIiIiIqLnX7UTzfHjx2Py5Mk4duwYJBIJUlNTsXnzZrz//vuYMGGCGGMkIiIiEhXnaIqj2rfOZ86cCY1Gg+7du6OgoACdO3eGXC7H+++/j0mT+P3iRERE9PzhNwOJo9qJpkQiwYcffohp06YhKSkJeXl58PT0hLm5uRjjIyIiIqLn1L9esN3IyAienp5PcyxERERENULfb3GLpdqJZrdu3SCRPPo/Rmxs7H8aEBERERHVDdVONL29vXVel5SUICEhAefOnUNgYODTGhcRERHRM8OKpjiqnWguW7as0vZ58+YhLy/vPw+IiIiIiOqGf/Vd55V58803sX79+qfVHREREdEzw+WNxPHUEs24uDgYGxs/re6IiIiI6DlX7VvnAwcO1Hmt1WqRlpaGkydPYvbs2U9tYERERETPCtfRFEe1E01LS0ud11KpFM2aNcOCBQvQs2fPpzYwIiIiomdFo+e3uMVSrURTrVZj9OjR8PLygrW1tVhjIiIiIqI6oFpzNGUyGXr27Ins7GyRhkNERET07PFhIHFU+2Ggli1b4urVq2KMhYiIiIjqkGonmosWLcL777+PPXv2IC0tDbm5uTobERER0fNGq5WItumzKs/RXLBgAaZOnYo+ffoAAPr166fzVZRarRYSiQRqtfrpj5KIiIiInjtVTjTnz5+PoKAg/P7772KOh4iIiOiZ0/e5lGKpcqKp1WoBAF26dBFtMERERERUd1RreaOHb5UTERER1RX6PpdSLNVKNJs2bfrEZPPu3bv/aUBEREREzxpvnYujWonm/PnzK3wzEBERERFRZaqVaA4dOhT29vZijYWIiIioRvDWuTiqvI4m52cSERERUXVU+6lzIiIiorpGU9MDqKOqnGhqNPxPQERERERVV605mkRERER1EedoiqPa33VORERERFQVrGgSERGR3uM6muJgoklERER6j7fOxcFb50REREQkClY0iYiISO/x1rk4WNEkIiIiqiXCw8PRvn17WFhYwN7eHgMGDEBiYqJOTFFREYKDg2Frawtzc3MMGjQIGRkZOjEpKSkICAiAqakp7O3tMW3aNJSWlurEHDhwAG3btoVcLoeHhwciIiIqjGf16tVo2LAhjI2N4evri+PHj1frephoEhERkd7TaMXbquPgwYMIDg7Gn3/+iejoaJSUlKBnz57Iz88XYkJCQrB7927s2LEDBw8eRGpqKgYOHCjsV6vVCAgIQHFxMY4ePYqNGzciIiICc+bMEWKSk5MREBCAbt26ISEhAVOmTMG4ceOwb98+IWbbtm0IDQ3F3LlzcerUKbRu3Rr+/v7IzMys8vVItHXwK38GvPt3TQ+BqIL5V8fV9BCIdHzgsqamh0CkI3Jdyxo796Hz+U8O+pc6v2D2r4/NysqCvb09Dh48iM6dOyMnJwf16tXDli1bMHjwYADApUuX0KJFC8TFxaFDhw7Yu3cv+vbti9TUVDg4OAAA1q5dixkzZiArKwtGRkaYMWMGIiMjce7cOeFcQ4cORXZ2NqKiogAAvr6+aN++PVatWgWg7Mt7XF1dMWnSJMycObNK42dFk4iIiPSeFhLRNpVKhdzcXJ1NpVJVaVw5OTkAABsbGwBAfHw8SkpK4OfnJ8Q0b94cDRo0QFxcHAAgLi4OXl5eQpIJAP7+/sjNzcX58+eFmIf7KI8p76O4uBjx8fE6MVKpFH5+fkJMVTDRJCIiIhJReHg4LC0tdbbw8PAnHqfRaDBlyhS8/PLLaNmyrNqbnp4OIyMjWFlZ6cQ6ODggPT1diHk4ySzfX77vcTG5ubkoLCzE7du3oVarK40p76Mq+NQ5ERER6T0x19EMCwtDaGioTptcLn/iccHBwTh37hyOHDki1tBEx0STiIiI9J6YT6zI5fIqJZYPmzhxIvbs2YNDhw7BxcVFaHd0dERxcTGys7N1qpoZGRlwdHQUYv75dHj5U+kPx/zzSfWMjAwoFAqYmJhAJpNBJpNVGlPeR1Xw1jkRERFRLaHVajFx4kTs3LkTsbGxcHd319nv4+MDQ0NDxMTECG2JiYlISUmBUqkEACiVSpw9e1bn6fDo6GgoFAp4enoKMQ/3UR5T3oeRkRF8fHx0YjQaDWJiYoSYqmBFk4iIiPSeppYs2B4cHIwtW7bgl19+gYWFhTAf0tLSEiYmJrC0tMTYsWMRGhoKGxsbKBQKTJo0CUqlEh06dAAA9OzZE56enhg5ciQWL16M9PR0zJo1C8HBwUJlNSgoCKtWrcL06dMxZswYxMbGYvv27YiMjBTGEhoaisDAQLRr1w4vvvgili9fjvz8fIwePbrK18NEk4iIiKiW+PLLLwEAXbt21WnfsGEDRo0aBQBYtmwZpFIpBg0aBJVKBX9/f6xZ82C5MplMhj179mDChAlQKpUwMzNDYGAgFixYIMS4u7sjMjISISEhWLFiBVxcXLBu3Tr4+/sLMUOGDEFWVhbmzJmD9PR0eHt7IyoqqsIDQo/DdTSJnhGuo0m1DdfRpNqmJtfR/O1M1ZYb+jf8WlVvfmZdwjmaRERERCQK3jonIiIivVf37u/WDqxoEhEREZEoWNEkIiIivaetJU+d1zVMNImIiEjvaXjrXBS8dU5EREREomBFk4iIiPSemN91rs9Y0SQiIiIiUbCiSURERHqPyxuJgxVNIiIiIhIFK5pERESk9zRc3kgUrGgSERERkShY0SQiIiK9xzma4mCiSURERHqPyxuJg7fOiYiIiEgUrGgSERGR3uNXUIqDFU0iIiIiEgUrmkRERKT3+DCQOFjRJCIiIiJRsKJJREREek/LBdtFwYomEREREYmCFU0iIiLSe3zqXBysaBIRERGRKFjRJCIiIr3Hp87FUScTTVVBUU0PgaiCYMOFNT0EIh1hGwfV9BCIdK1LrLFTM9EUB2+dExEREZEo6mRFk4iIiKg6NFoubyQGVjSJiIiISBSsaBIREZHe4xxNcbCiSURERESiYEWTiIiI9B4rmuJgRZOIiIiIRMGKJhEREek9fgWlOJhoEhERkd7TcnkjUfDWORERERGJghVNIiIi0nt8GEgcrGgSERERkShY0SQiIiK9x4eBxMGKJhERERGJghVNIiIi0nucoykOVjSJiIiISBSsaBIREZHeY0VTHEw0iYiISO/xYSBx8NY5ERERUS1y6NAhvPrqq3B2doZEIsGuXbt09o8aNQoSiURn69Wrl07M3bt3MWLECCgUClhZWWHs2LHIy8vTiTlz5gw6deoEY2NjuLq6YvHixRXGsmPHDjRv3hzGxsbw8vLCr7/+Wq1rYaJJREREek+rFW+rrvz8fLRu3RqrV69+ZEyvXr2QlpYmbD/88IPO/hEjRuD8+fOIjo7Gnj17cOjQIbz99tvC/tzcXPTs2RNubm6Ij4/HZ599hnnz5uHrr78WYo4ePYphw4Zh7Nix+OuvvzBgwAAMGDAA586dq/K18NY5ERERUS3Su3dv9O7d+7Excrkcjo6Ole67ePEioqKicOLECbRr1w4A8MUXX6BPnz74/PPP4ezsjM2bN6O4uBjr16+HkZERXnjhBSQkJGDp0qVCQrpixQr06tUL06ZNAwAsXLgQ0dHRWLVqFdauXVula2FFk4iIiPSeRiPeplKpkJubq7OpVKr/NN4DBw7A3t4ezZo1w4QJE3Dnzh1hX1xcHKysrIQkEwD8/PwglUpx7NgxIaZz584wMjISYvz9/ZGYmIh79+4JMX5+fjrn9ff3R1xcXJXHyUSTiIiISETh4eGwtLTU2cLDw/91f7169cJ3332HmJgYfPrppzh48CB69+4NtVoNAEhPT4e9vb3OMQYGBrCxsUF6eroQ4+DgoBNT/vpJMeX7q4K3zomIiEjvibm8UVhYGEJDQ3Xa5HL5v+5v6NChws9eXl5o1aoVGjdujAMHDqB79+7/ul8xsKJJREREJCK5XA6FQqGz/ZdE858aNWoEOzs7JCUlAQAcHR2RmZmpE1NaWoq7d+8K8zodHR2RkZGhE1P++kkxj5obWhkmmkRERKT3atNT59V18+ZN3LlzB05OTgAApVKJ7OxsxMfHCzGxsbHQaDTw9fUVYg4dOoSSkhIhJjo6Gs2aNYO1tbUQExMTo3Ou6OhoKJXKKo+NiSYRERHpPY1WvK268vLykJCQgISEBABAcnIyEhISkJKSgry8PEybNg1//vknrl27hpiYGPTv3x8eHh7w9/cHALRo0QK9evXC+PHjcfz4cfzxxx+YOHEihg4dCmdnZwDA8OHDYWRkhLFjx+L8+fPYtm0bVqxYoXOLf/LkyYiKisKSJUtw6dIlzJs3DydPnsTEiROrfC1MNImIiIhqkZMnT6JNmzZo06YNACA0NBRt2rTBnDlzIJPJcObMGfTr1w9NmzbF2LFj4ePjg8OHD+vcjt+8eTOaN2+O7t27o0+fPujYsaPOGpmWlpbYv38/kpOT4ePjg6lTp2LOnDk6a22+9NJL2LJlC77++mu0bt0aP/74I3bt2oWWLVtW+VokWm3d+3bP3qPO1PQQiCq4f+deTQ+BSEdY1NtPDiJ6hgJKEmvs3Kt+FS8dmthHIlrftR0rmkREREQkCi5vRERERHqv7t3frR1Y0SQiIiIiUbCiSURERHpPo6npEdRNrGgSERERkShY0SQiIiK9xzma4mCiSURERHrv3yysTk/GW+dEREREJApWNImIiEjv8da5OFjRJCIiIiJRsKJJREREek8r6iRNfgUlEREREdFTxYomERER6T0+dS4OVjSJiIiISBSsaBIREZHe41Pn4mCiSURERHpPw3vnouCtcyIiIiISBSuaREREpPd461wcrGgSERERkShY0SQiIiK9x4qmOFjRJCIiIiJRsKJJREREek/DkqYoWNEkIiIiIlGwoklERER6T6up6RHUTUw0iYiISO9peetcFLx1TkRERESiYEWTiIiI9J6Gt85FwYomEREREYmCFU0iIiLSe5yjKQ5WNImIiIhIFKxoEhERkd7TsKApClY0iYiIiEgUrGgSERGR3tOypCkKJppERESk9/gskDh465yIiIiIRMGKJhEREek9DW+di4IVTSIiIiISBSuaREREpPe4YLs4WNEkIiIiIlGwoklERER6T6up6RHUTaxoEhEREZEoWNHUI68H1MOY152wa38WvtqSJrQ3b2yKwEGOaN7YFBqNFldSCjHr82QUl2hhb2eI4f0c0LqFOawtDXA3uwSxR7OxdXcmStUV57M42Rth1fwm0GiB1989/ywvj54Tbw52RZeX7OBW3xSqYg3OXsrFlxFXceNWIQDA0V6OH7/tUOmxsz85j9//uA2PhmZ4c3ADeHkqYKUwRFpmEX7Zm4Ydu28JsZ2VdnittzM8GpnByFCK5JQCrN9yDcf/uvdMrpOeD42njUfzj99H8sqNuDD1YwBAh9++g20XX524619vxbngucJr224d0Gz+ZFi0bIbS/ALc2rQLibOXQatW6xzXKGQMXMe9ARO3+ii5fQ/X125B0idrhf1SI0M0mRUM5+H9IHesB1VaJi5/tAY3I34S8aqpMhrO0RQFK5p6oqm7Cfp0tcXVlEKd9uaNTbFoqjtOnb+PyfMv4735Sdj92x1h4VpXJzkkEuCLiJsI+vBvfLUlDX262WDUYMcK55DJgJlBDXD+7/xncUn0nGrT0go/R6binWl/IWT2GRjIJFi2oBWM5WW/jjJvq9Bv5FGdbd3maygoKMWf8XcBAM08LHAvpxgLl17CyOCT+G57Ct4JdMfAAGfhPN4vWOJEwj1Mm38OY6ecwqkz2fh0dks0aWReI9dNtY9lOy80GD8UuWcuVdiXsm4bfnN5WdguzVws7LNo1Qztd3+DzH1HcLj9APw1PAQOfV9B84+n6vThuexDuI55HRdnLMbBlr1xYuAEZJ84oxPT5ocVsH1FiTNvf4iDL/TCXyOnIv/vZHEumJ4bhw4dwquvvgpnZ2dIJBLs2rVLZ79Wq8WcOXPg5OQEExMT+Pn54fLlyzoxd+/exYgRI6BQKGBlZYWxY8ciLy9PJ+bMmTPo1KkTjI2N4erqisWLF+OfduzYgebNm8PY2BheXl749ddfq3UtrGjqAWO5FNPeaYAVG25iWD97nX3vDHfCL7/dxo7ILKHtVrpK+Dn+bB7izz74h5meVYyfouQI6GaDddvSdPoKHOiIG+kqJFzIQ4smZiJdDT3vps47q/P64+WJ2LP5JTTzsMDp8znQaIC72SU6MZ072CL2SBYKi8omUUX+lq6zPzWjCC2bK9BFaYefI1MBACvXXdGJ+XpTMjp1sMXLL9ri8lXdX7akf2RmpvDe+BnOBM1Ckw8mVNivLiiCKuN2pcc6v94H988mIumj1QCAgispuBj2Gdr+sBx/L1wNdV4+zJs3gts7w3DI+1UhcSy8dlOnn3o9O8G2c3v83tQPJfdyymKu3wLVjNr01Hl+fj5at26NMWPGYODAgRX2L168GCtXrsTGjRvh7u6O2bNnw9/fHxcuXICxsTEAYMSIEUhLS0N0dDRKSkowevRovP3229iyZQsAIDc3Fz179oSfnx/Wrl2Ls2fPYsyYMbCyssLbb78NADh69CiGDRuG8PBw9O3bF1u2bMGAAQNw6tQptGzZskrXwoqmHgge6YwTp3ORcEH3j6ulhQzNG5shJ7cUSz5sjC0rWmDxzEZ4oYnpY/szM5Hifr7u7aHWLczQsb0l1nzHX5JUPWZmMgBA7v2SSvc3a2yOpo0tsCc6vdL9Qj+mBsjNK33kfokEMDWRPfI8pF9afjEHmXsP4k5sXKX7nYe9ih5pf6LzX7vRbFEopCbGwj6p3AiaIpVOvLqwCDITY1i2fQEAYB/wCgqu3oR9n67o9ncMul2OgddXi2BobSkc4/DqK8iJP4dG749D92uH0OV8FFp8Oh1SY7kIV0xPotFoRduqq3fv3li0aBFee+21Cvu0Wi2WL1+OWbNmoX///mjVqhW+++47pKamCpXPixcvIioqCuvWrYOvry86duyIL774Alu3bkVqatmH8c2bN6O4uBjr16/HCy+8gKFDh+K9997D0qVLhXOtWLECvXr1wrRp09CiRQssXLgQbdu2xapVq6p8LUw067guvpZo7GaCDT9W/CPtZF/2y2zEAAdEHbyL2UuSkXS9EOHTG8HZwajS/pzsjdDPzw57D9wV2izMZAgd54ql626ioIiP7VHVSSTAe+M9cOZCDpJTCiqN6dvTEckp+Th3KfeR/bRsrkD3TvXwv31pj4wZ9porTIxliD2S9cgY0g9Ob/SBoo0nEj9cUun+W1v3ICFwGv7s8RaSFn+N+iP6o83Gz4T9WfuPwFrZBs5DAgCpFHJnezSZFQwAMHaqBwAwbeQKEzdnOA3uhYTR03F6bBgs276AtttWCv2YuLvC+mUfWLzQBCdfD8aFqR/DcaA/Wq6aC6pbVCoVcnNzdTaVSvXkAyuRnJyM9PR0+Pn5CW2Wlpbw9fVFXFzZB6e4uDhYWVmhXbt2Qoyfnx+kUimOHTsmxHTu3BlGRg/+3vv7+yMxMRH37t0TYh4+T3lM+XmqosYTzYsXL2LDhg24dKlsjsylS5cwYcIEjBkzBrGxsU88vrL/eBp1sdjDfi7Y2RjineHOWPzVDZSUVPxEJZGU/e+vv99F9JF7uJJShK9/SMPNdBV6drKpEG9rZYBFU91x+EQOog4+SDQnj3bBgT+zcY5zM6maQoOaoFEDM8xdfKHS/UZGUvh1dkDkY6qZ7g1MET7rBWz44TpOPOJBnx5d7DF6mBvmfHoB2TmsaOozYxdHvLD0QyS8NQ0aVeV/K26s247b0Udw/9zfSP1hN06PngHH13rCtJErAOD2b3/g4szFaLl6Pnrnn0XXC/uQtfcgAECrKfuwLZFKIDOW4/ToGbj3RzzuHjqOM29/CLtuHWDW1F2IgVaLhLfeR86Js8iKOoSL0z6By8jXWNWsAVqteFt4eDgsLS11tvDw8H81zvT0st+HDg4OOu0ODg7CvvT0dNjb606VMzAwgI2NjU5MZX08fI5HxZTvr4oanaMZFRWF/v37w9zcHAUFBdi5cyfeeusttG7dGhqNBj179sT+/fvxyiuvPLKP8PBwzJ8/X6etcesgNPGuOOdG3zRpaAJrS0Osmt9EaJPJJGjZ1AyvdrfD+JmJAICU1CKd41JSVbC3NdRps7EywCczG+NCUgFWRujOM2rtaY4ObRQY1KvskzwkgEwqwZ5vvbAy4ib2H+ZTvlRRyDseeKm9DSaGnUbWncr/4Hd72Q7GcimiYjMq3d/Q1RQrFrXG7n1p2Lg9pdKY7p3qYcakppj9yQWcPJ39tIZPzynLti9A7mCHjsd/FtqkBgaw6dQebu+OwF4zL0Cje2cm+/hpAIBpYzcUXL0BAEheHoHk5RGQO9mj5F4OTBvWR/OP30dBctnvx6K0LGhKSpB/+ZrQT97FsnnDJq5OyP87Gar0LBTdykBp7oNpTXmXrkAilcLYxREFSddFeQ/o2QsLC0NoaKhOm1yuHx8majTRXLBgAaZNm4ZFixZh69atGD58OCZMmICPPvoIQNl/mE8++eSxiWZl//FeD/5b1HE/LxIu5CHow0SdttCxrriRrsKOyEykZRXj9r0SuDjp/mN3cZTjxJn7wmvb/08yk64VYtm6G/jnfOnQhUmQPlQbV7a1xOt96iF0URLu3Hv0nDnSXyHveKCz0g6Twk4jLaPokXF9ezjhyPE7yM6tWIV0b1CWZO6NzcDXm65Verxf53oIe68Z5n52EXEn71YaQ/rlduyfOOjdV6et9bpw5CVexZXPvqmQZAKAwrsFAECVXnHahSotEwDgPKQvClNSkXOqbFm3e0dPQWpoCNNGrkJyata0IQCgMKVsjtzdo6fgNKgXZGamUOeXTR0xa+IOrVqNoptVrxjR06H9F3Mpq0oulz+1xNLRsWzVl4yMDDg5OQntGRkZ8Pb2FmIyMzN1jistLcXdu3eF4x0dHZGRofshvvz1k2LK91dFjd46P3/+PEaNGgUAeOONN3D//n0MHjxY2D9ixAicOXPmEUeXkcvlUCgUOptUVvn8Qn1TWKTB9Vsqna2oWIP7eaW4fqtsbshPe7PQ388OHdtZwsneCCMHOsDFSY79h8r+KNtaGeDTmY2RdacY67amwlJhAGvLsq3cjTTdc9y+VwKNFrh+S4W8AnWlYyP9NXWCB3p2dcD8zy+ioLAUNlaGsLEyhJGR7q+j+k7GaP2CJfbsrzjv0r2BKVZ+1BrHE+5h264bQh9WigeV+B5d7DErpDlWrb+KC4m5QoyZqUz0a6TaS52Xj7zzl3U2dX4BSu5kI+/8ZZg2coXHB+9C0fYFmLjVh33fV9B6/ae4c+g47p998MG9UehYWLRsCnNPD3h88C4aTx+P8yGLhET1dsxR5Jw6h1bffAyFdwso2r4ArzULkBV9RKhypv6wB8V3stF6XTjMWzSGTcd2aP7JNNyI+KnCw0ZE5dzd3eHo6IiYmBihLTc3F8eOHYNSqQQAKJVKZGdnIz4+XoiJjY2FRqOBr6+vEHPo0CGUlDz4IB8dHY1mzZrB2tpaiHn4POUx5eepihpf3kjy/xMFpVIpjI2NYWn54Ik8CwsL5OTk1NTQ9MKu/bdhaCjB28OcYGFugKsphfjws6tIyyq7ldmmpQXqO8pR31GO75d76hzbe9TjPwQQVea1PvUBAKvCvXXaP1p+CXtjHnxyDvBzQtYdVaULrHd7uR6srYzQq5sDenV7MH8oLaMIr48rm+jez98JBgZSTJ3QBFMnPJg+8mtMOj5enlihTyIA0BSXwK67Eu7vvQWZmSmKbqQhfed+JH28RieuXq/O8AgLglRuhNwzl3ByYDCy9h16EKDV4sSACXhh+SwoYzejNL8AWfsO4eK0T4UQdX4BjvUegxeWz0LHP39C8Z1spP24F4lzlj+jq6WH1aYF2/Py8pCUlCS8Tk5ORkJCAmxsbNCgQQNMmTIFixYtQpMmTYTljZydnTFgwAAAQIsWLdCrVy+MHz8ea9euRUlJCSZOnIihQ4fC2blsveHhw4dj/vz5GDt2LGbMmIFz585hxYoVWLZsmXDeyZMno0uXLliyZAkCAgKwdetWnDx5El9//XWVr0WircGFo1q3bo1PP/0UvXr1AgCcO3cOzZs3h4FBWf57+PBhBAYG4urVq9XqlwkQ1Ub373CuKtUuYVFv1/QQiHQElNTch8BJyx+9ssV/9cUURbXiDxw4gG7dulVoDwwMREREBLRaLebOnYuvv/4a2dnZ6NixI9asWYOmTZsKsXfv3sXEiROxe/duSKVSDBo0CCtXroS5+YMvrThz5gyCg4Nx4sQJ2NnZYdKkSZgxY4bOOXfs2IFZs2bh2rVraNKkCRYvXow+ffpU+VpqNNFcu3YtXF1dERAQUOn+Dz74AJmZmVi3bl21+mWiSbURE02qbZhoUm1Tk4nmxKXi3UFdFWr55KA6qkZvnQcFBT12/8cff/yMRkJERET6TMyHgfRZja+jSURERER1U40/DERERERU01jQFAcrmkREREQkClY0iYiISO9xjqY4WNEkIiIiIlGwoklERER6rwZXe6zTWNEkIiIiIlGwoklERER6T8M5mqJgoklERER6j7fOxcFb50REREQkClY0iYiISO9xeSNxsKJJRERERKJgRZOIiIj0Hiua4mBFk4iIiIhEwYomERER6T0NnzoXBSuaRERERCQKVjSJiIhI73GOpjiYaBIREZHe44Lt4uCtcyIiIiISBSuaREREpPf4XefiYEWTiIiIiETBiiYRERHpPT4MJA5WNImIiIhIFKxoEhERkd7jU+fiYEWTiIiIiETBiiYRERHpPa1GU9NDqJOYaBIREZHe4/JG4uCtcyIiIiISBSuaREREpPf4MJA4WNEkIiIiIlGwoklERER6jwu2i4MVTSIiIiISBSuaREREpPdY0RQHK5pEREREJApWNImIiEjvabRcsF0MTDSJiIhI7/HWuTh465yIiIiIRMGKJhEREek9VjTFwYomEREREYmCFU0iIiLSe/wKSnGwoklEREREomCiSURERHpPo9GItlXHvHnzIJFIdLbmzZsL+4uKihAcHAxbW1uYm5tj0KBByMjI0OkjJSUFAQEBMDU1hb29PaZNm4bS0lKdmAMHDqBt27aQy+Xw8PBARETEv37vHoeJJhEREVEt8sILLyAtLU3Yjhw5IuwLCQnB7t27sWPHDhw8eBCpqakYOHCgsF+tViMgIADFxcU4evQoNm7ciIiICMyZM0eISU5ORkBAALp164aEhARMmTIF48aNw759+576tXCOJhEREem92vTUuYGBARwdHSu05+Tk4Ntvv8WWLVvwyiuvAAA2bNiAFi1a4M8//0SHDh2wf/9+XLhwAb/99hscHBzg7e2NhQsXYsaMGZg3bx6MjIywdu1auLu7Y8mSJQCAFi1a4MiRI1i2bBn8/f2f6rWwoklERER6T6vViLapVCrk5ubqbCqV6pFjuXz5MpydndGoUSOMGDECKSkpAID4+HiUlJTAz89PiG3evDkaNGiAuLg4AEBcXBy8vLzg4OAgxPj7+yM3Nxfnz58XYh7uozymvI+niYkmERERkYjCw8NhaWmps4WHh1ca6+vri4iICERFReHLL79EcnIyOnXqhPv37yM9PR1GRkawsrLSOcbBwQHp6ekAgPT0dJ0ks3x/+b7HxeTm5qKwsPBpXLKAt86JiIhI74l56zwsLAyhoaE6bXK5vNLY3r17Cz+3atUKvr6+cHNzw/bt22FiYiLaGMXCiiYRERGRiORyORQKhc72qETzn6ysrNC0aVMkJSXB0dERxcXFyM7O1onJyMgQ5nQ6OjpWeAq9/PWTYhQKxVNPZploEhERkd7TarSibf9FXl4erly5AicnJ/j4+MDQ0BAxMTHC/sTERKSkpECpVAIAlEolzp49i8zMTCEmOjoaCoUCnp6eQszDfZTHlPfxNDHRJCIiIqol3n//fRw8eBDXrl3D0aNH8dprr0Emk2HYsGGwtLTE2LFjERoait9//x3x8fEYPXo0lEolOnToAADo2bMnPD09MXLkSJw+fRr79u3DrFmzEBwcLFRRg4KCcPXqVUyfPh2XLl3CmjVrsH37doSEhDz16+EcTSIiItJ7Gm31FlYXy82bNzFs2DDcuXMH9erVQ8eOHfHnn3+iXr16AIBly5ZBKpVi0KBBUKlU8Pf3x5o1a4TjZTIZ9uzZgwkTJkCpVMLMzAyBgYFYsGCBEOPu7o7IyEiEhIRgxYoVcHFxwbp165760kYAINHWwS/37D3qTE0PgaiC+3fu1fQQiHSERb1d00Mg0hFQklhj5/YPTBCt730bvUXru7ZjRZOIiIj0Xm1asL0uYaJJREREek9bze8kp6rhw0BEREREJApWNImIiEjv8da5OFjRJCIiIiJRsKJJREREek9bS5Y3qmtY0SQiIiIiUbCiSURERHpPwzmaomBFk4iIiIhEwYomERER6T2uoykOVjSJiIiISBSsaBIREZHe4zqa4mCiSURERHqPyxuJg7fOiYiIiEgUrGgSERGR3uOtc3GwoklEREREomBFk4iIiPQelzcSByuaRERERCQKiVar5aQEqpRKpUJ4eDjCwsIgl8trejhE/DdJtRL/XRI9GhNNeqTc3FxYWloiJycHCoWipodDxH+TVCvx3yXRo/HWORERERGJgokmEREREYmCiSYRERERiYKJJj2SXC7H3LlzObmdag3+m6TaiP8uiR6NDwMRERERkShY0SQiIiIiUTDRJCIiIiJRMNEkIiIiIlEw0SQiIiIiUTDRpEqtXr0aDRs2hLGxMXx9fXH8+PGaHhLpsUOHDuHVV1+Fs7MzJBIJdu3aVdNDIj335ZdfolWrVlAoFFAoFFAqldi7d29ND4uo1mGiSRVs27YNoaGhmDt3Lk6dOoXWrVvD398fmZmZNT000lP5+flo3bo1Vq9eXdNDIQIAuLi44JNPPkF8fDxOnjyJV155Bf3798f58+dremhEtQqXN6IKfH190b59e6xatQoAoNFo4OrqikmTJmHmzJk1PDrSdxKJBDt37sSAAQNqeihEOmxsbPDZZ59h7NixNT0UolqDFU3SUVxcjPj4ePj5+QltUqkUfn5+iIuLq8GRERHVTmq1Glu3bkV+fj6USmVND4eoVjGo6QFQ7XL79m2o1Wo4ODjotDs4OODSpUs1NCoiotrn7NmzUCqVKCoqgrm5OXbu3AlPT8+aHhZRrcKKJhER0b/QrFkzJCQk4NixY5gwYQICAwNx4cKFmh4WUa3CiibpsLOzg0wmQ0ZGhk57RkYGHB0da2hURES1j5GRETw8PAAAPj4+OHHiBFasWIGvvvqqhkdGVHuwokk6jIyM4OPjg5iYGKFNo9EgJiaGc4+IiB5Do9FApVLV9DCIahVWNKmC0NBQBAYGol27dnjxxRexfPly5OfnY/To0TU9NNJTeXl5SEpKEl4nJycjISEBNjY2aNCgQQ2OjPRVWFgYevfujQYNGuD+/fvYsmULDhw4gH379tX00IhqFSaaVMGQIUOQlZWFOXPmID09Hd7e3oiKiqrwgBDRs3Ly5El069ZNeB0aGgoACAwMRERERA2NivRZZmYm3nrrLaSlpcHS0hKtWrXCvn370KNHj5oeGlGtwnU0iYiIiEgUnKNJRERERKJgoklEREREomCiSURERESiYKJJRERERKJgoklEREREomCiSURERESiYKJJRERERKJgoklEREREomCiSURP3ahRozBgwADhddeuXTFlypRnPo4DBw5AIpEgOzv7kTESiQS7du2qcp/z5s2Dt7f3fxrXtWvXIJFIkJCQ8J/6ISKq7ZhoEumJUaNGQSKRQCKRwMjICB4eHliwYAFKS0tFP/fPP/+MhQsXVim2KskhERE9H/hd50R6pFevXtiwYQNUKhV+/fVXBAcHw9DQEGFhYRVii4uLYWRk9FTOa2Nj81T6ISKi5wsrmkR6RC6Xw9HREW5ubpgwYQL8/Pzwv//9D8CD290fffQRnJ2d0axZMwDAjRs38MYbb8DKygo2Njbo378/rl27JvSpVqsRGhoKKysr2NraYvr06dBqtTrn/eetc5VKhRkzZsDV1RVyuRweHh749ttvce3aNXTr1g0AYG1tDYlEglGjRgEANBoNwsPD4e7uDhMTE7Ru3Ro//vijznl+/fVXNG3aFCYmJujWrZvOOKtqxowZaNq0KUxNTdGoUSPMnj0bJSUlFeK++uoruLq6wtTUFG+88QZycnJ09q9btw4tWrSAsbExmjdvjjVr1lR7LEREzzsmmkR6zMTEBMXFxcLrmJgYJCYmIjo6Gnv27EFJSQn8/f1hYWGBw4cP448//oC5uTl69eolHLdkyRJERERg/fr1OHLkCO7evYudO3c+9rxvvfUWfvjhB6xcuRIXL17EV199BXNzc7i6uuKnn34CACQmJiItLQ0rVqwAAISHh+O7777D2rVrcf78eYSEhODNN9/EwYMHAZQlxAMHDsSrr76KhIQEjBs3DjNnzqz2e2JhYYGIiAhcuHABK1aswDfffINly5bpxCQlJWH79u3YvXs3oqKi8Ndff+Hdd98V9m/evBlz5szBRx99hIsXL+Ljjz/G7NmzsXHjxmqPh4jouaYlIr0QGBio7d+/v1ar1Wo1Go02OjpaK5fLte+//76w38HBQatSqYRjNm3apG3WrJlWo9EIbSqVSmtiYqLdt2+fVqvVap2cnLSLFy8W9peUlGhdXFyEc2m1Wm2XLl20kydP1mq1Wm1iYqIWgDY6OrrScf7+++9aANp79+4JbUVFRVpTU1Pt0aNHdWLHjh2rHTZsmFar1WrDwsK0np6eOvtnzJhRoa9/AqDduXPnI/d/9tlnWh8fH+H13LlztTKZTHvz5k2hbe/evVqpVKpNS0vTarVabePGjbVbtmzR6WfhwoVapVKp1Wq12uTkZC0A7V9//fXI8xIR1QWco0mkR/bs2QNzc3OUlJRAo9Fg+PDhmDdvnrDfy8tLZ17m6dOnkZSUBAsLC51+ioqKcOXKFeTk5CAtLQ2+vr7CPgMDA7Rr167C7fNyCQkJkMlk6NKlS5XHnZSUhIKCAvTo0UOnvbi4GG3atAEAXLx4UWccAKBUKqt8jnLbtm3DypUrceXKFeTl5aG0tBQKhUInpkGDBqhfv77OeTQaDRITE2FhYYErV65g7NixGD9+vBBTWloKS0vLao+HiOh5xkSTSI9069YNX375JYyMjODs7AwDA91fAWZmZjqv8/Ly4OPjg82bN1foq169ev9qDCYmJtU+Ji8vDwAQGRmpk+ABZfNOn5a4uDiMGDEC8+fPh7+/PywtLbF161YsWbKk2mP95ptvKiS+MpnsqY2ViOh5wESTSI+YmZnBw8OjyvFt27bFtm3bYG9vX6GqV87JyQnHjh1D586dAZRV7uLj49G2bdtK4728vKDRaHDw4EH4+flV2F9eUVWr1UKbp6cn5HI5UlJSHlkJbdGihfBgU7k///zzyRf5kKNHj8LNzQ0ffvih0Hb9+vUKcSkpKUhNTYWzs7NwHqlUimbNmsHBwQHOzs64evUqRowYUa3zExHVNXwYiIgeacSIEbCzs0P//v1x+PBhJCcn48CBA3jvvfdw8+ZNAMDkyZPxySefYNeuXbh06RLefffdx66B2bBhQwQGBmLMmDHYtWuX0Of27dsBAG5ubpBIJNizZw+ysrKQl5cHCwsLvP/++wgJCcHGjRtx5coVnDp1Cl988YXwgE1QUBAuX76MadOmITExEVu2bEFERES1rrdJkyZISUnB1q1bceXKFaxcubLSB5uMjY0RGBiI06dP4/Dhw3jvvffwxhtvwNHREQAwf/58hIeHY+XKlfj7779x9uxZbNiwAUuXLq3WeIiInndMNInokUxNTXHo0CE0aNAAAwcORIsWLTB27FgUFRUJFc6pU6di5MiRCAwMhFKphIWFBV577bXH9vvll19i8ODBePfdd9G8eXOMHz8e+fn5AID69etj/vz5mDlzJhwcHDBx4kQAwMKFCzF79myEh4ejRYsW6NWrFyIjI+Hu7g6gbN7kTz/9hF27dqF169ZYu3YtPv7442pdb79+/RASEoKJEyfC29sbR48exezZsyvEeXh4YODAgejTpw969uyJVq1a6SxfNG7cOKxbtw4bNmyAl5cXunTpgoiICGGsRET6QqJ91Ix9IiIiIqL/gBVNIiIiIhIFE00iIiIiEgUTTSIiIiISBRNNIiIiIhIFE00iIiIiEgUTTSIiIiISBRNNIiIiIhIFE00iIiIiEgUTTSIiIiISBRNNIiIiIhIFE00iIiIiEsX/ARZdOfggVAZ9AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "\n",
    "# Precision, Recall, F1 score\n",
    "report = classification_report(y_test, y_pred, digits=4)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display the confusion matrix as a DataFrame\n",
    "labels = sorted(set(y_test))\n",
    "cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "print(\"Confusion Matrix:\\n\", cm_df)\n",
    "\n",
    "# Visualize the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_df, annot=True, fmt='d', cmap='coolwarm')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.7285 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7386 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7166 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7352 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7409 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7409 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7221 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7311 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7381 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7390 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7159 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7210 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7003 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7004 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6873 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6945 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7285 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7321 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7282 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7320 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7172 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7156 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7175 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7156 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7136 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7122 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7136 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7122 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6259 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6261 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6273 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6272 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7309 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7373 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7279 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7363 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7273 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7257 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7258 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7260 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7219 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7212 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7209 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7207 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6502 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6501 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6511 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6520 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7280 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7379 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7164 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7349 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7396 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7397 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7219 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7308 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7379 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7382 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7155 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7207 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6998 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7000 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6871 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6942 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7288 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7320 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7279 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7320 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7173 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7158 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7171 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7150 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7138 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7120 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7135 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7120 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6264 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6264 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6274 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6271 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7307 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7373 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7278 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7360 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7272 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7257 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7256 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7259 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7220 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7209 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7206 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7202 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6504 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6503 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6511 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6519 | Hyperparameters: {'clf__alpha': 0.1, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7372 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7362 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7278 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7341 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7423 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7329 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7231 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7153 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7394 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7314 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7146 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7045 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6957 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6871 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6921 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6882 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7313 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7322 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7288 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7320 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7177 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7149 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7173 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7153 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7143 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7116 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7137 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7121 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6259 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6260 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6272 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6269 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7364 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7369 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7312 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7369 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7283 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7244 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7260 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7255 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7230 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7207 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7210 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7200 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6507 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6491 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6513 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6514 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7363 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7352 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7274 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7336 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7410 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7309 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7228 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7147 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7386 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7294 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7141 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7041 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6941 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6856 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6917 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6878 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7315 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7317 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7288 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7319 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7180 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7151 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7171 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7149 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7145 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7118 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7135 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7117 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6266 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6265 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6272 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6268 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7362 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7362 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7311 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7366 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7280 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7241 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7258 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7251 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7232 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7206 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7208 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7199 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6509 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6493 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6514 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6515 | Hyperparameters: {'clf__alpha': 0.5, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7387 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7324 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7283 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7289 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7389 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7258 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7158 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7018 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7357 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7239 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7091 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6935 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6883 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6766 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6864 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6789 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7330 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7305 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7298 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7318 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7181 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7142 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7174 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7147 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7145 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7110 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7137 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7116 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6260 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6257 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6270 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6268 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7386 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7338 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7330 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7365 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7288 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7229 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7260 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7246 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7236 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7196 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7210 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7195 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6505 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6482 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6514 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6510 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7375 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7306 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7280 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7281 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7365 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7231 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7152 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7011 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7340 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7217 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7085 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6930 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6861 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6747 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6859 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6784 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7330 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7300 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7297 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7317 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7182 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7141 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7171 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7144 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7149 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7111 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7136 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7113 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6264 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6263 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6269 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6267 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7383 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7330 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7327 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7361 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7287 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7222 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7259 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7244 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7240 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7194 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7209 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7193 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6507 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6484 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6513 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6510 | Hyperparameters: {'clf__alpha': 1.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7210 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6970 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6959 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6752 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7078 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6817 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6811 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6577 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7037 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6778 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6795 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6548 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6514 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6302 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6535 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6378 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7281 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7057 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7292 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7177 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7156 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6987 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7159 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7083 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7127 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6972 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7120 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7048 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6236 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6181 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6257 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6226 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7276 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7027 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7275 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7105 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7222 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7022 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7226 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7102 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7197 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7010 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7189 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7079 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6429 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6339 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6459 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6408 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': True, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7168 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6929 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6950 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6744 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6975 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6750 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6800 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6568 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6944 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6698 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6781 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6540 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6431 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6230 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6516 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6363 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': None, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7258 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7033 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7287 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7170 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7151 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6984 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7153 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7078 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7128 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6967 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7116 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7045 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6239 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6188 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6253 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6227 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7247 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6993 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7267 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7096 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7211 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7007 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7223 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7096 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7191 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7002 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.7186 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.7073 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 3), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6431 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6339 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': False}\n",
      "Mean accuracy: 0.6458 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': True}\n",
      "Mean accuracy: 0.6404 | Hyperparameters: {'clf__alpha': 10.0, 'clf__fit_prior': False, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (2, 2), 'tfidf__norm': 'l2', 'tfidf__use_idf': False}\n",
      "Best parameters:  {'clf__alpha': 0.5, 'clf__fit_prior': True, 'tfidf__max_features': None, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l1', 'tfidf__use_idf': True}\n",
      "Accuracy on test data: 0.7532\n",
      "Confusion Matrix:\n",
      " [[28493 10867 13640]\n",
      " [ 4182 43991  5041]\n",
      " [ 2973  2661 47678]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.54      0.64     53000\n",
      "           1       0.76      0.83      0.79     53214\n",
      "           3       0.72      0.89      0.80     53312\n",
      "\n",
      "    accuracy                           0.75    159526\n",
      "   macro avg       0.76      0.75      0.74    159526\n",
      "weighted avg       0.76      0.75      0.74    159526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "import dill\n",
    "\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,2))),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'tfidf__max_features': [None, 5000, 10000],\n",
    "    'clf__alpha': [0.1, 0.5, 1.0, 10.0],\n",
    "    #'tfidf__min_df': [1, 2],\n",
    "    #'tfidf__max_df': [0.75, 1.0],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3), (2,2)],\n",
    "    'tfidf__use_idf': [True, False],\n",
    "    'tfidf__norm': ['l1', 'l2'],\n",
    "    'clf__fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(text_clf, params, cv=10, n_jobs=1, scoring='accuracy')\n",
    "grid_search.fit(X_val.tolist(), y_val)\n",
    "\n",
    "# Print the mean test scores and corresponding hyperparameter combinations\n",
    "for mean_score, params in zip(grid_search.cv_results_['mean_test_score'], grid_search.cv_results_['params']):\n",
    "    print(\"Mean accuracy: {:.4f} | Hyperparameters: {}\".format(mean_score, params))\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "# Train the model with the best hyperparameters on the entire training set\n",
    "best_clf = grid_search.best_estimator_\n",
    "best_clf.fit(X_train.tolist(), y_train)\n",
    "\n",
    "y_pred = best_clf.predict(X_test.tolist())\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy on test data: {:.4f}\".format(accuracy))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Classification Report\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", cr)\n",
    "4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPECIFIC TF-IDF PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 0.7559\n",
      "Confusion Matrix:\n",
      " [[31821  9492 11551]\n",
      " [ 6315 42881  4227]\n",
      " [ 4798  2561 45879]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.60      0.66     52864\n",
      "           1       0.78      0.80      0.79     53423\n",
      "           3       0.74      0.86      0.80     53238\n",
      "\n",
      "    accuracy                           0.76    159525\n",
      "   macro avg       0.76      0.76      0.75    159525\n",
      "weighted avg       0.76      0.76      0.75    159525\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "import dill\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2), max_features=None, norm='l1', use_idf=True)),\n",
    "    ('clf', MultinomialNB(alpha=0.5, fit_prior=True))\n",
    "])\n",
    "\n",
    "text_clf.fit(X_train.tolist(), y_train)\n",
    "\n",
    "y_pred = text_clf.predict(X_val.tolist())\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print(\"Accuracy on test data: {:.4f}\".format(accuracy))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Classification Report\n",
    "cr = classification_report(y_val, y_pred)\n",
    "print(\"Classification Report:\\n\", cr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.6899 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 1000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6664 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 1000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.5251 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 1000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6630 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 1000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7328 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 5000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7155 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 5000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6061 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 5000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7104 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 5000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7391 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 10000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7264 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6372 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7213 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': 10000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7294 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': None, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7194 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6871 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': None, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7122 | Hyperparameters: {'clf__alpha': 0.01, 'vect__max_features': None, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.6899 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 1000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6664 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 1000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.5251 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 1000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6630 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 1000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7328 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 5000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7155 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 5000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6061 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 5000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7104 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 5000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7391 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 10000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7264 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6372 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7213 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': 10000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7359 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': None, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7359 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.7064 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': None, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7286 | Hyperparameters: {'clf__alpha': 0.1, 'vect__max_features': None, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.6898 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6664 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.5251 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 1000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6630 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7329 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7154 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6061 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 5000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7103 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7391 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7263 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6368 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7213 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7398 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': None, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7344 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.7086 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': None, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7197 | Hyperparameters: {'clf__alpha': 1.0, 'vect__max_features': None, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.6897 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6662 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.5250 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 1000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6629 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7323 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7148 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6051 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 5000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7098 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7380 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7255 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6354 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7204 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7130 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': None, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6698 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6624 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': None, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6597 | Hyperparameters: {'clf__alpha': 10.0, 'vect__max_features': None, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.6875 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6643 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.5237 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 1000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6615 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 1000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7220 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7097 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.5995 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 5000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7051 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 5000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.7157 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.7154 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6241 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 10000, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.7114 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': 10000, 'vect__ngram_range': (1, 3)}\n",
      "Mean accuracy: 0.6179 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': None, 'vect__ngram_range': (1, 1)}\n",
      "Mean accuracy: 0.6134 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n",
      "Mean accuracy: 0.6200 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': None, 'vect__ngram_range': (2, 2)}\n",
      "Mean accuracy: 0.6148 | Hyperparameters: {'clf__alpha': 100.0, 'vect__max_features': None, 'vect__ngram_range': (1, 3)}\n",
      "Best parameters:  {'clf__alpha': 1.0, 'vect__max_features': None, 'vect__ngram_range': (1, 1)}\n",
      "Accuracy on test data: 0.7398\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "import dill\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features=None, ngram_range=(1,2))),\n",
    "    ('clf', MultinomialNB(alpha=0.1))\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'vect__ngram_range': [(1,1), (1,2), (2,2), (1,3)],\n",
    "    'vect__max_features': [1000, 5000, 10000, None],\n",
    "    'clf__alpha': [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(text_clf, params, cv=5, n_jobs=1)\n",
    " \n",
    "grid_search.fit(X_train.tolist(), y_train)\n",
    "\n",
    "# Print the mean test scores and corresponding hyperparameter combinations\n",
    "for mean_score, params in zip(grid_search.cv_results_['mean_test_score'], grid_search.cv_results_['params']):\n",
    "    print(\"Mean accuracy: {:.4f} | Hyperparameters: {}\".format(mean_score, params))\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "y_pred = grid_search.predict(X_test.tolist())\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy on test data: {:.4f}\".format(accuracy))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tri-grams Hyper-Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39m# Perform grid search to find the best hyperparameters\u001b[39;00m\n\u001b[0;32m     34\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(text_clf, params, cv\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(X_val\u001b[39m.\u001b[39;49mtolist(), y_val)\n\u001b[0;32m     37\u001b[0m \u001b[39m# Print the mean test scores and corresponding hyperparameter combinations\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[39mfor\u001b[39;00m mean_score, params \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(grid_search\u001b[39m.\u001b[39mcv_results_[\u001b[39m'\u001b[39m\u001b[39mmean_test_score\u001b[39m\u001b[39m'\u001b[39m], grid_search\u001b[39m.\u001b[39mcv_results_[\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m]):\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\pipeline.py:401\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \n\u001b[0;32m    377\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    400\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m--> 401\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps)\n\u001b[0;32m    402\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[0;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\pipeline.py:359\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    357\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[0;32m    358\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    360\u001b[0m     cloned_transformer,\n\u001b[0;32m    361\u001b[0m     X,\n\u001b[0;32m    362\u001b[0m     y,\n\u001b[0;32m    363\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    364\u001b[0m     message_clsname\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    365\u001b[0m     message\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(step_idx),\n\u001b[0;32m    366\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps[name],\n\u001b[0;32m    367\u001b[0m )\n\u001b[0;32m    368\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    892\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 893\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit_transform(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    895\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1387\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1379\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1380\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1381\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1382\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1384\u001b[0m             )\n\u001b[0;32m   1385\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> 1387\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[0;32m   1389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[0;32m   1390\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1278\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1276\u001b[0m feature_idx \u001b[39m=\u001b[39m vocabulary[feature]\n\u001b[0;32m   1277\u001b[0m \u001b[39mif\u001b[39;00m feature_idx \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m feature_counter:\n\u001b[1;32m-> 1278\u001b[0m     feature_counter[feature_idx] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1279\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1280\u001b[0m     feature_counter[feature_idx] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from numba import jit, cuda\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from scipy.stats import uniform\n",
    "import nltk\n",
    "import dill\n",
    "\n",
    "# Define the pipeline \n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()), \n",
    "    ('tfidf', TfidfTransformer()), \n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Define the hyperparameters for GridSearchCV\n",
    "params = {\n",
    "    'vect__ngram_range': [(1,1), (1,2), (1,3), (2,2)],\n",
    "    'vect__max_features': [1000, 5000, 10000, None],\n",
    "    'tfidf__use_idf': [True, False],\n",
    "    'tfidf__norm': ['l1', 'l2'],\n",
    "    'clf__alpha': [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "}\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(text_clf, params, cv=10, n_jobs=1, scoring='accuracy')\n",
    "grid_search.fit(X_val.tolist(), y_val)\n",
    "\n",
    "# Print the mean test scores and corresponding hyperparameter combinations\n",
    "for mean_score, params in zip(grid_search.cv_results_['mean_test_score'], grid_search.cv_results_['params']):\n",
    "    print(\"Mean accuracy: {:.4f} | Hyperparameters: {}\".format(mean_score, params))\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "# Train the classifier with the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Train the classifier with the best hyperparameters\n",
    "text_clf1 = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=best_params['vect__ngram_range'], max_features=best_params['vect__max_features'])), \n",
    "    ('tfidf', TfidfTransformer(use_idf=best_params['tfidf__use_idf'], norm=best_params['tfidf__norm'])),\n",
    "    ('clf', MultinomialNB(alpha=best_params['clf__alpha']))\n",
    "])\n",
    "\n",
    "text_clf1.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "y_pred = text_clf1.predict(X_test.tolist())\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Final Hyper-Parameter Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 39\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39m# # Perform randomized search to find the best hyperparameters\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39m# random_search = RandomizedSearchCV(text_clf, params, cv=5, n_iter=50, n_jobs=1, random_state=19)\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39m# random_search.fit(X_train.tolist(), y_train)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m random_search2 \u001b[39m=\u001b[39m RandomizedSearchCV(text_clf, params, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, n_iter\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)  \u001b[39m# Change random_state\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m random_search2\u001b[39m.\u001b[39;49mfit(X_train\u001b[39m.\u001b[39;49mtolist(), y_train)\n\u001b[0;32m     41\u001b[0m \u001b[39m# Print the mean test scores and corresponding hyperparameter combinations\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[39mfor\u001b[39;00m mean_score, params \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(random_search2\u001b[39m.\u001b[39mcv_results_[\u001b[39m'\u001b[39m\u001b[39mmean_test_score\u001b[39m\u001b[39m'\u001b[39m], random_search2\u001b[39m.\u001b[39mcv_results_[\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m]):\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1768\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1766\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1767\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1768\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1769\u001b[0m         ParameterSampler(\n\u001b[0;32m   1770\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[0;32m   1771\u001b[0m         )\n\u001b[0;32m   1772\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\pipeline.py:401\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \n\u001b[0;32m    377\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    400\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m--> 401\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps)\n\u001b[0;32m    402\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[0;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\pipeline.py:359\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    357\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[0;32m    358\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    360\u001b[0m     cloned_transformer,\n\u001b[0;32m    361\u001b[0m     X,\n\u001b[0;32m    362\u001b[0m     y,\n\u001b[0;32m    363\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    364\u001b[0m     message_clsname\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    365\u001b[0m     message\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(step_idx),\n\u001b[0;32m    366\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps[name],\n\u001b[0;32m    367\u001b[0m )\n\u001b[0;32m    368\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    892\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 893\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit_transform(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    895\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1387\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1379\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1380\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1381\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1382\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1384\u001b[0m             )\n\u001b[0;32m   1385\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> 1387\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[0;32m   1389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[0;32m   1390\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\clayt\\anaconda3\\envs\\dissertation2023\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1276\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1274\u001b[0m \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m analyze(doc):\n\u001b[0;32m   1275\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1276\u001b[0m         feature_idx \u001b[39m=\u001b[39m vocabulary[feature]\n\u001b[0;32m   1277\u001b[0m         \u001b[39mif\u001b[39;00m feature_idx \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m feature_counter:\n\u001b[0;32m   1278\u001b[0m             feature_counter[feature_idx] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from numba import jit, cuda\n",
    "# from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import FunctionTransformer\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# from nltk.corpus import stopwords\n",
    "# import string\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from scipy.stats import uniform\n",
    "# import nltk\n",
    "# import dill\n",
    "\n",
    "# # Define the pipeline \n",
    "# text_clf = Pipeline([\n",
    "#     ('vect', CountVectorizer()), # This step converts the collection of text into a matrix of token counts. It creates a vocabulary of all the unique words in the corpus and assigns a numerical value to each word.\n",
    "#     ('tfidf', TfidfTransformer()), # This step converts the raw term frequency matrix generated by CountVectorizer into a normalized term frequency-inverse document frequency (TF-IDF) representation.\n",
    "#     ('clf', MultinomialNB())\n",
    "# ])\n",
    "\n",
    "# # Define the hyperparameters for RandomizedSearchCV\n",
    "# params = {\n",
    "#     'vect__ngram_range': [(1,1), (1,2), (1,3), (2,2)],\n",
    "#     'vect__max_features': [1000, 5000, 10000, None],\n",
    "#     'tfidf__use_idf': [True, False],\n",
    "#     'tfidf__norm': ['l1', 'l2'],\n",
    "#     'clf__alpha': [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "# }\n",
    "\n",
    "# # # Perform randomized search to find the best hyperparameters\n",
    "# # random_search = RandomizedSearchCV(text_clf, params, cv=5, n_iter=50, n_jobs=1, random_state=19)\n",
    "# # random_search.fit(X_train.tolist(), y_train)\n",
    "\n",
    "# random_search2 = RandomizedSearchCV(text_clf, params, cv=10, n_iter=10, n_jobs=1, random_state=42)  # Change random_state\n",
    "# random_search2.fit(X_train.tolist(), y_train)\n",
    "\n",
    "# # Print the mean test scores and corresponding hyperparameter combinations\n",
    "# for mean_score, params in zip(random_search2.cv_results_['mean_test_score'], random_search2.cv_results_['params']):\n",
    "#     print(\"Mean accuracy: {:.4f} | Hyperparameters: {}\".format(mean_score, params))\n",
    "\n",
    "# print(\"Best parameters: \", random_search2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numba import jit, cuda\n",
    "# import spacy\n",
    "# import numpy as np\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# # Define the set of best parameters\n",
    "# best_params = {'vect__ngram_range': (1,2), 'vect__max_features': None, 'tfidf__use_idf': True, 'tfidf__norm': 'l1', 'clf__alpha': 1.0}\n",
    "\n",
    "# # Define a custom transformer for part-of-speech tagging\n",
    "# class POSTagger:\n",
    "#     def transform(self, X):\n",
    "#         return [self.tag_text(text) for text in X]\n",
    "    \n",
    "#     def tag_text(self, text):\n",
    "#         doc = nlp(text)\n",
    "#         return ' '.join([token.pos_ for token in doc])\n",
    "\n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "\n",
    "# # Train and evaluate the classifier using part-of-speech tagging\n",
    "# text_clf = Pipeline([\n",
    "#     ('pos_tagger', POSTagger()),\n",
    "#     ('vect', CountVectorizer()),\n",
    "#     ('tfidf', TfidfTransformer()),\n",
    "#     ('clf', MultinomialNB(alpha=best_params['clf__alpha']))\n",
    "# ])\n",
    "\n",
    "# scores = cross_val_score(text_clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "# print(\"Accuracy scores with part-of-speech tagging: \", scores)\n",
    "# print(\"Mean accuracy with part-of-speech tagging: \", np.mean(scores))\n",
    "\n",
    "# # Save the model using dill\n",
    "\n",
    "# import dill\n",
    "\n",
    "# filename = 'my_model.pkl'\n",
    "# with open(filename, 'wb') as file:\n",
    "#     dill.dump(text_clf, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# # Define the first set of best parameters\n",
    "# best_params1 = {'vect__ngram_range': (1,3), 'vect__max_features': None, 'tfidf__use_idf': True, 'tfidf__norm': 'l1', 'clf__alpha': 1.0}\n",
    "\n",
    "# # Define the second set of best parameters\n",
    "# best_params2 = {'clf__alpha': 0.651484771857788, 'tfidf__use_idf': True, 'vect__max_df': 0.8, 'vect__max_features': None, 'vect__min_df': 3, 'vect__ngram_range': (1,2)}\n",
    "\n",
    "# # Train and evaluate the classifier using the first set of best parameters\n",
    "# text_clf1 = Pipeline([\n",
    "#     ('vect', CountVectorizer(ngram_range=best_params1['vect__ngram_range'], max_features=best_params1['vect__max_features'])), \n",
    "#     ('tfidf', TfidfTransformer(use_idf=best_params1['tfidf__use_idf'], norm=best_params1['tfidf__norm'])),\n",
    "#     ('clf', MultinomialNB(alpha=best_params1['clf__alpha']))\n",
    "# ])\n",
    "\n",
    "# scores1 = cross_val_score(text_clf1, X_train, y_train, cv=5, scoring='accuracy')\n",
    "# print(\"Accuracy scores with best parameters 1: \", scores1)\n",
    "# print(\"Mean accuracy with best parameters 1: \", np.mean(scores1))\n",
    "\n",
    "# # Fit the model with the whole training set\n",
    "# text_clf1.fit(X_train, y_train)\n",
    "\n",
    "# # # Save the model to a file\n",
    "# # filename = 'naive_bayes_modelFinal.sav'\n",
    "# # dill.dump(text_clf1, open(filename, 'wb'))\n",
    "\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# # Evaluate the classifier on the test set\n",
    "# y_pred = text_clf1.predict(X_test.tolist())  # Change text_clf to text_clf1\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# # Print the classification report\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# # # Train and evaluate the classifier using the second set of best parameters\n",
    "# # text_clf2 = Pipeline([\n",
    "# #     ('vect', CountVectorizer(ngram_range=best_params2['vect__ngram_range'], min_df=best_params2['vect__min_df'], \n",
    "# #                               max_df=best_params2['vect__max_df'], max_features=best_params2['vect__max_features'])),\n",
    "# #     ('tfidf', TfidfTransformer(use_idf=best_params2['tfidf__use_idf'])),\n",
    "# #     ('clf', MultinomialNB(alpha=best_params2['clf__alpha']))\n",
    "# # ])\n",
    "\n",
    "# # scores2 = cross_val_score(text_clf2, X_train, y_train, cv=10, scoring='accuracy')\n",
    "# # print(\"Accuracy scores with best parameters 2: \", scores2)\n",
    "# # print(\"Mean accuracy with best parameters 2: \", np.mean(scores2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# pipeline = joblib.load('nbmodelwithdifferenthp2.sav')\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# # Read CSV file into a pandas DataFrame\n",
    "# df = pd.read_csv('SampleTweets.csv')\n",
    "\n",
    "# # Extract preprocessed text data as a list\n",
    "# preprocessed_data = df['processed_text'].tolist()\n",
    "\n",
    "# predictions = pipeline.predict(preprocessed_data)\n",
    "\n",
    "# for text, prediction in zip(preprocessed_data, predictions):\n",
    "#     print(f'Text: {text} | Prediction: {prediction}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dissertation 2023",
   "language": "python",
   "name": "dissertation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c5394edd7dbe54ff5ee01d77964ae3a51c12f52fc62d5a457fcc64c12a95467e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
